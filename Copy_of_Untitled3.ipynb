{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwmQbAT0iSo9voRAr2kPU8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/senushidinara/Tvideo/blob/main/Copy_of_Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvKmJCFytybL",
        "outputId": "140d1870-a199-429e-c6d2-c08c2fd00c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'<script>var currentView = 2\\n\\n</script><!----><script>var currentView = 2\\n\\n</script><!----><html><head><!DOCTYPE html><environment style=\"display:none\">nlsp.nasa.gov</environment><alias style=\"display:none\">lsdapub</alias><configID style=\"display:none\"></configID><originalUrl style=\"display:none\">http://insight-2-prod.nasawestprime.com:9200/_alias/lsdapub</originalUrl><script src=\"/static/libs/bootstrap-5.2.0/js/popper.min.js?_v=CLEAR__BROWSER__CACHE__6.14.4\"></script><script src=\"/static/libs/bo'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "url = \"https://nlsp.nasa.gov/files/lsda/JMGROUNDLMLSTP34_115.xls\"\n",
        "\n",
        "# Fetch the content from the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Print the first 500 characters of the response content\n",
        "    print(response.content[:500])\n",
        "    # Try loading with pandas, might still fail if the content is not direct Excel\n",
        "    # df = pd.read_excel(url, engine='xlrd')\n",
        "    # print(df.head())\n",
        "else:\n",
        "    print(f\"Failed to retrieve the file. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Install 'xlrd' if your files are in the older .xls format\n",
        "#    (Only needed for .xls files)\n",
        "!pip install xlrd\n",
        "\n",
        "# 2. Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "# Follow the prompts to authenticate your Google Drive access\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 3. ***CRITICAL: Define the exact path to your data folder.***\n",
        "#    Modify 'NASA_LSDA' if your folder name is different.\n",
        "drive_path = '/content/drive/MyDrive/NASA_LSDA/'\n",
        "\n",
        "# 4. Define the exact filenames you uploaded.\n",
        "#    ***NOTE: Change the file extensions and names if you uploaded CSVs or ZIPs.***\n",
        "sleep_file = \"JMGROUNDLMLSTP34_115.xls\"\n",
        "hrv_file   = \"HRV_dataset_file.xls\"\n",
        "ecg_file   = \"ECG_dataset_file.xls\"\n",
        "\n",
        "try:\n",
        "    print(f\"\\nAttempting to load files from: {drive_path}\")\n",
        "\n",
        "    # Check for file existence before attempting to read\n",
        "    if not os.path.exists(os.path.join(drive_path, sleep_file)):\n",
        "        print(f\"❌ File Not Found: {sleep_file} at {drive_path}. Please check the folder name and file name.\")\n",
        "    if not os.path.exists(os.path.join(drive_path, hrv_file)):\n",
        "        print(f\"❌ File Not Found: {hrv_file} at {drive_path}. Please check the folder name and file name.\")\n",
        "    if not os.path.exists(os.path.join(drive_path, ecg_file)):\n",
        "        print(f\"❌ File Not Found: {ecg_file} at {drive_path}. Please check the folder name and file name.\")\n",
        "\n",
        "    # 5. Load data into pandas DataFrames\n",
        "    #    Use pd.read_excel(..., engine='xlrd') for .xls files\n",
        "    sleep_df = pd.read_excel(os.path.join(drive_path, sleep_file), engine='xlrd')\n",
        "    hrv_df   = pd.read_excel(os.path.join(drive_path, hrv_file), engine='xlrd')\n",
        "    ecg_df   = pd.read_excel(os.path.join(drive_path, ecg_file), engine='xlrd')\n",
        "\n",
        "    print(\"\\n✅ All NASA files loaded successfully into DataFrames!\")\n",
        "    print(\"---\")\n",
        "    print(\"Sleep data shape:\", sleep_df.shape)\n",
        "    print(\"HRV data shape:\", hrv_df.shape)\n",
        "    print(\"ECG data shape:\", ecg_df.shape)\n",
        "\n",
        "    # Display the first few rows of the sleep data to confirm\n",
        "    print(\"\\nSleep Data Head (first 5 rows):\")\n",
        "    print(sleep_df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ An error occurred during file processing: {e}\")\n",
        "    print(\"Ensure all filenames and the drive path are correct, and the files are not nested in subfolders.\")\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Install 'xlrd' if your files are in the older .xls format\n",
        "#    (Only needed for .xls files)\n",
        "!pip install xlrd\n",
        "\n",
        "# 2. Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "# Follow the prompts to authenticate your Google Drive access\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 3. ***CRITICAL: Define the exact path to your data folder.***\n",
        "#    Modify 'NASA_LSDA' if your folder name is different.\n",
        "drive_path = '/content/drive/MyDrive/NASA_LSDA/'\n",
        "\n",
        "# 4. Define the exact filenames you uploaded.\n",
        "#    ***NOTE: Change the file extensions and names if you uploaded CSVs or ZIPs.***\n",
        "sleep_file = \"JMGROUNDLMLSTP34_115.xls\"\n",
        "hrv_file   = \"HRV_dataset_file.xls\"\n",
        "ecg_file   = \"ECG_dataset_file.xls\"\n",
        "\n",
        "try:\n",
        "    print(f\"\\nAttempting to load files from: {drive_path}\")\n",
        "\n",
        "    # Check for file existence before attempting to read\n",
        "    if not os.path.exists(os.path.join(drive_path, sleep_file)):\n",
        "        print(f\"❌ File Not Found: {sleep_file} at {drive_path}. Please check the folder name and file name.\")\n",
        "    if not os.path.exists(os.path.join(drive_path, hrv_file)):\n",
        "        print(f\"❌ File Not Found: {hrv_file} at {drive_path}. Please check the folder name and file name.\")\n",
        "    if not os.path.exists(os.path.join(drive_path, ecg_file)):\n",
        "        print(f\"❌ File Not Found: {ecg_file} at {drive_path}. Please check the folder name and file name.\")\n",
        "\n",
        "    # 5. Load data into pandas DataFrames\n",
        "    #    Use pd.read_excel(..., engine='xlrd') for .xls files\n",
        "    sleep_df = pd.read_excel(os.path.join(drive_path, sleep_file), engine='xlrd')\n",
        "    hrv_df   = pd.read_excel(os.path.join(drive_path, hrv_file), engine='xlrd')\n",
        "    ecg_df   = pd.read_excel(os.path.join(drive_path, ecg_file), engine='xlrd')\n",
        "\n",
        "    print(\"\\n✅ All NASA files loaded successfully into DataFrames!\")\n",
        "    print(\"---\")\n",
        "    print(\"Sleep data shape:\", sleep_df.shape)\n",
        "    print(\"HRV data shape:\", hrv_df.shape)\n",
        "    print(\"ECG data shape:\", ecg_df.shape)\n",
        "\n",
        "    # Display the first few rows of the sleep data to confirm\n",
        "    print(\"\\nSleep Data Head (first 5 rows):\")\n",
        "    print(sleep_df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ An error occurred during file processing: {e}\")\n",
        "    print(\"Ensure all filenames and the drive path are correct, and the files are not nested in subfolders.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqXlSpV11e7c",
        "outputId": "6d43cc89-53d4-48e5-b532-1b908de96231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "\n",
            "Attempting to load files from: /content/drive/MyDrive/NASA_LSDA/\n",
            "❌ File Not Found: JMGROUNDLMLSTP34_115.xls at /content/drive/MyDrive/NASA_LSDA/. Please check the folder name and file name.\n",
            "❌ File Not Found: HRV_dataset_file.xls at /content/drive/MyDrive/NASA_LSDA/. Please check the folder name and file name.\n",
            "❌ File Not Found: ECG_dataset_file.xls at /content/drive/MyDrive/NASA_LSDA/. Please check the folder name and file name.\n",
            "\n",
            "❌ An error occurred during file processing: [Errno 2] No such file or directory: '/content/drive/MyDrive/NASA_LSDA/JMGROUNDLMLSTP34_115.xls'\n",
            "Ensure all filenames and the drive path are correct, and the files are not nested in subfolders.\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Attempting to load files from: /content/drive/MyDrive/NASA_LSDA/\n",
            "❌ File Not Found: JMGROUNDLMLSTP34_115.xls at /content/drive/MyDrive/NASA_LSDA/. Please check the folder name and file name.\n",
            "❌ File Not Found: HRV_dataset_file.xls at /content/drive/MyDrive/NASA_LSDA/. Please check the folder name and file name.\n",
            "❌ File Not Found: ECG_dataset_file.xls at /content/drive/MyDrive/NASA_LSDA/. Please check the folder name and file name.\n",
            "\n",
            "❌ An error occurred during file processing: [Errno 2] No such file or directory: '/content/drive/MyDrive/NASA_LSDA/JMGROUNDLMLSTP34_115.xls'\n",
            "Ensure all filenames and the drive path are correct, and the files are not nested in subfolders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fea1626f",
        "outputId": "73cc5568-3018-4c53-b402-93df270a973b"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25 entries, 0 to 24\n",
            "Data columns (total 5 columns):\n",
            " #   Column                                                      Non-Null Count  Dtype \n",
            "---  ------                                                      --------------  ----- \n",
            " 0   NASA Life Sciences Data Archive (http://lsda.jsc.nasa.gov)  17 non-null     object\n",
            " 1   Unnamed: 1                                                  7 non-null      object\n",
            " 2   Unnamed: 2                                                  6 non-null      object\n",
            " 3   Unnamed: 3                                                  7 non-null      object\n",
            " 4   Unnamed: 4                                                  6 non-null      object\n",
            "dtypes: object(5)\n",
            "memory usage: 1.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "00a82cfd",
        "outputId": "936fbb9a-bdf8-4d65-a870-c7f2b06b9684"
      },
      "source": [
        "new_column_names = ['Measurement', 'Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                    'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "df.columns = new_column_names\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement Objective Measurement - Baseline  \\\n",
              "0           NaN                         Baseline   \n",
              "1  Duration (h)                        6.62±0.31   \n",
              "2  % Efficiency                       88.50±1.44   \n",
              "3   Latency (h)                        0.27±0.06   \n",
              "4       WASO **                        0.90±0.12   \n",
              "\n",
              "  Objective Measurement - Chamber Subjective Measurement - Baseline  \\\n",
              "0                         Chamber                          Baseline   \n",
              "1                       6.00±0.24                         6.78±0.27   \n",
              "2                      88.10±1.73                        96.40±1.16   \n",
              "3                       0.20±0.05                         0.20±0.05   \n",
              "4                       0.86±0.15                               NaN   \n",
              "\n",
              "  Subjective Measurement - Chamber  \n",
              "0                          Chamber  \n",
              "1                        6.21±0.21  \n",
              "2                       95.66±1.03  \n",
              "3                        0.24±0.05  \n",
              "4                              NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1c1a2f7-ad96-4a20-b22d-9c345a3d6ba8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Objective Measurement - Baseline</th>\n",
              "      <th>Objective Measurement - Chamber</th>\n",
              "      <th>Subjective Measurement - Baseline</th>\n",
              "      <th>Subjective Measurement - Chamber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>Chamber</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>Chamber</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>6.62±0.31</td>\n",
              "      <td>6.00±0.24</td>\n",
              "      <td>6.78±0.27</td>\n",
              "      <td>6.21±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>88.50±1.44</td>\n",
              "      <td>88.10±1.73</td>\n",
              "      <td>96.40±1.16</td>\n",
              "      <td>95.66±1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>0.27±0.06</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.24±0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>0.90±0.12</td>\n",
              "      <td>0.86±0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1c1a2f7-ad96-4a20-b22d-9c345a3d6ba8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1c1a2f7-ad96-4a20-b22d-9c345a3d6ba8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1c1a2f7-ad96-4a20-b22d-9c345a3d6ba8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86b7ad9e-d8ec-45b3-b11c-e7681a93ea73\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86b7ad9e-d8ec-45b3-b11c-e7681a93ea73')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86b7ad9e-d8ec-45b3-b11c-e7681a93ea73 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"% Efficiency\",\n          \"WASO **\",\n          \"Duration (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"6.62\\u00b10.31\",\n          \"0.90\\u00b10.12\",\n          \"88.50\\u00b11.44\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"6.00\\u00b10.24\",\n          \"0.86\\u00b10.15\",\n          \"88.10\\u00b11.73\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"6.78\\u00b10.27\",\n          \"0.20\\u00b10.05\",\n          \"Baseline\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"6.21\\u00b10.21\",\n          \"0.24\\u00b10.05\",\n          \"Chamber\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "5c7ffd4e",
        "outputId": "e9c55463-f557-40c8-e813-2bd46c64cda4"
      },
      "source": [
        "display(df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Objective Measurement', 'Unnamed: 2',\n",
              "       'Subjective Measurement', 'Unnamed: 4'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "c7ee7382",
        "outputId": "d6129a3e-b4b5-4051-b3ec-17d8c97248d0"
      },
      "source": [
        "excel_file_path = '/content/unzipped_data/JMGROUNDLMLSTP34_115/JMGROUNDLMLSTP34_115.xls'\n",
        "df = pd.read_excel(excel_file_path, header=9, engine='xlrd')\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Unnamed: 0 Objective Measurement  Unnamed: 2 Subjective Measurement  \\\n",
              "0           NaN              Baseline     Chamber               Baseline   \n",
              "1  Duration (h)             6.62±0.31   6.00±0.24              6.78±0.27   \n",
              "2  % Efficiency            88.50±1.44  88.10±1.73             96.40±1.16   \n",
              "3   Latency (h)             0.27±0.06   0.20±0.05              0.20±0.05   \n",
              "4       WASO **             0.90±0.12   0.86±0.15                    NaN   \n",
              "\n",
              "   Unnamed: 4  \n",
              "0     Chamber  \n",
              "1   6.21±0.21  \n",
              "2  95.66±1.03  \n",
              "3   0.24±0.05  \n",
              "4         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29be9c10-d062-45e2-90a8-d32a9eb1d984\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Objective Measurement</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Subjective Measurement</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>Chamber</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>Chamber</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>6.62±0.31</td>\n",
              "      <td>6.00±0.24</td>\n",
              "      <td>6.78±0.27</td>\n",
              "      <td>6.21±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>88.50±1.44</td>\n",
              "      <td>88.10±1.73</td>\n",
              "      <td>96.40±1.16</td>\n",
              "      <td>95.66±1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>0.27±0.06</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.24±0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>0.90±0.12</td>\n",
              "      <td>0.86±0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29be9c10-d062-45e2-90a8-d32a9eb1d984')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29be9c10-d062-45e2-90a8-d32a9eb1d984 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29be9c10-d062-45e2-90a8-d32a9eb1d984');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7d450b43-8d39-4b18-b67f-6b4ca551cee7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d450b43-8d39-4b18-b67f-6b4ca551cee7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7d450b43-8d39-4b18-b67f-6b4ca551cee7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"% Efficiency\",\n          \"WASO **\",\n          \"Duration (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"6.62\\u00b10.31\",\n          \"0.90\\u00b10.12\",\n          \"88.50\\u00b11.44\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"6.00\\u00b10.24\",\n          \"0.86\\u00b10.15\",\n          \"88.10\\u00b11.73\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"6.78\\u00b10.27\",\n          \"0.20\\u00b10.05\",\n          \"Baseline\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 4\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"6.21\\u00b10.21\",\n          \"0.24\\u00b10.05\",\n          \"Chamber\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c97bf00b"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "* The header information was spread across multiple rows in the original data, with specific column names located in row 10 (0-based index 9).\n",
        "* Loading the data with `header=9` correctly set the row at index 9 as the header, but did not create a multi-level header.\n",
        "* The first row of the loaded DataFrame contained redundant header information from the original file structure.\n",
        "* After cleaning, the DataFrame has 15 rows and the columns are named 'Measurement', 'Objective Measurement - Baseline', 'Objective Measurement - Chamber', 'Subjective Measurement - Baseline', and 'Subjective Measurement - Chamber'.\n",
        "* Only the 'Measurement' column has a significant number of non-null values (12 out of 15), while the other measurement columns each have only 5 non-null values.\n",
        "* All columns in the cleaned DataFrame are currently of the 'object' data type.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "* Convert the measurement columns to a numeric data type to enable quantitative analysis.\n",
        "* Investigate the reason for the high number of missing values in the measurement columns and determine how to handle them (e.g., imputation, removal of rows/columns)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "83ba23d6",
        "outputId": "c72678c7-da2e-4f29-a99b-0936ad99c046"
      },
      "source": [
        "measurements_to_keep = ['Duration (h)', '% Efficiency', 'Latency (h)', 'WASO **', 'Quality', 'Number of Awakenings']\n",
        "df_measurements = df[df['Measurement'].isin(measurements_to_keep)].copy()\n",
        "\n",
        "display(df_measurements)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            Measurement\n",
              "0          Duration (h)\n",
              "1          % Efficiency\n",
              "2           Latency (h)\n",
              "3               WASO **\n",
              "4               Quality\n",
              "5  Number of Awakenings"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf30492f-0454-4a5e-8ff0-67a58e8b0943\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Number of Awakenings</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf30492f-0454-4a5e-8ff0-67a58e8b0943')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf30492f-0454-4a5e-8ff0-67a58e8b0943 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf30492f-0454-4a5e-8ff0-67a58e8b0943');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d6a749aa-653b-4857-a774-d7b28d15805f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6a749aa-653b-4857-a774-d7b28d15805f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d6a749aa-653b-4857-a774-d7b28d15805f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b01fb31b-71a4-4ce3-a7f8-96bfab436ac8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_measurements')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b01fb31b-71a4-4ce3-a7f8-96bfab436ac8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_measurements');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_measurements",
              "summary": "{\n  \"name\": \"df_measurements\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Duration (h)\",\n          \"% Efficiency\",\n          \"Number of Awakenings\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<google.colab._quickchart_helpers.SectionTitle at 0x799af6b94800>"
            ],
            "text/html": [
              "<h4 class=\"colab-quickchart-section-title\">Categorical distributions</h4>\n",
              "<style>\n",
              "  .colab-quickchart-section-title {\n",
              "      clear: both;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "from matplotlib import pyplot as plt\n",
              "import seaborn as sns\n",
              "df_measurements.groupby('Measurement').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
              "plt.gca().spines[['top', 'right',]].set_visible(False)"
            ],
            "text/html": [
              "      <div class=\"colab-quickchart-chart-with-code\" id=\"chart-d12a1687-2915-4569-aed4-791e79bfe569\">\n",
              "        <img style=\"width: 180px;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAApoAAAGZCAYAAAApcJHMAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\n",
              "bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\n",
              "YQAAD2EBqD+naQAAMYdJREFUeJzt3Xl0Tff+//HXkRBjQqvVqh8xxZThGBJDccUU7VcNuS0VUUNJ\n",
              "qFZbqvi2VUWvooTSWzNFdVCue6tFzeUagjqGUiUV1NyWBGkSSfbvD7+eX0+F5pCPI/F8rLXXyt77\n",
              "sz/7fT7Lklc+ezg2y7IsAQAAALmsgKcLAAAAQP5E0AQAAIARBE0AAAAYQdAEAACAEQRNAAAAGEHQ\n",
              "BAAAgBEETQAAABhB0AQAAIARBE0AAAAYQdCER02ePNnTJQAAAEMImvCoY8eOeboEAABgCEETAAAA\n",
              "RhA0AQAAYARBEwAAAEYQNAEAAGAEQRMAAABGEDQBAABgBEETAAAARhA0AQAAYARBEwAAAEYQNAEA\n",
              "AGAEQRMAAABGEDQBAABgBEETAAAARnh7ugDc2678EKfTn0/2dBkAAOQrDz+Z6ekSJDGjCQAAAEMI\n",
              "mgAAADCCoAkAAAAjCJoAAAAwgqAJAAAAIwiaAAAAMIKgCQAAACMImgAAADCCoAkAAAAjCJoAAAAw\n",
              "gqAJAAAAIwiad6m33npLvXv3dq5v3rxZNptNGzZscG7r27ev3njjDed69+7d5evrqytXrrj0tXTp\n",
              "UtWtW1d2u13Vq1dX8+bNlZWVJUmyLEvjxo1T9erVVaNGDVWvXl3vvvuuLMvKti7LspSYmKgRI0Y4\n",
              "139vO2LECCUmJt7wWAAAcG8haN6lwsPDXULl+vXrVb9+/eu2NW/eXJKUnJysL774QiEhIVq8eLGz\n",
              "zenTpxUTE6OlS5fK4XDo+++/17vvviubzSZJeu211/Sf//xHmzdv1sGDB7V582YtW7ZMw4cPv66m\n",
              "n3/+Wd26dVN8fLwuXryoIUOGaMmSJVqyZImGDBmiixcvKj4+Xt26ddMvv/xiZmAAAECeYbOYfror\n",
              "paenq2TJkvrhhx9Urlw5tWjRQoMGDdK4ceO0YcMGnT59WpUqVdKFCxdUuHBhTZ8+XWvXrlWXLl00\n",
              "ceJEbdq0SZLkcDgUERGhI0eOqESJEi7nuHz5skqXLq1vv/1WNWvWdG4/cOCA6tatq59//lnFihVz\n",
              "OSY1NVWPPfaYdu3apbVr1yo0NFSStGPHDrVo0UJ169bVihUrVLhw4es+U1pamtLS0ly2DXzaT6N6\n",
              "8fcOAAC56eEnMz1dgiRmNO9ahQoVUqNGjbR+/XqlpaXp6NGjevzxx/XTTz8pNTVV69evV8OGDZ2B\n",
              "bvbs2erVq5fatm2rw4cP69ChQ5Kk4OBgNW7cWBUqVFDHjh01fvx4nTx5UtK1QOnj4+MSMiWpZs2a\n",
              "KlSokA4cOOCy/ZdfflFMTIz69eunnj176vPPP9fSpUu1dOlSff755+rZs6f69eunmJiYbGc0x4wZ\n",
              "Iz8/P5dl9xETowcAAO4GBM272O+Xz7dv366wsDBJUoMGDbR161Zt2LBB4eHhkqR9+/bp9OnTat26\n",
              "tQoWLKjo6GjNmTNHklSgQAEtWbJEW7ZsUZs2bfTf//5XtWrV0pEj1xLe75fQc+L+++/Xhx9+qLCw\n",
              "MJUqVUpjx45Vx44d1bFjR40dO1alSpVSWFiYPvzwQ91///3XHT9s2DAlJSW5LLWr3O4oAQCAuxWX\n",
              "zu9iW7ZsUXR0tLp3764yZcqob9++mjlzpk6cOKGPP/5Y8+bN06OPPqqXXnpJ8+bNU8mSJSVJV69e\n",
              "VVZWlk6cOCFvb+/r+m3Tpo1at26tmJgYty+d57bYtjaN6MHfOwAA5CYuneMvhYaG6ty5c/roo4/U\n",
              "rFkzSdLf/vY3ffLJJzp9+rTCwsKUnp6uhQsXatu2bUpMTFRiYqJOnjyp8uXL68svv9TJkyf13//+\n",
              "19nnhQsXdPToUVWuXFnFixfXiy++qNjYWP3888+Srl0ej42N1cCBA42HTAAAkL9dP92Fu0bBggXV\n",
              "uHFj7dmzR9WrV5ckBQQE6NKlS2rcuLEKFiyozz77TBUqVHDu/13Xrl01e/Zs2e12jRw5UkePHlXR\n",
              "okWVkZGh7t27q3379pKu3Tc5btw4NWrUSF5eXsrKytKzzz6rwYMH3/HPCwAA8hcuncOjuHQOAEDu\n",
              "49I5AAAA8jWCJgAAAIwgaAIAAMAIgiYAAACMIGgCAADACIImAAAAjCBoAgAAwAiCJgAAAIwgaAIA\n",
              "AMAIgiYAAACM4LvO4VHFAl7Ww09O9HQZAADAAGY0AQAAYARBEwAAAEYQNAEAAGAEQRMAAABGEDQB\n",
              "AABgBEETAAAARhA0AQAAYARBEwAAAEYQNAEAAGAEQRMAAABGEDQBAABgBEETAAAARhA0AQAAYARB\n",
              "EwAAAEYQNAEAAGAEQRMAAABGEDQBAABgBEETAAAARhA0AQAAYARBEwAAAEYQNAEAAGAEQRMAAABG\n",
              "EDQBAABgBEETAAAARhA0AQAAYARBEwAAAEYQNAEAAGAEQRMAAABGEDQBAABgBEETAAAARtgsy7I8\n",
              "XQTuXcGP+6pht1KeLgMAgHxlepdjni5BEjOaAAAAMISgCQAAACMImgAAADCCoAkAAAAjCJoAAAAw\n",
              "gqAJAAAAIwiaAAAAMIKgCQAAACMImgAAADCCoAkAAAAjCJp5XHp6uoYMGaIqVaqoRo0aCgwM1OzZ\n",
              "s2+rzw0bNshut0uSTp06pSZNmjj3jRgxQqmpqbfVPwAAuDd4e7oA3J4ePXooLS1Ne/bsUbFixZSY\n",
              "mKjHHntM6enp6tev3233X7ZsWW3atMm5/tZbb+mll15S4cKFb7tvAACQvzGjmYcdPnxYy5Yt04wZ\n",
              "M1SsWDFJkr+/vyZMmKBRo0a5zExK0v79++Xv7y9JysjIUEREhOrVq6datWopKipKV65cue4ciYmJ\n",
              "KlmypCSpb9++kqQmTZrIbrfr+PHjKlOmjFJSUpzto6Ki9MEHH5j5wAAAIE8haOZhu3fvVtWqVXX/\n",
              "/fe7bG/YsKFOnz6ts2fP3vBYLy8vLVq0SDt37tT+/fvl5+enKVOm3PR806ZNkyRt2rRJDodD5cuX\n",
              "V8uWLbVw4UJJ0tmzZ7VmzRp169Yt2+PT0tKUnJzssmRlWe58ZAAAkIcQNPOxIkWK3HCfZVmKi4tT\n",
              "7dq1FRwcrC+//FIOh8Ptc7z44ot6//33JUkzZ85Uly5dVLx48WzbjhkzRn5+fi7L+YR0t88JAADy\n",
              "BoJmHla7dm0dPnxYv/zyi8v2rVu3qlatWrrvvvuUmZnp3P7Hh3gWLVqkdevWaePGjdq3b59eeeWV\n",
              "W3rIJywsTEWLFtX69es1Y8YM9e/f/4Zthw0bpqSkJJflgcqF3D4nAADIGwiaeVjVqlX1xBNPKCYm\n",
              "xnmfZGJiooYMGaIJEyaoUqVKOnbsmM6fPy9JWrBggfPYCxcuqHTp0vL19dWlS5c0b968HJ2zRIkS\n",
              "SkpKctn24osv6plnnlGNGjUUEBBww2N9fHzk6+vrshQoYHPzUwMAgLyCoJnHzZ8/X5UrV1ZQUJCq\n",
              "Vq2qKlWqaPz48YqIiFDZsmX16quvKiwsTA0aNNB9993nPO6ZZ55RSkqKqlWrpscee8zlFUY3M2jQ\n",
              "ILVq1Up2u13nzp2TJD355JO6fPmynn/+eSOfEQAA5E02y7J4GiOfyMrK0tChQ7V69WqtXbvWJVia\n",
              "tHPnTkVFRen7779XgQLu/e0S/LivGnYrZagyAADuTdO7HPN0CZJ4j2a+UqBAAY0bN+6OnrN37976\n",
              "+uuvNWvWLLdDJgAAyN8Imrgts2bN8nQJAADgLsUUFAAAAIwgaAIAAMAIgiYAAACMIGgCAADACIIm\n",
              "AAAAjCBoAgAAwAiCJgAAAIwgaAIAAMAIXtgOj2pZvbcmdpno6TIAAIABzGgCAADACIImAAAAjCBo\n",
              "AgAAwAiCJgAAAIwgaAIAAMAIgiYAAACMIGgCAADACIImAAAAjCBoAgAAwAiCJgAAAIwgaAIAAMAI\n",
              "giYAAACMIGgCAADACIImAAAAjCBoAgAAwAiCJgAAAIwgaAIAAMAIgiYAAACMIGgCAADACIImAAAA\n",
              "jCBoAgAAwAiCJgAAAIwgaAIAAMAIgiYAAACMIGgCAADACIImAAAAjCBoAgAAwAiCJgAAAIwgaAIA\n",
              "AMAIgiYAAACM8PZ0Abi3Xflwp86sHO/pMgAAyFceOjDY0yVIYkYTAAAAhhA0AQAAYARBEwAAAEYQ\n",
              "NAEAAGAEQRMAAABGEDQBAABgBEETAAAARhA0AQAAYARBEwAAAEYQNAEAAGCE20Fzzpw5OdoGAACA\n",
              "e5vbQXPq1KnXbXv//fev2+bv76/q1asrIyPDua1evXrasGGDu6e8qR49emjSpEm52udf2bZtm4KC\n",
              "glS7dm2tWrUq2zZz586VzWbTpk2bcu28GzZskN1uz7X+Tp06pSZNmuRafwAAAH/kndOG8fHx2rp1\n",
              "q86fP6/33nvPuT0pKUlpaWnZHpOWlqbZs2crNjb29is1KCMjQ97eOR4Kffjhh4qKitKwYcNu2Gb2\n",
              "7Nlq0aKFZs+efdeGubJly+ZqEAYAAPijHM9onj59Wg6HQykpKdq9e7dz+fnnnzVv3rxsjxkxYoRG\n",
              "jRqllJSU6/b9eSbylVde0YgRI5zHderUSU888YQCAgLUtm1b7d+/XxEREQoICFCXLl2UlZXlPHbv\n",
              "3r1q1KiRAgIC1L17d/3222+SpEuXLqlPnz4KCwtTcHCwYmJilJ6eLklq1qyZBgwYoIYNG6p169bX\n",
              "1Xfu3DlFRkYqKChIgYGBmj59uiTpnXfe0aeffqqpU6fKbrfr4sWL1x176NAhHT16VPPnz9eyZcuU\n",
              "nJwsSYqKitKiRYskSf/85z9VqFAhXblyRZLUvHlzffPNN8rIyFBERITq1aunWrVqKSoqytnmj5KT\n",
              "k9W6dWuNHDlSkrRq1So1btxYdevWVVhYmNavXy/p2ixoYGCgnnvuOYWEhKhWrVrauXOnJCkxMVEl\n",
              "S5Z09mmz2fSPf/xDYWFhqlixoubOnevct2XLFtntdgUFBalXr14KCQlxzk6PHj1aNWrUkN1ul91u\n",
              "17Fjx66rFwAA3HtyHDTbt2+vuXPnauHChZo7d65zmTx5surVq5ftMSEhIQoPD1dcXJzbhe3cuVPz\n",
              "58/XoUOHdOnSJfXu3Vuff/65Dhw4oIMHD2rFihXOttu3b9eqVat08OBB/frrr87zDRo0SE2aNFF8\n",
              "fLz27NmjrKwsTZ482XncDz/8oG+++Ubr1q277vwvvPCCqlWrpn379mndunUaPXq0tm3bpqFDh6pd\n",
              "u3YaPHiwHA6HS1D73ezZs9WtWzeVLVtWzZs31yeffCJJatmypdasWSNJWr16terVq6eNGzcqJSVF\n",
              "e/bsUcOGDeXl5aVFixZp586d2r9/v/z8/DRlyhSX/k+cOKHw8HBFR0dr+PDh+vHHHzVixAh99dVX\n",
              "2rVrlxYtWqSoqCjnTPP333+v7t27a8+ePXrhhRf02muv3XDcfXx8FB8frxUrVmjAgAHKyMhQenq6\n",
              "OnfurLi4OO3bt0/dunXT3r17JUkXLlzQu+++q2+//VYOh0NbtmxRmTJlsu07LS1NycnJLkumlZVt\n",
              "WwAAkPfl/Hrx//PYY49p+/btSkhIcLn/8plnnsm2/ahRoxQWFqa+ffu6dZ7WrVurVKlSkqQ6derI\n",
              "x8dHJUqUkCTVrl1bhw8fdrbt1KmTc9+zzz6r9957T//7v/+rZcuWaevWrZo4caIk6bfffpOXl5fz\n",
              "uOjoaBUsWDDb869Zs0a7du2SJD344IOKjIzUmjVr1KBBg5vWnZGRofnz52vjxo2SpF69emnUqFGK\n",
              "iYlRy5Yt9dZbbykzM1MHDhzQ22+/rTVr1sjLy0thYWEqWLCgsrKyFBcXpy+//FIZGRlKSkpSo0aN\n",
              "nP2fPXtWTZs21axZs9SiRQtJ0sqVK3XkyBE1bdrU2a5AgQI6fvy4JKlKlSqqX7++JKlhw4Z69913\n",
              "b1h/165dJUnVq1eXt7e3zpw5o19//VXe3t4KDw+XJIWHh6ty5cqSJF9fX1WtWlXR0dFq3bq1/ud/\n",
              "/kflypXLtu8xY8borbfectlWt3D5m44nAADIu9wOms8995xWrlwpu93uDG02m+2GQdPf319RUVEa\n",
              "PXq064m9vZWZmelcT01NVfHixZ3rhQsXdv7s5eV13fofQ+6f2Ww2SZJlWVqyZIkCAgKybffH8/2V\n",
              "3/v8K8uXL9fFixcVERHhrOHUqVPav3+/AgMD5ePjo48++kh169ZVixYt9Pbbb8vLy8sZGhctWqR1\n",
              "69Zp48aN8vX11Xvvvecy41qyZElVqVJFy5cvV/PmzWWz2WRZllq1auW8LP9HJ0+edGvsctr29/Hw\n",
              "8vLStm3btGXLFm3YsEENGjTQxx9/nO19qcOGDdPAgQNdtg30f/yGtQAAgLzN7afOV69erQMHDmjp\n",
              "0qVavHixFi9erM8+++ymx7z++utauHChTp065dxWpUoVxcfHS5J++eUXffXVV+6W4vT555/r8uXL\n",
              "yszM1Ny5c9WyZUtJUocOHTR27FhnWLpw4YKOHDmSoz5btmypmTNnSpLOnz+vpUuXqlWrVn953OzZ\n",
              "szVp0iQlJiYqMTFRx44d08CBAzV79mxnv8OHD1fLli1VqlQpFSxYUIsXL3bWfOHCBZUuXVq+vr66\n",
              "dOnSdfe/+vj4aOnSpTp16pT69OmjrKwsRUREaM2aNc7L2ZKcY5sbqlWrpqtXrzpnaTdu3Ogcx0uX\n",
              "Luns2bNq0qSJ3njjDTVu3Fi7d+/Oth8fHx/5+vq6LF42XuUKAEB+5fZv+Ycfflg+Pj5uHVO6dGkN\n",
              "GDBAp0+fdm6LiYnR+fPnVaNGDT3zzDN/eUn6ZkJDQxUREaEaNWqoZMmSeumllyRJcXFxKlKkiOx2\n",
              "u4KDg9WiRQslJibmqM/33ntPBw8eVFBQkMLDw/Xaa685Lz/fyKlTp7R27Vo99dRTLtu7du2qhQsX\n",
              "Kj09XS1bttSxY8ecwbJly5a6cuWKQkJCJF27BSElJUXVqlXTY489lu3MYMGCBbVo0SJlZmaqa9eu\n",
              "8vf316JFixQbG6uQkBDVqFEjV1/55OPjo08++UQDBgxQUFCQ5s6dq2rVqqlkyZJKSkpyPjQVHBys\n",
              "q1evqnv37rl2bgAAkHfZLMuy3Dlg8ODB+vHHH9W5c2eXy6zt2rXL9eJw97h06ZLzPtgdO3aoXbt2\n",
              "SkhIUNGiRW+r39j7m+qtMk/kRokAAOD/eejAYE+XIOkW7tH8/dU4H3zwgXObzWYjaOZzS5YsUVxc\n",
              "nCzLkre3txYsWHDbIRMAAORvbs9oArmJGU0AAHLf3TKj6fY9mhkZGZowYYKee+45SVJCQkK276EE\n",
              "AADAvc3tS+fPP/+8MjMztXnzZknS/fffr86dOzsvqQMAAADSLQTNbdu2yeFwqHbt2pKuvdfx6tWr\n",
              "uV4YAAAA8ja3L53/8UlzScrMzHT53nEAAABAuoWgGRwcrIULFyorK0tHjhxR37591axZMwOlAQAA\n",
              "IC9zO2hOnDhRmzZt0pkzZ9SoUSMVKFBA77zzjonaAAAAkIfxeiN4FK83AgAg990trzdy+2EgSVqx\n",
              "YoUOHz7s/A5xSRo4cGCuFQUAAIC8z+2g2bVrVx04cEC1a9eWl5eXpGvfDATcimLd6+mhiXfHX10A\n",
              "ACB3uR00d+3ape+++84ZMgEAAIDsuP0wkL+/v9LS0kzUAgAAgHzE7RnNCRMmqGXLlmrWrJnLOzWH\n",
              "Dx+eq4UBAAAgb3M7aA4bNkyFChVSamoq3wgEAACAG3I7aB46dEiHDh0yUQsAAADyEbfv0axWrZqS\n",
              "k5NN1AIAAIB8xO0ZzSJFiqhOnTpq3bq1yz2aEydOzNXCAAAAkLe5HTRr1qypmjVrmqgFAAAA+Yjb\n",
              "QfPNN980UQcAAADyGbfv0Txx4oTatm0ru90uSXI4HIqLi8vtugAAAJDHuR00Y2Nj9fTTT8uyLElS\n",
              "YGCg5syZk+uFAQAAIG9zO2ieO3dO0dHRKlDg2qHe3t7y9nb7CjwAAADyObeDpre3t3M2U5IuXLjg\n",
              "sg4AAABItxA0n3rqKcXGxio5OVmzZs1Sq1at1Lt3bxO1AQAAIA9z+5r3oEGD9PHHHyspKUlff/21\n",
              "Bg4cqKioKBO1AQAAIA9zK2hmZmYqIiJCa9asUZcuXUzVBAAAgHzArUvnXl5eSklJUVZWlql6AAAA\n",
              "kE+4fek8NDRUbdu2VXR0tIoXL+7c3q5du1wtDAAAAHmb20Fz7969kqSZM2c6t9lsNoImAAAAXLgd\n",
              "NNevX2+iDgAAAOQzbgfNb775JtvtTZs2ve1iAAAAkH/c0uuNfpeamqpDhw4pMDBQ3377ba4WBgAA\n",
              "gLzN7aC5Y8cOl/X4+HjNmzcvt+oBAABAPuH2NwP9WVhYmLZu3ZobtQAAACAfueWnzqVrL3Dfvn27\n",
              "rl69mqtFAQAAIO9zO2i2b9/+/x/s7a0qVaroww8/zNWiAAAAkPe5HTSPHj1qog4AAADkM27fo7lj\n",
              "xw6lpKRIkj777DO98sorOnXqVK4XBgAAgLzN7aDZu3dv+fj46PDhw3rttddUsGBB9ezZ00RtAAAA\n",
              "yMPcDppeXl7y8vLSihUr1K9fP40ZM0bnzp0zURsAAADyMLfv0UxLS9PZs2f1xRdfaOzYsZKuPX0O\n",
              "3IpvNvyoV19e7ukyAADIV8bFtfV0CZJuYUbz5ZdfVrVq1eTn56c6deooISFBpUqVMlEbAAAA8jCb\n",
              "ZVnW7XSQmZmpzMxMFSpUKLdqwj2kXp0Oav633p4uAwCAfOVumdF0+9K5JJ06dUr79+9Xamqqc1u7\n",
              "du1yrSgAAADkfW4HzTlz5mjkyJH69ddfVbVqVe3Zs0cNGjQgaAIAAMCF2/doxsXFaffu3apcubJ2\n",
              "7dqldevWKSAgwERtAAAAyMPcDpqFChVSqVKllJGRIUlq2rSpHA5HbtcFAACAPM7tS+c+Pj6yLEsB\n",
              "AQGaNGmSKlSooMuXL5uoDQAAAHmY20Fz9OjRSk5O1rhx49S3b19dvHhR//znP03UBgAAgDzM7aDZ\n",
              "vHlzSZKfn59Wr16d6wUBAAAgf3D7Hs0TJ06obdu2stvtkiSHw6G4uLjcrgsAAAB5nNtBMzY2Vk8/\n",
              "/bR+f897YGCg5syZk+uFAQAAIG9zO2ieO3dO0dHRKlDg2qHe3t7y9r6l977fE/z9/d1+Kn/SpEk6\n",
              "c+aMmYLclJKSonr16unSpUuSbv55XnnlFS1atOgOVgcAAO5mbgdNb29v/fFbKy9cuKDb/BZL/Mnd\n",
              "FDSnTp2q9u3bq0SJEn/Z9tVXX9WIESOUmZl5ByoDAAB3O7eD5lNPPaXY2FglJydr1qxZatWqlZ59\n",
              "9lkTteVrEydOVGhoqOx2u0JDQ7V161ZJ0siRI3Xq1Cl17txZdrtdDodDV69e1dChQxUWFia73a5O\n",
              "nTrpwoULkqQePXooNjZWLVq0UEBAgCIjI5Weni5JSk9P1+DBgxUYGKiQkBC1adNGkhQUFKQtW7Y4\n",
              "a5kxY4Y6d+6cbZ3Tp09XVFSUy7alS5eqYcOGqlixokaPHu3c/uCDD6py5cr6+uuvs+0rLS1NycnJ\n",
              "LouVlXWLIwgAAO52bgfNQYMGKTw8XPXq1dPq1as1aNAgvfDCCyZqy9e6deumHTt2yOFwaMqUKerZ\n",
              "s6ckafjw4Spbtqw+/fRTORwO2e12jR8/XsWKFVN8fLwcDoeCgoL0+uuvO/tyOBz64osvdPDgQZ09\n",
              "e1ZLliyRJI0ZM0Y//PCDdu3apT179mjBggWSpAEDBmjq1KnO499//309//zz19V44sQJJSUlqXLl\n",
              "yi7bL168qK1bt2rHjh0aP368Tp486dzXsGFDrV27NtvPPGbMGPn5+bksp8/+cIsjCAAA7nY5vrly\n",
              "4MCBLutly5aVJO3YsUM7duzQxIkTc7eyfG737t16++239csvv8jb21uHDh3Sb7/9piJFilzXdtmy\n",
              "ZUpKSnIGyPT0dPn7+zv3d+zYUUWLFpUkhYWFKSEhQZK0fPlyjR07Vj4+PpKkBx54QJIUHR2t4cOH\n",
              "6+zZszp8+LBsNpuaNGly3Xl/+uknlSlT5rrtv89wli5dWpUqVdLRo0f1yCOPSJIeeughHThwINvP\n",
              "PGzYsOv+HYU3jb7xIAEAgDwtx0Fz0qRJCg0NVZs2bZwPAuHWpKenKzIyUuvXr1doaKiSk5Pl5+en\n",
              "tLS0bIOmZVmaMmWKWrdunW1/hQsXdv7s5eXl/HrQGylSpIh69Oih6dOn6+DBg+rfv3+27YoWLarU\n",
              "1FS3zpeamprtZ5CufavU76H3dzb+LQEAkG/lOGiuXbtWc+bM0aJFi9SpUyf16tXrukuqyJnU1FSl\n",
              "p6erfPnykqQpU6a47Pf19VVSUpJzvUOHDoqLi1Pjxo1VtGhRpaSk6OjRo6pVq9ZNz9OuXTtNnjxZ\n",
              "jz76qHx8fHT+/HnnrGb//v3VoEEDXb16VbNnz872+GrVquncuXM3nGnNzsGDBxUSEpKjtgAAIH/L\n",
              "8XRSeHi4FixYoF27dql8+fLq2rWrwsPDtX37dpP15QsREREqV66cc0lOTtbo0aMVFhamunXrqlCh\n",
              "Qi7tBwwYoD59+jgfBhoyZIhCQ0NVv359BQcHq0GDBjl6ZdKQIUMUEBCgOnXqyG63q3v37s595cqV\n",
              "U+3atRUdHe287P5nhQsXVuvWrbVu3bocfU7LsrR27Vp17NgxR+0BAED+ZrNu4d1EZ86c0dy5c/Xe\n",
              "e+/pnXfecQkwyBuuXLmiatWqadOmTapYseIN28XHx2vkyJFavnz5X/a5cuVKLVy4UAsXLsxxHfXq\n",
              "dFDzv/XOcXsAAPDXxsW19XQJktyY0czMzNS//vUvtW3bVq1atZKXl5e+/fZbQmYeNG3aNFWvXl3P\n",
              "PffcTUOmdO3hosjISOcL228mKSlJ48aNy60yAQBAHpfjGc2HHnpI5cuXV8+ePfXoo49etz84ODjX\n",
              "i0P+x4wmAAC5726Z0czxw0CFCxfW+fPnNW7cONlsNpdvA7LZbPrxxx+NFAgAAIC8KcdBMzEx0WAZ\n",
              "AAAAyG94iSEAAACMIGgCAADACIImAAAAjCBoAgAAwAiCJgAAAIwgaAIAAMCIHL/eCDChabNKGjfx\n",
              "7nipLAAAyF3MaAIAAMAIgiYAAACMIGgCAADACIImAAAAjCBoAgAAwAiCJgAAAIwgaAIAAMAIgiYA\n",
              "AACMIGgCAADACIImAAAAjCBoAgAAwAiCJgAAAIwgaAIAAMAIgiYAAACMIGgCAADACIImAAAAjCBo\n",
              "AgAAwAiCJgAAAIwgaAIAAMAIgiYAAACMIGgCAADACIImAAAAjCBoAgAAwAiCJgAAAIwgaAIAAMAI\n",
              "giYAAACMIGgCAADACIImAAAAjCBoAgAAwAibZVmWp4vAvatnLZuGhfL3DgAAuSlgXqanS5DEjCYA\n",
              "AAAMIWgCAADACIImAAAAjCBoAgAAwAiCJgAAAIwgaAIAAMAIgiYAAACMIGgCAADACIImAAAAjCBo\n",
              "AgAAwAiCJgAAAIwgaAIAAMAIgmYu8/f3V7Vq1RQSEqIqVaqoffv22rJli5FzTZo0SWfOnHGuT5s2\n",
              "TePHj8/18zz11FPaunWrJKlHjx6aNGlStu2WL1+umJiYXD8/AADImwiaBnz66afas2ePjhw5ou7d\n",
              "u+vxxx/X9u3b3e4nMzPzpvv/HDT79u2rwYMHu32em4mPj9evv/6qhg0b/mXbtm3bateuXTp8+HCu\n",
              "1gAAAPImgqZhkZGR6tu3r959911J0ogRI/TSSy8590+dOlU9evSQJM2bN0/h4eH6+9//rqCgIMXH\n",
              "x2vixIkKDQ2V3W5XaGioc2Zx5MiROnXqlDp37iy73S6Hw+HSd2ZmpgYPHqzAwEAFBgbqhRdeUHp6\n",
              "uqRrs5KxsbFq0aKFAgICFBkZ6dz3Z9OnT1dUVJTLtoMHD97w2E6dOmnWrFnZ9pWWlqbk5GSXJTPL\n",
              "7SEFAAB5BEHzDqhfv76+++67HLXdvn27/vGPf2jfvn1q2LChunXrph07dsjhcGjKlCnq2bOnJGn4\n",
              "8OEqW7asPv30UzkcDtntdpd+ZsyYoR07dmjXrl1yOBxKSEhQXFycc7/D4dAXX3yhgwcP6uzZs1qy\n",
              "ZEm29WzYsEH169d32XazYxs2bKi1a9dm29eYMWPk5+fnsuz9OUfDAgAA8iCC5h1gWVaO2zZq1EjV\n",
              "qlVzru/evVt/+9vfFBgYqL59++rQoUP67bff/rKfNWvWqEePHvLx8ZG3t7f69Omj1atXO/d37NhR\n",
              "RYsWlZeXl8LCwpSQkJBtPz/99JPKlCnjsu1mxz700EP66aefsu1r2LBhSkpKclmCS//lRwEAAHmU\n",
              "t6cLuBfs2LFDgYGBkiRvb2+Xey9TU1Nd2hYvXtz5c3p6uiIjI7V+/XqFhoYqOTlZfn5+SktLU5Ei\n",
              "RdyqwWazuawXLlzY+bOXl5cyMjKyPa5o0aLX1XizY1NTU29Ym4+Pj3x8fFy2efGnDgAA+Ra/5g37\n",
              "97//rQ8++ECDBg2SJFWpUkU7d+5UZmamUlJSbnjJWroW2tLT01W+fHlJ0pQpU1z2+/r6KikpKdtj\n",
              "W7Zsqfnz5ys9PV0ZGRmaNWuWWrdu7Xb9wcHBOnToUI7bHzx4UCEhIW6fBwAA5D/MaBrQuXNnFS5c\n",
              "WFeuXFHNmjX11VdfOe9zjIyM1OLFi1WjRg2VK1dOtWvXVkpKSrb9+Pr6avTo0QoLC1Pp0qX19NNP\n",
              "u+wfMGCA+vTpo6JFi2revHku+2JiYpSQkKA6depIkpo1a+byEFJOPfnkk1q1apVatmyZo/YrV67U\n",
              "k08+6fZ5AABA/mOz3LmBEPecy5cvq1GjRtq6dauKFSt207Y///yzmjdvrp07d6pQoUI56r9nLZuG\n",
              "hTKxDgBAbgqYd/NXJN4p/IbHTRUvXlxxcXE6evToX7ZNSEjQtGnTchwyAQBA/salc/ylFi1a5Kjd\n",
              "n1+DBAAA7m3MaAIAAMAIgiYAAACMIGgCAADACIImAAAAjCBoAgAAwAiCJgAAAIwgaAIAAMAI3qMJ\n",
              "jyoV8bICJk70dBkAAMAAZjQBAABgBEETAAAARhA0AQAAYARBEwAAAEYQNAEAAGAEQRMAAABGEDQB\n",
              "AABgBEETAAAARhA0AQAAYARBEwAAAEYQNAEAAGAEQRMAAABGEDQBAABgBEETAAAARhA0AQAAYARB\n",
              "EwAAAEYQNAEAAGAEQRMAAABGEDQBAABgBEETAAAARhA0AQAAYARBEwAAAEYQNAEAAGAEQRMAAABG\n",
              "EDQBAABgBEETAAAARhA0AQAAYARBEwAAAEYQNAEAAGAEQRMAAABG2CzLsjxdBO5dxSNCVfLpFp4u\n",
              "AwCAfOWnnu94ugRJzGgCAADAEIImAAAAjCBoAgAAwAiCJgAAAIwgaAIAAMAIgiYAAACMIGgCAADA\n",
              "CIImAAAAjCBoAgAAwAiCJgAAAIwgaAIAAMAIgmYuuXr1qjp06KCQkBBFRkYqIyNDkpSamqqmTZvq\n",
              "woULNzy2WbNmqlixoux2u3NZtWqVJGnbtm0KCgpS7dq1tWrVquvWH3/8cR06dOimtQ0fPlwfffRR\n",
              "7n1YAACAHPD2dAH5xapVq3Tfffdp2bJl6tWrl1auXKm2bdtq1KhRev7551WqVKmbHh8XF6cOHTpc\n",
              "t/3DDz9UVFSUhg0bJknq16+fy3pERMRf1jZy5Ej3PxAAAMBtYkYzlxQsWFApKSmSpJSUFBUqVEh7\n",
              "9+7V999/r06dOt1Sn++8844+/fRTTZ06VXa7/br1ixcvyt/fXw6HQ5J08uRJPfnkkwoKClJwcLDe\n",
              "eOMNSVKPHj00adIkSddmXocOHaqwsDDZ7XZ16tTJOdvao0cPxcbGqkWLFgoICFBkZKTS09MlSenp\n",
              "6Ro8eLACAwMVEhKiNm3aSJKCgoK0ZcsWZ80zZsxQ586ds/08aWlpSk5OdlmUad3S2AAAgLsfQTOX\n",
              "tGrVSiVKlFBISIj8/PzUvHlzDRw4UJMnT87R8S+//LLLpfOEhAQNHTpU7dq10+DBg+VwOK5bL1my\n",
              "pEsf0dHRqlu3rvbt26e9e/dqwIAB151n/PjxKlasmOLj4+VwOBQUFKTXX3/dud/hcOiLL77QwYMH\n",
              "dfbsWS1ZskSSNGbMGP3www/atWuX9uzZowULFkiSBgwYoKlTpzqPf//99/X8889n+xnHjBkjPz8/\n",
              "lyX96OkcjQ8AAMh7uHSeSwoUKKCZM2c61ydNmqQOHTooIyNDUVFRSktLU//+/dW8efNsj7/RpfOc\n",
              "unz5sjZv3uy8t1OSHnjggevaLVu2TElJSc4AmZ6eLn9/f+f+jh07qmjRopKksLAwJSQkSJKWL1+u\n",
              "sWPHysfHx6Xv6OhoDR8+XGfPntXhw4dls9nUpEmTbGscNmyYBg4c6LKtbGT24wEAAPI+gqYBx44d\n",
              "01dffaWVK1eqe/fuiomJUd26ddWgQQN99913Hq3NsixNmTJFrVu3znZ/4cKFnT97eXk5H2q6kSJF\n",
              "iqhHjx6aPn26Dh48qP79+9+wrY+PjzOo/v+T2HJePAAAyFO4dG7Aiy++qLi4OBUoUEBXrlyRzWZz\n",
              "/mxK8eLF1bRpU02YMMG57fz589e169Chg+Li4lzuJ81J+G3Xrp0mT56stLS06/ru37+/ZsyYoXXr\n",
              "1qlr1663+1EAAEA+QdDMZYsWLVJISIhq1aolSRo6dKgGDBigevXqOR/Oyc6f79G8ldcRLViwQDt3\n",
              "7lStWrVkt9td7p383ZAhQxQaGqr69esrODhYDRo0cD5MdDNDhgxRQECA6tSpI7vdru7duzv3lStX\n",
              "TrVr11Z0dLTzsjsAAIDNsiwe+8VtuXLliqpVq6ZNmzapYsWKbh1bPCJUJZ9uYagyAADuTT/1fMfT\n",
              "JUhiRhO3adq0aapevbqee+45t0MmAADI35jRhEcxowkAQO5jRhMAAAD5GkETAAAARhA0AQAAYARB\n",
              "EwAAAEYQNAEAAGAEQRMAAABGEDQBAABgBEETAAAARnh7ugDc22JqNdHEu+SlsgAAIHcxowkAAAAj\n",
              "CJoAAAAwgqAJAAAAIwiaAAAAMIKgCQAAACMImgAAADCCoAkAAAAjCJoAAAAwgqAJAAAAIwiaAAAA\n",
              "MIKgCQAAACMImgAAADCCoAkAAAAjCJoAAAAwwtvTBeDelZaWphUrVigzM1NeXl6eLueekpmZqfj4\n",
              "eIWFhTH2dxDj7jmMvWcw7p5xJ8a9QoUKevHFF/+ync2yLMtIBcBfSE5Olp+fn5KSkuTr6+vpcu4p\n",
              "jL1nMO6ew9h7BuPuGXfTuHPpHAAAAEYQNAEAAGAEQRMAAABGEDThMT4+PnrzzTfl4+Pj6VLuOYy9\n",
              "ZzDunsPYewbj7hl307jzMBAAAACMYEYTAAAARhA0AQAAYARBEwAAAEYQNGHc4cOH1ahRIwUEBCg0\n",
              "NFTfffddtu1mz56tqlWrqnLlyurTp4+uXr16hyvNX3Iy7uvWrVNYWJhq1qypWrVq6dVXX1VWVpYH\n",
              "qs1fcvpvXpIsy1Lz5s1VsmTJO1dgPpXTcd+3b5+aNWumGjVqqEaNGlq6dOkdrjT/ycnYZ2VlaeDA\n",
              "gapZs6aCg4MVHh6uI0eOeKDa/GPAgAHy9/eXzWaTw+G4YTuP/n61AMPCw8OtuXPnWpZlWYsXL7bq\n",
              "1at3XZsff/zRevjhh63Tp09bWVlZ1hNPPGFNnTr1Dleav+Rk3L/99lsrISHBsizL+u2336xHH33U\n",
              "eQxuXU7G/ncTJkywevfubfn5+d2Z4vKxnIz7lStXrIoVK1qbNm2yLMuyMjIyrHPnzt3JMvOlnIz9\n",
              "v/71LyssLMxKT0+3LMuyRo0aZT311FN3ssx8Z+PGjdaJEyesChUqWLt37862jad/vxI0YdTZs2et\n",
              "EiVKWFevXrUsy7KysrKsMmXKWIcPH3ZpN27cOCs2Nta5/uWXX1qPPvroHa01P8npuP9Z//79rTff\n",
              "fPMOVJh/uTP2+/fvt5o0aWIdOXKEoHmbcjruM2fOtLp06eKJEvOtnI79smXLrJCQECs5OdnKysqy\n",
              "Bg8ebL388sueKDnfuVnQ9PTvVy6dw6gTJ07o4Ycflre3tyTJZrOpfPnyOn78uEu748ePq0KFCs51\n",
              "f3//69og53I67n905swZff7552rbtu2dKjNfyunYX716VX369NH06dPl5eXliVLzlZyO+4EDB+Tj\n",
              "46O2bdvKbrfrmWee0fnz5z1Rcr6R07F/4okn1KxZMz300EN6+OGHtXbtWo0cOdITJd9TPP37laAJ\n",
              "QMnJyXriiSf06quvql69ep4u557w1ltvKTIyUjVq1PB0KfeUjIwMrVmzRtOnT9fu3bv1yCOPqF+/\n",
              "fp4u656wc+dO7d+/XydPntSpU6fUokUL9e3b19NlwTCCJoz6P//n/+j06dPKyMiQdO3Bh+PHj6t8\n",
              "+fIu7cqXL69jx4451xMTE69rg5zL6bhL0qVLl9SmTRu1b99eAwcOvNOl5js5HfuNGzdqypQp8vf3\n",
              "V+PGjZWcnCx/f39m126RO//XhIeH65FHHpHNZlN0dLS2bdvmiZLzjZyO/fz5850PvhUoUEDdu3fX\n",
              "+vXrPVHyPcXTv18JmjDqwQcfVJ06dbRw4UJJ0pIlS1SuXDlVqVLFpd3f//53/ec//9GZM2dkWZam\n",
              "TZump59+2hMl5ws5HffLly+rTZs2atOmjV5//XVPlJrv5HTsN23apGPHjikxMVGbN2+Wr6+vEhMT\n",
              "9cADD3ii7Dwvp+PeqVMn7dixQ8nJyZKkr776SiEhIXe83vwkp2NfqVIlrVu3Tunp6ZKk5cuXKzAw\n",
              "8I7Xe6/x+O/XO3Y3KO5Z33//vdWgQQOratWqVt26da29e/dalmVZzz77rPXvf//b2W7GjBlWpUqV\n",
              "rEqVKlm9evVyPpmIW5OTcR89erTl7e1thYSEOJfRo0d7sux8Iaf/5n939OhRHgbKBTkd9/nz51u1\n",
              "atWygoKCrDZt2ljHjx/3VMn5Rk7GPjU11erdu7dVvXp1KygoyGrVqpXzrRe4NTExMdYjjzxieXl5\n",
              "WQ8++KBVuXJly7Lurt+vfNc5AAAAjODSOQAAAIwgaAIAAMAIgiYAAACMIGgCAADACIImAAAAjCBo\n",
              "AgAAwAiCJgAAAIwgaAIAAMAIgiYAAACMIGgCAADACIImAAAAjPi/XlLEUw0myKYAAAAASUVORK5C\n",
              "YII=\n",
              "\">\n",
              "      </div>\n",
              "      <script type=\"text/javascript\">\n",
              "        (() => {\n",
              "          const chartElement = document.getElementById(\"chart-d12a1687-2915-4569-aed4-791e79bfe569\");\n",
              "          async function getCodeForChartHandler(event) {\n",
              "            const chartCodeResponse =  await google.colab.kernel.invokeFunction(\n",
              "                'getCodeForChart', [\"chart-d12a1687-2915-4569-aed4-791e79bfe569\"], {});\n",
              "            const responseJson = chartCodeResponse.data['application/json'];\n",
              "            await google.colab.notebook.addCell(responseJson.code, 'code');\n",
              "          }\n",
              "          chartElement.onclick = getCodeForChartHandler;\n",
              "        })();\n",
              "      </script>\n",
              "      <style>\n",
              "        .colab-quickchart-chart-with-code  {\n",
              "            display: block;\n",
              "            float: left;\n",
              "            border: 1px solid transparent;\n",
              "        }\n",
              "\n",
              "        .colab-quickchart-chart-with-code:hover {\n",
              "            cursor: pointer;\n",
              "            border: 1px solid #aaa;\n",
              "        }\n",
              "      </style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "df_measurements.groupby('Measurement').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "zlfGbpoN48p4",
        "outputId": "2cd4c342-49e0-4bba-ec45-259782682d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "c816d478",
        "outputId": "cb4e448c-4ff4-4306-95a1-9c9b9c72f11d"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# File paths for the EEG and ECG data (assuming they are in the unzipped_data directory)\n",
        "# Based on previous steps, we know the sleep data file path. We need to find paths for EEG and ECG.\n",
        "# Let's assume a directory structure or naming convention based on the task description.\n",
        "# If the file names are not immediately obvious from the unzip output, further inspection might be needed.\n",
        "# However, based on the previous code cell that tried to load HRV and ECG files from Google Drive,\n",
        "# let's assume those filenames are correct for the unzipped data as well, potentially in subdirectories.\n",
        "\n",
        "# Based on the unzip output, the structure seems to be /content/unzipped_data/<dataset_name>/<filename>\n",
        "# The previous code attempted to load HRV_dataset_file.xls and ECG_dataset_file.xls.\n",
        "# Let's assume these exist within the relevant dataset folders if not directly in unzipped_data.\n",
        "# Since the task mentions HC2S, SHARP-1, and SHARP-2, and the unzip output shows JMGROUNDLMLSTP34_115 which seems to be related to sleep,\n",
        "# we need to figure out which unzipped files correspond to EEG/ECG for the mentioned datasets.\n",
        "# Let's check the unzipped folders for potential EEG/ECG files.\n",
        "\n",
        "# Given the available files from the unzip output, it seems like the provided zip file\n",
        "# might not contain all the specified datasets (HC2S, SHARP-1, SHARP-2) or the files are named differently.\n",
        "# However, the previous unsuccessful Google Drive mounting code did list 'HRV_dataset_file.xls' and 'ECG_dataset_file.xls'.\n",
        "# It's possible these were intended to be part of the data.\n",
        "# Let's re-examine the unzip output and the original problem description. The original problem description\n",
        "# says \"Load the EEG and ECG data from the specified NASA datasets (HC2S, SHARP-1, SHARP-2)\".\n",
        "# The unzip output shows files related to \"JMGROUNDLMLSTP34\". It does not explicitly mention HC2S, SHARP-1, or SHARP-2.\n",
        "# The previous cells attempted to load files named 'HRV_dataset_file.xls' and 'ECG_dataset_file.xls',\n",
        "# which were assumed to be in a 'NASA_LSDA' folder on Google Drive, but were not found.\n",
        "# The current available files are within '/content/unzipped_data/' and include 'JMGROUNDLMLSTP34_115.xls',\n",
        "# 'JMGROUNDLMLSTP34_1.xls', and .tif files. None of these are explicitly named 'EEG' or 'ECG' or relate to HC2S, SHARP-1, SHARP-2.\n",
        "\n",
        "# There seems to be a mismatch between the task description (HC2S, SHARP-1, SHARP-2 EEG/ECG data)\n",
        "# and the available data from the unzipped file (JMGROUNDLMLSTP34 sleep data and .tif files).\n",
        "# Since I cannot ask the user for clarification and must work with the available data,\n",
        "# I will proceed assuming that the 'JMGROUNDLMLSTP34_115.xls' file, which was used in previous steps and seems to contain sleep data, is the\n",
        "# relevant file for this task, even though the task specifies EEG/ECG and different dataset names.\n",
        "# It's possible the task description is aspirational and the provided data is a sample.\n",
        "\n",
        "# Based on the file names available in the unzipped directory and the previous successful loading of\n",
        "# 'JMGROUNDLMLSTP34_115.xls', I will attempt to load this file again.\n",
        "# I will also check for 'JMGROUNDLMLSTP34_1.xls' to see if it contains similar data, although it's not explicitly mentioned as EEG/ECG.\n",
        "# I will ignore the .tif files as they are image files and not data tables.\n",
        "\n",
        "excel_file_path_115 = '/content/unzipped_data/JMGROUNDLMLSTP34_115/JMGROUNDLMLSTP34_115.xls'\n",
        "excel_file_path_1 = '/content/unzipped_data/JMGROUNDLMLSTP34_1/JMGROUNDLMLSTP341.xls'\n",
        "\n",
        "# Initialize a dictionary to store the dataframes\n",
        "dataframes = {}\n",
        "\n",
        "try:\n",
        "    # Load the 115 file. Use header=9 as determined in previous steps for the relevant data.\n",
        "    df_115 = pd.read_excel(excel_file_path_115, header=9, engine='xlrd')\n",
        "    # Apply the same cleaning steps as before (rename columns, drop first row, drop columns with high missing values)\n",
        "    new_column_names = ['Measurement', 'Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                        'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "    df_115.columns = new_column_names\n",
        "    df_115 = df_115.iloc[1:].reset_index(drop=True)\n",
        "    # Convert measurement columns to numeric, coercing errors\n",
        "    measurement_columns = ['Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                           'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "    for col in measurement_columns:\n",
        "        df_115[col] = pd.to_numeric(df_115[col], errors='coerce')\n",
        "    # Drop columns with 100% missing values\n",
        "    missing_percentage_115 = (df_115.isnull().sum() / len(df_115)) * 100\n",
        "    columns_to_drop_115 = missing_percentage_115[missing_percentage_115 == 100].index.tolist()\n",
        "    df_115 = df_115.drop(columns=columns_to_drop_115)\n",
        "\n",
        "\n",
        "    dataframes['JMGROUNDLMLSTP34_115'] = df_115\n",
        "\n",
        "    print(\"Loaded and cleaned JMGROUNDLMLSTP34_115.xls:\")\n",
        "    display(df_115.head())\n",
        "    df_115.info()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading or cleaning {excel_file_path_115}: {e}\")\n",
        "\n",
        "try:\n",
        "    # Load the 1 file. Let's assume it has a similar structure and use header=9 as a starting point.\n",
        "    df_1 = pd.read_excel(excel_file_path_1, header=9, engine='xlrd')\n",
        "    # Apply similar cleaning steps\n",
        "    new_column_names = ['Measurement', 'Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                        'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "    df_1.columns = new_column_names\n",
        "    df_1 = df_1.iloc[1:].reset_index(drop=True)\n",
        "    # Convert measurement columns to numeric, coercing errors\n",
        "    measurement_columns = ['Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                           'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "    for col in measurement_columns:\n",
        "        df_1[col] = pd.to_numeric(df_1[col], errors='coerce')\n",
        "    # Drop columns with 100% missing values\n",
        "    missing_percentage_1 = (df_1.isnull().sum() / len(df_1)) * 100\n",
        "    columns_to_drop_1 = missing_percentage_1[missing_percentage_1 == 100].index.tolist()\n",
        "    df_1 = df_1.drop(columns=columns_to_drop_1)\n",
        "\n",
        "    dataframes['JMGROUNDLMLSTP34_1'] = df_1\n",
        "\n",
        "    print(\"\\nLoaded and cleaned JMGROUNDLMLSTP34_1.xls:\")\n",
        "    display(df_1.head())\n",
        "    df_1.info()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading or cleaning {excel_file_path_1}: {e}\")\n",
        "\n",
        "# Check if any dataframes were loaded\n",
        "if not dataframes:\n",
        "    print(\"\\nNo dataframes were successfully loaded.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded and cleaned JMGROUNDLMLSTP34_115.xls:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement\n",
              "0  Duration (h)\n",
              "1  % Efficiency\n",
              "2   Latency (h)\n",
              "3       WASO **\n",
              "4       Quality"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81b6325e-9b49-48e0-bd75-cb93f0fc70ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81b6325e-9b49-48e0-bd75-cb93f0fc70ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81b6325e-9b49-48e0-bd75-cb93f0fc70ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81b6325e-9b49-48e0-bd75-cb93f0fc70ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d52e5514-507f-4aed-b58c-4ef83d90ab2d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d52e5514-507f-4aed-b58c-4ef83d90ab2d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d52e5514-507f-4aed-b58c-4ef83d90ab2d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\\\nNo dataframes were successfully loaded\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"% Efficiency\",\n          \"Quality\",\n          \"Latency (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15 entries, 0 to 14\n",
            "Data columns (total 1 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Measurement  12 non-null     object\n",
            "dtypes: object(1)\n",
            "memory usage: 252.0+ bytes\n",
            "\n",
            "Loaded and cleaned JMGROUNDLMLSTP34_1.xls:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                     Measurement  Subjective Measurement - Chamber\n",
              "0            Parameters Measured                               NaN\n",
              "1  Melatonin acrophase, saliva\\n                               NaN\n",
              "2                 Hardware Items                               NaN\n",
              "3          Saliva Collection Kit                             125.0\n",
              "4    Table of Sessions Performed                               NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3675f213-a6c0-4148-bb15-2af8c3dbf4da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Subjective Measurement - Chamber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Parameters Measured</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Melatonin acrophase, saliva\\n</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hardware Items</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Saliva Collection Kit</td>\n",
              "      <td>125.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Table of Sessions Performed</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3675f213-a6c0-4148-bb15-2af8c3dbf4da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3675f213-a6c0-4148-bb15-2af8c3dbf4da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3675f213-a6c0-4148-bb15-2af8c3dbf4da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-39b7ee24-97fc-4af1-a796-8b9c0c88941b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39b7ee24-97fc-4af1-a796-8b9c0c88941b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-39b7ee24-97fc-4af1-a796-8b9c0c88941b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\\\nNo dataframes were successfully loaded\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Melatonin acrophase, saliva\\n\",\n          \"Table of Sessions Performed\",\n          \"Hardware Items\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 125.0,\n        \"max\": 125.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          125.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28 entries, 0 to 27\n",
            "Data columns (total 2 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   Measurement                       27 non-null     object \n",
            " 1   Subjective Measurement - Chamber  1 non-null      float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 580.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "df_measurements.groupby('Measurement').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "wpL24t9c46Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "9bcbe996",
        "outputId": "0a179b3c-0fd6-4a2f-9577-fd7e52fedb3a"
      },
      "source": [
        "display(df['Measurement'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Measurement\n",
              "Duration (h)                                                                                                                   1\n",
              "% Efficiency                                                                                                                   1\n",
              "Latency (h)                                                                                                                    1\n",
              "WASO **                                                                                                                        1\n",
              "Quality                                                                                                                        1\n",
              "Number of Awakenings                                                                                                           1\n",
              "*  Values are Mean SEM of 8 subjects                                                                                           1\n",
              "**  Wake after sleep onset                                                                                                     1\n",
              "Reference:                                                                                                                     1\n",
              "Putcha L, Nimmagudda R, and Rivera C. Assessment Of Sleep Dynamics In A Simulated Space Station Environment                    1\n",
              "In : Lane HW, Sauer RL, and Feeback DL, eds. Isolation: NASA Experiments in Closed-Environment Living.                         1\n",
              "American Astronautical Society Science and Technology Series; Vol 104. San Diego, CA. Univelt, Incorporated; 2002: 141-154.    1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Measurement</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Duration (h)</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>% Efficiency</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latency (h)</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WASO **</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Quality</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of Awakenings</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>*  Values are Mean SEM of 8 subjects</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>**  Wake after sleep onset</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reference:</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Putcha L, Nimmagudda R, and Rivera C. Assessment Of Sleep Dynamics In A Simulated Space Station Environment</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>In : Lane HW, Sauer RL, and Feeback DL, eds. Isolation: NASA Experiments in Closed-Environment Living.</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>American Astronautical Society Science and Technology Series; Vol 104. San Diego, CA. Univelt, Incorporated; 2002: 141-154.</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab setup: install necessary packages\n",
        "!pip install mne numpy pandas scikit-learn\n",
        "\n",
        "# Mount Google Drive (optional, if you want to save processed data)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set paths\n",
        "import os\n",
        "data_dir = '/content/EEG_BCI_Hackathon'  # Colab folder\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Download dataset from Zenodo\n",
        "dataset_url = 'https://zenodo.org/record/4917218/files/P01.zip?download=1'  # Example for P01\n",
        "# Repeat for P01 → P15, or automate later\n",
        "!wget -O {os.path.join(data_dir,'P01.zip')} \"{dataset_url}\"\n",
        "\n",
        "# Extract ZIP\n",
        "import zipfile\n",
        "with zipfile.ZipFile(os.path.join(data_dir,'P01.zip'), 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.join(data_dir,'P01'))\n",
        "\n",
        "# Load EEG .set file using MNE\n",
        "import mne\n",
        "# Replace with your actual .set path inside the extracted folder\n",
        "set_file = os.path.join(data_dir,'P01','Session1','EEG','task_easy.set')\n",
        "raw = mne.io.read_raw_eeglab(set_file, preload=True)\n",
        "\n",
        "# Basic info\n",
        "print(raw.info)\n",
        "print(raw.ch_names)\n",
        "\n",
        "# Preprocessing example\n",
        "# 1 Hz high-pass, 40 Hz low-pass, downsample to 250 Hz\n",
        "raw.filter(1., 40.)\n",
        "raw.resample(250)\n",
        "\n",
        "# Epoching: 2-second non-overlapping epochs\n",
        "epoch_length_sec = 2\n",
        "sfreq = raw.info['sfreq']\n",
        "epoch_length_samples = int(epoch_length_sec * sfreq)\n",
        "\n",
        "data = raw.get_data()  # shape (channels, samples)\n",
        "n_epochs = data.shape[1] // epoch_length_samples\n",
        "epochs = data[:, :n_epochs*epoch_length_samples].reshape(data.shape[0], n_epochs, epoch_length_samples)\n",
        "epochs = epochs.transpose(1,0,2)  # shape (n_epochs, n_channels, n_samples)\n",
        "print(\"Epochs shape:\", epochs.shape)\n",
        "\n",
        "# Optional: create labels (here dummy, replace with actual labels from documentation)\n",
        "import numpy as np\n",
        "labels = np.random.randint(0, 3, n_epochs)  # 0=easy,1=medium,2=difficult\n",
        "\n",
        "# Flatten epochs for classical ML (mean, std, min, max per channel)\n",
        "def extract_features(epoch):\n",
        "    return np.concatenate([np.mean(epoch, axis=1),\n",
        "                           np.std(epoch, axis=1),\n",
        "                           np.min(epoch, axis=1),\n",
        "                           np.max(epoch, axis=1)])\n",
        "X = np.array([extract_features(e) for e in epochs])\n",
        "y = labels\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Multi-model ensemble example\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "multi_model = VotingClassifier(estimators=[('rf', rf), ('xgb', xgb)], voting='soft')\n",
        "multi_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = multi_model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fBayqL45BB3U",
        "outputId": "18843d21-5380-4424-ae58-4b3287d2f307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.10.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.4)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "Downloading mne-1.10.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.10.1\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--2025-10-01 09:05:15--  https://zenodo.org/record/4917218/files/P01.zip?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/4917218/files/P01.zip [following]\n",
            "--2025-10-01 09:05:16--  https://zenodo.org/records/4917218/files/P01.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120948158 (115M) [application/octet-stream]\n",
            "Saving to: ‘/content/EEG_BCI_Hackathon/P01.zip’\n",
            "\n",
            "/content/EEG_BCI_Ha 100%[===================>] 115.34M  10.1MB/s    in 11s     \n",
            "\n",
            "2025-10-01 09:05:27 (11.0 MB/s) - ‘/content/EEG_BCI_Hackathon/P01.zip’ saved [120948158/120948158]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "input_fname does not exist: \"/content/EEG_BCI_Hackathon/P01/Session1/EEG/task_easy.set\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-231991657.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Replace with your actual .set path inside the extracted folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mset_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'P01'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Session1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'EEG'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'task_easy.set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_raw_eeglab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Basic info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mne/io/eeglab/eeglab.py\u001b[0m in \u001b[0;36mread_raw_eeglab\u001b[0;34m(input_fname, eog, preload, uint16_codec, montage_units, verbose)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.11\u001b[0m\u001b[0;36m.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \"\"\"\n\u001b[0;32m--> 328\u001b[0;31m     return RawEEGLAB(\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0minput_fname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-389>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_fname, eog, preload, uint16_codec, montage_units, verbose)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mne/io/eeglab/eeglab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_fname, eog, preload, uint16_codec, montage_units, verbose)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     ):\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0minput_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_check_fname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_fname\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0meeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_load_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muint16_codec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-119>\u001b[0m in \u001b[0;36m_check_fname\u001b[0;34m(fname, overwrite, must_exist, name, need_dir, check_bids_split, verbose)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mne/utils/check.py\u001b[0m in \u001b[0;36m_check_fname\u001b[0;34m(fname, overwrite, must_exist, name, need_dir, check_bids_split, verbose)\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mPermissionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name} does not have read permissions: {fname}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmust_exist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name} does not exist: \"{fname}\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: input_fname does not exist: \"/content/EEG_BCI_Hackathon/P01/Session1/EEG/task_easy.set\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ciFwFoEBBCdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "c041c966",
        "outputId": "021b9c50-babf-46ec-ecb3-da5f92e27ef6"
      },
      "source": [
        "measurement_columns = ['Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                       'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "\n",
        "print(\"DataFrame columns before conversion:\")\n",
        "display(df.columns)\n",
        "\n",
        "for col in measurement_columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "display(df.head())\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame columns before conversion:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Index(['Measurement'], dtype='object')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Objective Measurement - Baseline'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Objective Measurement - Baseline'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1166581772.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeasurement_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Objective Measurement - Baseline'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "750290ee",
        "outputId": "837e65d8-2abf-42a7-fd1a-bc0c379981ad"
      },
      "source": [
        "display(df.head())\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement Objective Measurement - Baseline  \\\n",
              "0  Duration (h)                        6.62±0.31   \n",
              "1  % Efficiency                       88.50±1.44   \n",
              "2   Latency (h)                        0.27±0.06   \n",
              "3       WASO **                        0.90±0.12   \n",
              "4       Quality                              NaN   \n",
              "\n",
              "  Objective Measurement - Chamber Subjective Measurement - Baseline  \\\n",
              "0                       6.00±0.24                         6.78±0.27   \n",
              "1                      88.10±1.73                        96.40±1.16   \n",
              "2                       0.20±0.05                         0.20±0.05   \n",
              "3                       0.86±0.15                               NaN   \n",
              "4                             NaN                         1.31±0.11   \n",
              "\n",
              "  Subjective Measurement - Chamber  \n",
              "0                        6.21±0.21  \n",
              "1                       95.66±1.03  \n",
              "2                        0.24±0.05  \n",
              "3                              NaN  \n",
              "4                        1.08±0.21  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5003e4b7-f26b-4e2e-b1a8-9bcf70729936\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Objective Measurement - Baseline</th>\n",
              "      <th>Objective Measurement - Chamber</th>\n",
              "      <th>Subjective Measurement - Baseline</th>\n",
              "      <th>Subjective Measurement - Chamber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>6.62±0.31</td>\n",
              "      <td>6.00±0.24</td>\n",
              "      <td>6.78±0.27</td>\n",
              "      <td>6.21±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>88.50±1.44</td>\n",
              "      <td>88.10±1.73</td>\n",
              "      <td>96.40±1.16</td>\n",
              "      <td>95.66±1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>0.27±0.06</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.24±0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>0.90±0.12</td>\n",
              "      <td>0.86±0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.31±0.11</td>\n",
              "      <td>1.08±0.21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5003e4b7-f26b-4e2e-b1a8-9bcf70729936')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5003e4b7-f26b-4e2e-b1a8-9bcf70729936 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5003e4b7-f26b-4e2e-b1a8-9bcf70729936');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d8a94e69-00fa-470a-b9a8-b648cabe799c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8a94e69-00fa-470a-b9a8-b648cabe799c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d8a94e69-00fa-470a-b9a8-b648cabe799c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"% Efficiency\",\n          \"Quality\",\n          \"Latency (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"88.50\\u00b11.44\",\n          \"0.90\\u00b10.12\",\n          \"6.62\\u00b10.31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"88.10\\u00b11.73\",\n          \"0.86\\u00b10.15\",\n          \"6.00\\u00b10.24\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"96.40\\u00b11.16\",\n          \"1.31\\u00b10.11\",\n          \"6.78\\u00b10.27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"95.66\\u00b11.03\",\n          \"1.08\\u00b10.21\",\n          \"6.21\\u00b10.21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15 entries, 0 to 14\n",
            "Data columns (total 5 columns):\n",
            " #   Column                             Non-Null Count  Dtype \n",
            "---  ------                             --------------  ----- \n",
            " 0   Measurement                        12 non-null     object\n",
            " 1   Objective Measurement - Baseline   5 non-null      object\n",
            " 2   Objective Measurement - Chamber    5 non-null      object\n",
            " 3   Subjective Measurement - Baseline  5 non-null      object\n",
            " 4   Subjective Measurement - Chamber   5 non-null      object\n",
            "dtypes: object(5)\n",
            "memory usage: 732.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "940bb562",
        "outputId": "472f6be0-4a66-4de2-8309-5d38de151fb5"
      },
      "source": [
        "df = df.iloc[1:].reset_index(drop=True)\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement Objective Measurement - Baseline  \\\n",
              "0  Duration (h)                        6.62±0.31   \n",
              "1  % Efficiency                       88.50±1.44   \n",
              "2   Latency (h)                        0.27±0.06   \n",
              "3       WASO **                        0.90±0.12   \n",
              "4       Quality                              NaN   \n",
              "\n",
              "  Objective Measurement - Chamber Subjective Measurement - Baseline  \\\n",
              "0                       6.00±0.24                         6.78±0.27   \n",
              "1                      88.10±1.73                        96.40±1.16   \n",
              "2                       0.20±0.05                         0.20±0.05   \n",
              "3                       0.86±0.15                               NaN   \n",
              "4                             NaN                         1.31±0.11   \n",
              "\n",
              "  Subjective Measurement - Chamber  \n",
              "0                        6.21±0.21  \n",
              "1                       95.66±1.03  \n",
              "2                        0.24±0.05  \n",
              "3                              NaN  \n",
              "4                        1.08±0.21  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d685be4-4448-423a-a9ee-bb87ba8fa365\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Objective Measurement - Baseline</th>\n",
              "      <th>Objective Measurement - Chamber</th>\n",
              "      <th>Subjective Measurement - Baseline</th>\n",
              "      <th>Subjective Measurement - Chamber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>6.62±0.31</td>\n",
              "      <td>6.00±0.24</td>\n",
              "      <td>6.78±0.27</td>\n",
              "      <td>6.21±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>88.50±1.44</td>\n",
              "      <td>88.10±1.73</td>\n",
              "      <td>96.40±1.16</td>\n",
              "      <td>95.66±1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>0.27±0.06</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.24±0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>0.90±0.12</td>\n",
              "      <td>0.86±0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.31±0.11</td>\n",
              "      <td>1.08±0.21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d685be4-4448-423a-a9ee-bb87ba8fa365')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d685be4-4448-423a-a9ee-bb87ba8fa365 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d685be4-4448-423a-a9ee-bb87ba8fa365');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-99a4a4f8-fbd3-4cf9-bbfd-3a270eafbf83\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99a4a4f8-fbd3-4cf9-bbfd-3a270eafbf83')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-99a4a4f8-fbd3-4cf9-bbfd-3a270eafbf83 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"% Efficiency\",\n          \"Quality\",\n          \"Latency (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"88.50\\u00b11.44\",\n          \"0.90\\u00b10.12\",\n          \"6.62\\u00b10.31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"88.10\\u00b11.73\",\n          \"0.86\\u00b10.15\",\n          \"6.00\\u00b10.24\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"96.40\\u00b11.16\",\n          \"1.31\\u00b10.11\",\n          \"6.78\\u00b10.27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"95.66\\u00b11.03\",\n          \"1.08\\u00b10.21\",\n          \"6.21\\u00b10.21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder for the dataset\n",
        "import os\n",
        "data_dir = '/content/EEG_BCI_Hackathon'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Example: P01.zip URL from Zenodo\n",
        "url_p01 = \"https://zenodo.org/record/4917218/files/P01.zip?download=1\"\n",
        "\n",
        "# Download\n",
        "!wget -O {os.path.join(data_dir,'P01.zip')} \"{url_p01}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuzhnY3WBh8j",
        "outputId": "aba472d9-e996-461f-99a7-117c99bc9093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-01 09:06:46--  https://zenodo.org/record/4917218/files/P01.zip?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/4917218/files/P01.zip [following]\n",
            "--2025-10-01 09:06:46--  https://zenodo.org/records/4917218/files/P01.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120948158 (115M) [application/octet-stream]\n",
            "Saving to: ‘/content/EEG_BCI_Hackathon/P01.zip’\n",
            "\n",
            "/content/EEG_BCI_Ha 100%[===================>] 115.34M  7.55MB/s    in 15s     \n",
            "\n",
            "2025-10-01 09:07:03 (7.53 MB/s) - ‘/content/EEG_BCI_Hackathon/P01.zip’ saved [120948158/120948158]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 1. Install required packages\n",
        "# ===============================\n",
        "!pip install mne numpy pandas scikit-learn xgboost\n",
        "\n",
        "# ===============================\n",
        "# 2. Setup directories\n",
        "# ===============================\n",
        "import os\n",
        "data_dir = '/content/EEG_BCI_Hackathon'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# 3. Download all participant ZIPs\n",
        "# ===============================\n",
        "for i in range(1, 16):\n",
        "    url = f\"https://zenodo.org/record/4917218/files/P{i:02d}.zip?download=1\"\n",
        "    out_file = os.path.join(data_dir, f\"P{i:02d}.zip\")\n",
        "    # Check if the zip file already exists and is not empty\n",
        "    if not os.path.exists(out_file) or os.stat(out_file).st_size == 0:\n",
        "        print(f\"Downloading {os.path.basename(out_file)}...\")\n",
        "        !wget -O {out_file} \"{url}\"\n",
        "    else:\n",
        "        print(f\"{os.path.basename(out_file)} already exists, skipping download.\")\n",
        "\n",
        "\n",
        "    # Extract ZIP\n",
        "    extract_path = os.path.join(data_dir, f\"P{i:02d}\")\n",
        "    # Check if the extraction directory is empty or doesn't exist\n",
        "    if not os.path.exists(extract_path) or not os.listdir(extract_path):\n",
        "        print(f\"Extracting {os.path.basename(out_file)}...\")\n",
        "        os.makedirs(extract_path, exist_ok=True)\n",
        "        import zipfile\n",
        "        with zipfile.ZipFile(out_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "    else:\n",
        "        print(f\"{os.path.basename(extract_path)} directory is not empty, skipping extraction.\")\n",
        "\n",
        "\n",
        "print(\"All participants download and extraction check completed!\")\n",
        "\n",
        "# Add a command to list the contents of the extracted P01 directory to find the correct file path\n",
        "print(\"\\nListing contents of extracted P01 directory:\")\n",
        "!ls -R /content/EEG_BCI_Hackathon/P01\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 4. Load all EEG .set files with MNE\n",
        "# ===============================\n",
        "import mne\n",
        "import numpy as np\n",
        "import glob # Import glob to find files\n",
        "\n",
        "def load_eeg_epochs(file_path):\n",
        "    \"\"\"Load EEG .set file and return MNE Epochs object\"\"\"\n",
        "    # Use read_epochs_eeglab for files containing epochs\n",
        "    epochs = mne.io.read_epochs_eeglab(file_path)\n",
        "    return epochs\n",
        "\n",
        "# List to store all loaded epochs\n",
        "all_eeg_epochs = []\n",
        "eeg_data_dir = os.path.join(data_dir, 'P{i:02d}', 'P{i:02d}', 'S{s}', 'eeg') # Pattern for EEG data directories\n",
        "task_patterns = ['*MATBeasy.set', '*MATBmed.set', '*MATBdiff.set', '*RS.set'] # Patterns for task files\n",
        "\n",
        "\n",
        "print(\"\\nLoading all EEG files...\")\n",
        "for i in range(1, 16): # Iterate through participants P01 to P15\n",
        "    for s in range(1, 3): # Iterate through sessions S1 and S2\n",
        "        current_eeg_dir = eeg_data_dir.format(i=i, s=s)\n",
        "        print(f\"Checking directory: {current_eeg_dir}\")\n",
        "        if os.path.exists(current_eeg_dir):\n",
        "            for pattern in task_patterns:\n",
        "                file_pattern = os.path.join(current_eeg_dir, pattern)\n",
        "                eeg_files = glob.glob(file_pattern)\n",
        "                for eeg_file in eeg_files:\n",
        "                    print(f\"Loading file: {eeg_file}\")\n",
        "                    try:\n",
        "                        epochs = load_eeg_epochs(eeg_file)\n",
        "                        all_eeg_epochs.append(epochs)\n",
        "                        print(f\"Successfully loaded {os.path.basename(eeg_file)}. Number of epochs: {len(epochs)}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error loading {eeg_file}: {e}\")\n",
        "        else:\n",
        "            print(f\"Directory not found: {current_eeg_dir}\")\n",
        "\n",
        "print(f\"\\nFinished loading all EEG files. Total number of loaded Epochs objects: {len(all_eeg_epochs)}\")\n",
        "\n",
        "# Concatenate all epochs into a single Epochs object if needed for consistent processing\n",
        "if all_eeg_epochs:\n",
        "    try:\n",
        "        combined_eeg_epochs = mne.concatenate_epochs(all_eeg_epochs)\n",
        "        print(\"\\nSuccessfully concatenated all EEG epochs.\")\n",
        "        print(\"Combined EEG Epochs Info:\")\n",
        "        print(combined_eeg_epochs.info)\n",
        "        print(\"Combined EEG Epochs shape:\", combined_eeg_epochs.get_data().shape)\n",
        "    except Exception as e:\n",
        "        print(f\"Error concatenating epochs: {e}\")\n",
        "        combined_eeg_epochs = None # Set to None if concatenation fails\n",
        "else:\n",
        "    combined_eeg_epochs = None\n",
        "    print(\"\\nNo EEG epochs were loaded.\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 5. Preprocessing (Adapted for Epochs)\n",
        "# ===============================\n",
        "print(\"\\nProceeding with Preprocessing steps (adapted for epochs):\")\n",
        "# Apply filtering to the epochs if needed (e.g., band-pass filter)\n",
        "# if combined_eeg_epochs:\n",
        "#     print(\"Applying band-pass filter (1-40 Hz)...\")\n",
        "#     combined_eeg_epochs.filter(1., 40.) # Example: Apply a band-pass filter from 1 to 40 Hz\n",
        "\n",
        "# No need for manual segmentation as data is already in epochs.\n",
        "# Resampling can still be applied to epochs if needed\n",
        "# if combined_eeg_epochs:\n",
        "#     print(\"Resampling to 250 Hz...\")\n",
        "#     combined_eeg_epochs.resample(250) # Example: Resample to 250 Hz\n",
        "\n",
        "print(\"Preprocessing steps adapted for epoch data. Filtering/Resampling can be applied directly to eeg_epochs object if needed.\")\n",
        "\n",
        "# ===============================\n",
        "# 6. Feature Extraction for ML\n",
        "# ===============================\n",
        "print(\"\\nProceeding with Feature Extraction:\")\n",
        "# Extract data from epochs object for feature extraction\n",
        "if combined_eeg_epochs:\n",
        "    epochs_data = combined_eeg_epochs.get_data() # shape: (n_epochs, n_channels, n_times)\n",
        "\n",
        "    def extract_features(epoch):\n",
        "        \"\"\"Compute simple features: mean, std, min, max per channel\"\"\"\n",
        "        return np.concatenate([np.mean(epoch, axis=1),\n",
        "                               np.std(epoch, axis=1),\n",
        "                               np.min(epoch, axis=1),\n",
        "                               np.max(epoch, axis=1)])\n",
        "\n",
        "    X_eeg_features = np.array([extract_features(epoch) for epoch in epochs_data])\n",
        "\n",
        "    # Get labels from epochs metadata or events if available\n",
        "    # Assuming the event ID is in the third column of the events array\n",
        "    if combined_eeg_epochs.events is not None:\n",
        "        labels_eeg = combined_eeg_epochs.events[:, 2]\n",
        "        print(f\"\\nExtracted {len(labels_eeg)} labels from combined epoch events.\")\n",
        "        print(f\"Unique labels: {np.unique(labels_eeg)}\")\n",
        "        y_eeg = labels_eeg\n",
        "    else:\n",
        "         # If no events are found, use dummy labels as a placeholder\n",
        "        print(\"\\nNo events found in combined epochs. Cannot extract labels.\")\n",
        "        X_eeg_features = None # Set features to None if labels cannot be extracted\n",
        "\n",
        "\n",
        "    if X_eeg_features is not None:\n",
        "        print(\"EEG Feature matrix shape:\", X_eeg_features.shape)\n",
        "        print(\"EEG Labels shape:\", y_eeg.shape)\n",
        "    else:\n",
        "        print(\"EEG feature extraction skipped due to missing data or labels.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"Skipping EEG feature extraction as no epochs were loaded or concatenated.\")\n",
        "    X_eeg_features = None\n",
        "    y_eeg = None\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 7. Split, Scale, and Train Multi-Model (Adapt for full data)\n",
        "# ===============================\n",
        "print(\"\\nProceeding with Model Training (Random Forest on EEG features):\")\n",
        "# We will use the extracted EEG features (X_eeg_features) and labels (y_eeg) for the Random Forest part.\n",
        "# The full multi-model ensemble requires loading and processing ECG data and building/training the CNN and LSTM models separately.\n",
        "# This part of the code now attempts to train the RF on features from all loaded EEG data.\n",
        "\n",
        "if X_eeg_features is not None and y_eeg is not None and len(np.unique(y_eeg)) > 1:\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    # Split data\n",
        "    X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_eeg_features, y_eeg, test_size=0.2, random_state=42, stratify=y_eeg)\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_rf = scaler.fit_transform(X_train_rf)\n",
        "    X_test_rf = scaler.transform(X_test_rf)\n",
        "\n",
        "    # Train Random Forest model\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    print(\"\\nTraining Random Forest model on extracted EEG features from all loaded data...\")\n",
        "    rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "    # Evaluate Random Forest model\n",
        "    y_pred_rf = rf.predict(X_test_rf)\n",
        "    print(\"\\nRandom Forest Model Accuracy on Test Set (EEG Features):\", accuracy_score(y_test_rf, y_pred_rf))\n",
        "\n",
        "    print(\"\\nRandom Forest model training and evaluation completed on extracted EEG features.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping Random Forest model training due to insufficient EEG features or labels.\")\n",
        "\n",
        "# Note: The CNN and LSTM models would require training on the preprocessed EEG segments and ECG sequences respectively.\n",
        "# The combination of models would happen after all models are trained."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKhHNPCpBqfE",
        "outputId": "cebd1059-b233-4e66-c6a8-6bd765170d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.4)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "P01.zip already exists, skipping download.\n",
            "P01 directory is not empty, skipping extraction.\n",
            "P02.zip already exists, skipping download.\n",
            "P02 directory is not empty, skipping extraction.\n",
            "P03.zip already exists, skipping download.\n",
            "P03 directory is not empty, skipping extraction.\n",
            "P04.zip already exists, skipping download.\n",
            "P04 directory is not empty, skipping extraction.\n",
            "P05.zip already exists, skipping download.\n",
            "P05 directory is not empty, skipping extraction.\n",
            "P06.zip already exists, skipping download.\n",
            "P06 directory is not empty, skipping extraction.\n",
            "P07.zip already exists, skipping download.\n",
            "P07 directory is not empty, skipping extraction.\n",
            "P08.zip already exists, skipping download.\n",
            "P08 directory is not empty, skipping extraction.\n",
            "P09.zip already exists, skipping download.\n",
            "P09 directory is not empty, skipping extraction.\n",
            "P10.zip already exists, skipping download.\n",
            "P10 directory is not empty, skipping extraction.\n",
            "P11.zip already exists, skipping download.\n",
            "P11 directory is not empty, skipping extraction.\n",
            "P12.zip already exists, skipping download.\n",
            "P12 directory is not empty, skipping extraction.\n",
            "P13.zip already exists, skipping download.\n",
            "P13 directory is not empty, skipping extraction.\n",
            "P14.zip already exists, skipping download.\n",
            "P14 directory is not empty, skipping extraction.\n",
            "P15.zip already exists, skipping download.\n",
            "P15 directory is not empty, skipping extraction.\n",
            "All participants download and extraction check completed!\n",
            "\n",
            "Listing contents of extracted P01 directory:\n",
            "/content/EEG_BCI_Hackathon/P01:\n",
            "P01\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01:\n",
            "S1  S2\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S1:\n",
            "eeg  electrode_positions\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S1/eeg:\n",
            "alldata_sbj01_sess1_MATBdiff.set  alldata_sbj01_sess1_RSraw.set\n",
            "alldata_sbj01_sess1_MATBeasy.set  alldata_sbj01_sess1_RS.set\n",
            "alldata_sbj01_sess1_MATBmed.set\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S1/electrode_positions:\n",
            "get_chanlocs.txt\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S2:\n",
            "eeg  electrode_positions\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S2/eeg:\n",
            "alldata_sbj01_sess2_MATBdiff.set  alldata_sbj01_sess2_RSraw.set\n",
            "alldata_sbj01_sess2_MATBeasy.set  alldata_sbj01_sess2_RS.set\n",
            "alldata_sbj01_sess2_MATBmed.set\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S2/electrode_positions:\n",
            "get_chanlocs.txt\n",
            "\n",
            "Loading all EEG files...\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBmed.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj03_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj03_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj03_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj03_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj03_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj03_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj03_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj03_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj04_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj04_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBdiff.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj04_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RS.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj04_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj04_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj04_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBdiff.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj04_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RS.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj04_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj05_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj05_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj05_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj05_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj05_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj05_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj05_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj05_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj06_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj06_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj06_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj06_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj06_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj06_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj06_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj06_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj07_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj07_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj07_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj07_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj07_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj07_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj07_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj07_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj08_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj08_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj08_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj08_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj08_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBmed.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj08_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj08_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj08_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj09_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj09_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj09_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj09_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj09_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj09_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj09_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj09_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj10_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj10_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBdiff.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj10_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj10_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj10_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj10_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj10_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj10_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj11_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBmed.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj11_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj11_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj11_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj11_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj11_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj11_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj11_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj12_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj12_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj12_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj12_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj12_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj12_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj12_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj12_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj13_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj13_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj13_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj13_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj13_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj13_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj13_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj13_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-4099228395.py:57: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj14_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj14_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj14_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj14_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj14_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj14_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj14_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj14_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj15_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj15_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj15_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj15_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj15_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj15_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj15_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj15_sess2_RS.set. Number of epochs: 30\n",
            "\n",
            "Finished loading all EEG files. Total number of loaded Epochs objects: 120\n",
            "Not setting metadata\n",
            "14310 matching events found\n",
            "No baseline correction applied\n",
            "\n",
            "Successfully concatenated all EEG epochs.\n",
            "Combined EEG Epochs Info:\n",
            "<Info | 8 non-empty values\n",
            " bads: []\n",
            " ch_names: Fp1, Fz, F3, F7, FT9, FC5, FC1, C3, T7, CP5, CP1, Pz, P3, P7, ...\n",
            " chs: 61 EEG\n",
            " custom_ref_applied: False\n",
            " dig: 64 items (3 Cardinal, 61 EEG)\n",
            " highpass: 0.0 Hz\n",
            " lowpass: 125.0 Hz\n",
            " meas_date: unspecified\n",
            " nchan: 61\n",
            " projs: []\n",
            " sfreq: 250.0 Hz\n",
            ">\n",
            "Combined EEG Epochs shape: (14310, 61, 500)\n",
            "\n",
            "Proceeding with Preprocessing steps (adapted for epochs):\n",
            "Preprocessing steps adapted for epoch data. Filtering/Resampling can be applied directly to eeg_epochs object if needed.\n",
            "\n",
            "Proceeding with Feature Extraction:\n",
            "\n",
            "Extracted 14310 labels from combined epoch events.\n",
            "Unique labels: [1]\n",
            "EEG Feature matrix shape: (14310, 244)\n",
            "EEG Labels shape: (14310,)\n",
            "\n",
            "Proceeding with Model Training (Random Forest on EEG features):\n",
            "\n",
            "Skipping Random Forest model training due to insufficient EEG features or labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 1. Install packages\n",
        "# ===============================\n",
        "!pip install mne wfdb numpy pandas scikit-learn tensorflow requests\n",
        "\n",
        "import os, zipfile, requests\n",
        "import numpy as np\n",
        "import mne\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Dropout, LSTM, Flatten, concatenate, BatchNormalization\n",
        "\n",
        "# ===============================\n",
        "# 2. Download GitHub dataset\n",
        "# ===============================\n",
        "# Note: This section downloads data from a GitHub repository, which might be different\n",
        "# from the Zenodo data previously downloaded. If you intend to use the Zenodo data,\n",
        "# this section should be replaced or modified to load data from the extracted Zenodo files.\n",
        "base_url = \"https://github.com/BBNLP/PassiveBCI-Hackathon-2021/raw/main/data/\"\n",
        "participants = [f\"P{i:02d}.zip\" for i in range(1,16)]\n",
        "data_dir = \"PassiveBCI_data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "for p in participants:\n",
        "    url = base_url + p\n",
        "    zip_path = os.path.join(data_dir, p)\n",
        "    # Check if the file already exists to avoid re-downloading\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Downloading {p} ...\")\n",
        "        r = requests.get(url)\n",
        "        with open(zip_path,\"wb\") as f:\n",
        "            f.write(r.content)\n",
        "\n",
        "    extract_path = os.path.join(data_dir,p.replace(\".zip\",\"\"))\n",
        "    # Check if the extraction directory is empty or doesn't exist\n",
        "    if not os.path.exists(extract_path) or not os.listdir(extract_path):\n",
        "        print(f\"Extracting {p} ...\")\n",
        "        with zipfile.ZipFile(zip_path,\"r\") as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "    else:\n",
        "        print(f\"{os.path.basename(extract_path)} directory is not empty, skipping extraction.\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 3. Functions to load EEG/ECG/HRV\n",
        "# ===============================\n",
        "def load_eeg_epochs_and_labels(set_file, epoch_sec=2, downsample=250):\n",
        "    \"\"\"Load EEG .set file, preprocess, epoch, and extract labels.\"\"\"\n",
        "    raw = mne.io.read_raw_eeglab(set_file, preload=True, verbose=False)\n",
        "    raw.filter(1., 40., verbose=False)\n",
        "    raw.resample(downsample, verbose=False)\n",
        "\n",
        "    # Pick EEG channels\n",
        "    eeg_channels = [ch for ch in raw.info['ch_names'] if 'EEG' in ch or 'eeg' in ch]\n",
        "    # Check if any EEG channels were found\n",
        "    if not eeg_channels:\n",
        "        print(f\"No EEG channels found in {os.path.basename(set_file)}\")\n",
        "        return None, None, 0\n",
        "    data = raw.get_data(picks=eeg_channels)\n",
        "\n",
        "    # Epoching\n",
        "    sfreq = raw.info['sfreq']\n",
        "    epoch_len = int(epoch_sec * sfreq)\n",
        "    n_samples = data.shape[1]\n",
        "    n_epochs = n_samples // epoch_len\n",
        "\n",
        "    if n_epochs == 0:\n",
        "        print(f\"No full epochs of length {epoch_sec}s found in {os.path.basename(set_file)}\")\n",
        "        return None, None, 0\n",
        "\n",
        "    eeg_epochs = data[:, :n_epochs*epoch_len].reshape(len(eeg_channels), n_epochs, epoch_len).transpose(1,0,2)\n",
        "\n",
        "    # Extract labels from annotations/events\n",
        "    events, event_ids = mne.events_from_annotations(raw, verbose=False)\n",
        "    labels = np.zeros(n_epochs)\n",
        "    # Map event samples to epoch indices\n",
        "    event_epoch_indices = (events[:, 0] // epoch_len).astype(int)\n",
        "    # Ensure event indices are within the valid range of epochs\n",
        "    valid_event_indices = event_epoch_indices < n_epochs\n",
        "\n",
        "    if np.any(valid_event_indices):\n",
        "         # Assign labels to epochs based on the first event within or immediately before the epoch\n",
        "        # This is a simplification; a more robust approach might consider events within the epoch window\n",
        "        unique_event_epochs, first_occurrence_indices = np.unique(event_epoch_indices[valid_event_indices], return_index=True)\n",
        "        labels[unique_event_epochs] = events[valid_event_indices][first_occurrence_indices, 2]\n",
        "    else:\n",
        "        print(f\"No events found within epoch boundaries in {os.path.basename(set_file)}. Using dummy labels.\")\n",
        "        labels = np.zeros(n_epochs) # Use a default label if no events are found\n",
        "\n",
        "\n",
        "    return eeg_epochs, labels, n_epochs\n",
        "\n",
        "def load_ecg_features(set_file):\n",
        "    \"\"\"Load ECG data, preprocess, and extract simple features per epoch.\"\"\"\n",
        "    raw = mne.io.read_raw_eeglab(set_file, preload=True, verbose=False)\n",
        "    ecg_channels = [ch for ch in raw.info['ch_names'] if 'ECG' in ch or 'ecg' in ch]\n",
        "    if not ecg_channels:\n",
        "        print(f\"No ECG channels found in {os.path.basename(set_file)}\")\n",
        "        return None, 0\n",
        "    ecg = raw.get_data(picks=ecg_channels)[0] # Assuming one ECG channel\n",
        "\n",
        "    # Simple epoching for feature extraction (matching EEG epoch length)\n",
        "    epoch_sec = 2 # Match EEG epoch length\n",
        "    sfreq = raw.info['sfreq']\n",
        "    epoch_len = int(epoch_sec * sfreq)\n",
        "    n_samples = len(ecg)\n",
        "    n_epochs = n_samples // epoch_len\n",
        "\n",
        "    if n_epochs == 0:\n",
        "        print(f\"No full ECG epochs of length {epoch_sec}s found in {os.path.basename(set_file)}\")\n",
        "        return None, 0\n",
        "\n",
        "    ecg_epochs = ecg[:n_epochs*epoch_len].reshape(n_epochs, epoch_len)\n",
        "\n",
        "    # Extract simple features (mean, std) per epoch\n",
        "    mean_ecg = np.mean(ecg_epochs, axis=1)\n",
        "    std_ecg = np.std(ecg_epochs, axis=1)\n",
        "    return np.vstack([mean_ecg, std_ecg]).T, n_epochs # Shape (n_epochs, 2)\n",
        "\n",
        "def load_raw_ecg_epochs(set_file, epoch_sec=2, downsample=250):\n",
        "    \"\"\"Load raw ECG data and segment into epochs.\"\"\"\n",
        "    raw = mne.io.read_raw_eeglab(set_file, preload=True, verbose=False)\n",
        "    raw.filter(0.5, 45., verbose=False) # Apply basic filter\n",
        "    raw.resample(downsample, verbose=False) # Resample\n",
        "\n",
        "    ecg_channels = [ch for ch in raw.info['ch_names'] if 'ECG' in ch or 'ecg' in ch]\n",
        "    if not ecg_channels:\n",
        "        print(f\"No ECG channels found in {os.path.basename(set_file)}\")\n",
        "        return None, 0\n",
        "    ecg = raw.get_data(picks=ecg_channels)[0] # Assuming one ECG channel\n",
        "\n",
        "    sfreq = raw.info['sfreq']\n",
        "    epoch_len = int(epoch_sec * sfreq)\n",
        "    n_samples = len(ecg)\n",
        "    n_epochs = n_samples // epoch_len\n",
        "\n",
        "    if n_epochs == 0:\n",
        "        print(f\"No full raw ECG epochs of length {epoch_sec}s found in {os.path.basename(set_file)}\")\n",
        "        return None, 0\n",
        "\n",
        "    # Reshape into epochs (n_epochs, n_samples_per_epoch, 1) for CNN/LSTM input\n",
        "    raw_ecg_epochs = ecg[:n_epochs*epoch_len].reshape(n_epochs, epoch_len, 1)\n",
        "\n",
        "    return raw_ecg_epochs, n_epochs\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 4. Data augmentation (Placeholder - can be applied per batch during training)\n",
        "# ===============================\n",
        "def add_gaussian_noise(signal, std=0.01):\n",
        "    \"\"\"Add Gaussian noise to a signal.\"\"\"\n",
        "    if signal is None: return None\n",
        "    return signal + np.random.normal(0, std, signal.shape)\n",
        "\n",
        "def time_shift(signal, max_shift=50):\n",
        "    \"\"\"Apply time shift to a signal.\"\"\"\n",
        "    if signal is None: return None\n",
        "    shift = np.random.randint(-max_shift, max_shift)\n",
        "    return np.roll(signal, shift, axis=-1)\n",
        "\n",
        "def amplitude_scaling(signal, scale_range=(0.9, 1.1)):\n",
        "    \"\"\"Apply amplitude scaling to a signal.\"\"\"\n",
        "    if signal is None: return None\n",
        "    return signal * np.random.uniform(*scale_range)\n",
        "\n",
        "def augment_batch(X_eeg, X_ecg):\n",
        "    \"\"\"Apply augmentation to a batch of EEG and ECG data.\"\"\"\n",
        "    # Augmentation should ideally be applied to raw or minimally processed data\n",
        "    # and potentially within the training loop.\n",
        "    # This is a placeholder example.\n",
        "    if X_eeg is not None:\n",
        "        X_eeg_aug = add_gaussian_noise(X_eeg)\n",
        "        X_eeg_aug = time_shift(X_eeg_aug)\n",
        "        X_eeg_aug = amplitude_scaling(X_eeg_aug)\n",
        "    else:\n",
        "        X_eeg_aug = None\n",
        "\n",
        "    if X_ecg is not None:\n",
        "        X_ecg_aug = add_gaussian_noise(X_ecg)\n",
        "        X_ecg_aug = time_shift(X_ecg_aug)\n",
        "        X_ecg_aug = amplitude_scaling(X_ecg_aug)\n",
        "    else:\n",
        "        X_ecg_aug = None\n",
        "\n",
        "    return X_eeg_aug, X_ecg_aug\n",
        "\n",
        "# ===============================\n",
        "# 5. Load all participants & sessions\n",
        "# ===============================\n",
        "# Lists to store data from all files\n",
        "all_eeg_epochs_list = []\n",
        "all_hrv_features_list = []\n",
        "all_raw_ecg_epochs_list = []\n",
        "all_labels_list = []\n",
        "\n",
        "data_pattern = os.path.join(data_dir, 'P{i:02d}', 'P{i:02d}', 'S{s}', 'eeg', '*.set') # Pattern to find all EEG .set files\n",
        "\n",
        "print(\"\\nLoading data from all participants and sessions...\")\n",
        "\n",
        "# Use glob to find all .set files matching the pattern\n",
        "set_files = glob.glob(data_pattern.format(i='*', s='*'))\n",
        "\n",
        "if not set_files:\n",
        "    print(\"No .set files found matching the pattern:\", data_pattern.format(i='*', s='*'))\n",
        "else:\n",
        "    print(f\"Found {len(set_files)} .set files. Loading...\")\n",
        "\n",
        "    for set_file in set_files:\n",
        "        print(f\"Processing file: {os.path.basename(set_file)}\")\n",
        "        try:\n",
        "            # Load EEG epochs and labels\n",
        "            eeg_epochs, labels, n_eeg_epochs = load_eeg_epochs_and_labels(set_file)\n",
        "\n",
        "            # Load ECG features (mean/std per epoch)\n",
        "            hrv_features, n_hrv_epochs = load_ecg_features(set_file)\n",
        "\n",
        "            # Load raw ECG epochs\n",
        "            raw_ecg_epochs, n_raw_ecg_epochs = load_raw_ecg_epochs(set_file)\n",
        "\n",
        "            # Ensure all data types have the same number of epochs for this file\n",
        "            # This assumes a one-to-one correspondence between EEG epochs, ECG features, and raw ECG epochs.\n",
        "            # If the number of epochs differs, we take the minimum to keep corresponding data points.\n",
        "            min_epochs = min(n_eeg_epochs, n_hrv_epochs, n_raw_ecg_epochs)\n",
        "\n",
        "            if min_epochs > 0:\n",
        "                 # Append data up to min_epochs\n",
        "                if eeg_epochs is not None:\n",
        "                    all_eeg_epochs_list.append(eeg_epochs[:min_epochs])\n",
        "                if hrv_features is not None:\n",
        "                    all_hrv_features_list.append(hrv_features[:min_epochs])\n",
        "                if raw_ecg_epochs is not None:\n",
        "                    all_raw_ecg_epochs_list.append(raw_ecg_epochs[:min_epochs])\n",
        "                if labels is not None:\n",
        "                     # Ensure labels match the number of epochs\n",
        "                    all_labels_list.append(labels[:min_epochs])\n",
        "                print(f\"Successfully loaded and collected {min_epochs} epochs from {os.path.basename(set_file)}\")\n",
        "            else:\n",
        "                print(f\"Skipping {os.path.basename(set_file)} due to insufficient epochs after loading.\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {os.path.basename(set_file)}: {e}\")\n",
        "\n",
        "# Concatenate data from all files\n",
        "X_eeg = np.vstack(all_eeg_epochs_list) if all_eeg_epochs_list else None\n",
        "X_hrv = np.vstack(all_hrv_features_list) if all_hrv_features_list else None\n",
        "X_ecg = np.vstack(all_raw_ecg_epochs_list) if all_raw_ecg_epochs_list else None\n",
        "y = np.concatenate(all_labels_list) if all_labels_list else None\n",
        "\n",
        "\n",
        "print(\"\\nFinished loading data from all files.\")\n",
        "if X_eeg is not None:\n",
        "    print(\"Combined EEG epochs shape:\", X_eeg.shape)\n",
        "if X_hrv is not None:\n",
        "    print(\"Combined HRV features shape:\", X_hrv.shape)\n",
        "if X_ecg is not None:\n",
        "    print(\"Combined raw ECG epochs shape:\", X_ecg.shape)\n",
        "if y is not None:\n",
        "    print(\"Combined labels shape:\", y.shape)\n",
        "    unique_labels = np.unique(y)\n",
        "    print(\"Unique labels in combined data:\", unique_labels)\n",
        "    if len(unique_labels) < 2:\n",
        "        print(\"Warning: Only one unique label found. Classification models require at least two classes.\")\n",
        "else:\n",
        "    print(\"No data was loaded successfully.\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 6. Prepare labels\n",
        "# ===============================\n",
        "# Convert labels to one-hot encoding if needed for deep learning models\n",
        "if y is not None and len(np.unique(y)) > 1:\n",
        "    lb = LabelBinarizer()\n",
        "    y_onehot = lb.fit_transform(y)\n",
        "    print(\"\\nLabels converted to one-hot encoding.\")\n",
        "    print(\"One-hot encoded labels shape:\", y_onehot.shape)\n",
        "else:\n",
        "     print(\"\\nSkipping one-hot encoding due to insufficient unique labels.\")\n",
        "     y_onehot = None\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 7. Train-test split\n",
        "# ===============================\n",
        "# Split the data for training and testing\n",
        "if X_eeg is not None and y is not None and len(np.unique(y)) > 1:\n",
        "    print(\"\\nSplitting data into training and testing sets...\")\n",
        "    # Perform stratified split if possible\n",
        "    try:\n",
        "        X_eeg_train, X_eeg_test, X_hrv_train, X_hrv_test, X_ecg_train, X_ecg_test, y_train, y_test, y_onehot_train, y_onehot_test = train_test_split(\n",
        "            X_eeg, X_hrv, X_ecg, y, y_onehot, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "        print(\"Data split successfully with stratification.\")\n",
        "        print(\"X_eeg_train shape:\", X_eeg_train.shape)\n",
        "        print(\"X_hrv_train shape:\", X_hrv_train.shape)\n",
        "        print(\"X_ecg_train shape:\", X_ecg_train.shape)\n",
        "        print(\"y_train shape:\", y_train.shape)\n",
        "        if y_onehot_train is not None:\n",
        "             print(\"y_onehot_train shape:\", y_onehot_train.shape)\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Could not perform stratified split: {e}. Attempting non-stratified split.\")\n",
        "        # Fallback to non-stratified split if stratification fails (e.g., single class in a split)\n",
        "        X_eeg_train, X_eeg_test, X_hrv_train, X_hrv_test, X_ecg_train, X_ecg_test, y_train, y_test = train_test_split(\n",
        "            X_eeg, X_hrv, X_ecg, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "        y_onehot_train = lb.transform(y_train) if lb else None\n",
        "        y_onehot_test = lb.transform(y_test) if lb else None\n",
        "        print(\"Data split successfully without stratification.\")\n",
        "        print(\"X_eeg_train shape:\", X_eeg_train.shape)\n",
        "        print(\"X_hrv_train shape:\", X_hrv_train.shape)\n",
        "        print(\"X_ecg_train shape:\", X_ecg_train.shape)\n",
        "        print(\"y_train shape:\", y_train.shape)\n",
        "        if y_onehot_train is not None:\n",
        "             print(\"y_onehot_train shape:\", y_onehot_train.shape)\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping data splitting due to insufficient data or unique labels.\")\n",
        "    X_eeg_train, X_eeg_test, X_hrv_train, X_hrv_test, X_ecg_train, X_ecg_test, y_train, y_test, y_onehot_train, y_onehot_test = None, None, None, None, None, None, None, None, None, None\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 8. Multi-modal network\n",
        "# ===============================\n",
        "# Define and compile the multi-modal model if data is available\n",
        "if X_eeg_train is not None and X_hrv_train is not None and X_ecg_train is not None and y_onehot_train is not None:\n",
        "    print(\"\\nBuilding multi-modal network...\")\n",
        "    n_channels = X_eeg_train.shape[1] # Number of EEG channels\n",
        "    n_eeg_samples = X_eeg_train.shape[2] # Number of time steps per EEG epoch\n",
        "    n_hrv = X_hrv_train.shape[1] # Number of HRV features per epoch\n",
        "    n_ecg_samples = X_ecg_train.shape[1] # Number of time steps per raw ECG epoch\n",
        "    n_classes = y_onehot_train.shape[1] # Number of output classes\n",
        "\n",
        "\n",
        "    # EEG branch (CNN)\n",
        "    eeg_input = Input(shape=(n_channels, n_eeg_samples))\n",
        "    # Transpose input for Conv1D if needed (Conv1D expects (batch, steps, channels))\n",
        "    # Assuming input shape is (batch, channels, steps), we need to transpose\n",
        "    eeg_input_transposed = tf.transpose(eeg_input, perm=[0, 2, 1])\n",
        "    x = Conv1D(filters=32, kernel_size=5, activation='relu', padding='same')(eeg_input_transposed)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "\n",
        "    # HRV branch (Dense)\n",
        "    hrv_input = Input(shape=(n_hrv,))\n",
        "    y_hrv_branch = Dense(32, activation='relu')(hrv_input)\n",
        "    y_hrv_branch = Dropout(0.2)(y_hrv_branch)\n",
        "\n",
        "    # Raw ECG branch (CNN or LSTM - using CNN here as an example)\n",
        "    # Assuming input shape is (batch, steps, channels) for Conv1D\n",
        "    ecg_input = Input(shape=(n_ecg_samples, 1)) # Assuming 1 channel for raw ECG\n",
        "    z = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(ecg_input)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = MaxPooling1D(pool_size=2)(z)\n",
        "    z = Dropout(0.2)(z)\n",
        "    z = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(z)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = MaxPooling1D(pool_size=2)(z)\n",
        "    z = Dropout(0.2)(z)\n",
        "    z = Flatten()(z)\n",
        "\n",
        "\n",
        "    # Merge\n",
        "    combined = concatenate([x, y_hrv_branch, z])\n",
        "    dense_combined = Dense(64, activation='relu')(combined)\n",
        "    dense_combined = Dropout(0.3)(dense_combined)\n",
        "    output = Dense(n_classes, activation='softmax')(dense_combined)\n",
        "\n",
        "    multi_modal_model = Model(inputs=[eeg_input, hrv_input, ecg_input], outputs=output)\n",
        "    multi_modal_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nMulti-modal model summary:\")\n",
        "    multi_modal_model.summary()\n",
        "\n",
        "    # ===============================\n",
        "    # 9. Train with augmentation\n",
        "    # ===============================\n",
        "    print(\"\\nTraining multi-modal model with augmentation...\")\n",
        "    batch_size = 32\n",
        "    epochs = 20 # Example number of epochs\n",
        "\n",
        "    # Note: Implementing augmentation directly within the training loop\n",
        "    # would involve creating a custom data generator.\n",
        "    # For simplicity here, we will train without explicit augmentation loop,\n",
        "    # but the augment_batch function is available if needed.\n",
        "\n",
        "    # Train the model\n",
        "    history = multi_modal_model.fit(\n",
        "        [X_eeg_train, X_hrv_train, X_ecg_train],\n",
        "        y_onehot_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_split=0.2 # Using 20% of training data for validation\n",
        "    )\n",
        "\n",
        "    print(\"\\nMulti-modal model training completed.\")\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 10. Evaluate the model\n",
        "    # ===============================\n",
        "    print(\"\\nEvaluating multi-modal model on test set...\")\n",
        "    if X_eeg_test is not None and X_hrv_test is not None and X_ecg_test is not None and y_onehot_test is not None:\n",
        "        loss, accuracy = multi_modal_model.evaluate([X_eeg_test, X_hrv_test, X_ecg_test], y_onehot_test, verbose=0)\n",
        "        print(f\"Multi-modal Model Test Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Multi-modal Model Test Loss: {loss:.4f}\")\n",
        "\n",
        "        # Optional: Classification report and confusion matrix\n",
        "        # y_pred_proba = multi_modal_model.predict([X_eeg_test, X_hrv_test, X_ecg_test])\n",
        "        # y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "        # y_true = np.argmax(y_onehot_test, axis=1)\n",
        "        # from sklearn.metrics import classification_report, confusion_matrix\n",
        "        # print(\"\\nClassification Report:\")\n",
        "        # print(classification_report(y_true, y_pred))\n",
        "        # print(\"\\nConfusion Matrix:\")\n",
        "        # print(confusion_matrix(y_true, y_pred))\n",
        "    else:\n",
        "        print(\"Skipping evaluation due to missing test data.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping multi-modal network building and training due to insufficient data or unique labels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DgOUt8qPEFH6",
        "outputId": "761839fa-5524-4436-c054-2acffa69024d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.12/dist-packages (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.12.15)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.20.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.4)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.23)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Extracting P01.zip ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1823521086.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracting {p} ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3818164f",
        "outputId": "41231ecb-dc7d-4406-e7b6-e36eed26c657"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'y_eeg' contains the extracted labels from the combined EEG epochs\n",
        "if 'y_eeg' in locals() and y_eeg is not None:\n",
        "    unique_labels, label_counts = np.unique(y_eeg, return_counts=True)\n",
        "\n",
        "    if len(unique_labels) > 0:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.barplot(x=unique_labels, y=label_counts, palette='viridis')\n",
        "        plt.xlabel('Label')\n",
        "        plt.ylabel('Count')\n",
        "        plt.title('Distribution of Labels in Loaded EEG Data')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(f\"\\nUnique labels and their counts: {dict(zip(unique_labels, label_counts))}\")\n",
        "    else:\n",
        "        print(\"No labels found to visualize.\")\n",
        "else:\n",
        "    print(\"EEG labels (y_eeg) not found. Please ensure the EEG data was loaded and labels were extracted.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG labels (y_eeg) not found. Please ensure the EEG data was loaded and labels were extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41380417",
        "outputId": "4995dc8e-c392-4531-c9ac-f22f570333d3"
      },
      "source": [
        "# ===============================\n",
        "# Load and Preprocess ECG Data\n",
        "# ===============================\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mne # MNE might have utilities for physiological data beyond EEG\n",
        "\n",
        "# Assuming the data_dir is already defined from previous steps\n",
        "# data_dir = '/content/EEG_BCI_Hackathon'\n",
        "\n",
        "# Pattern for ECG data directories (assuming similar structure to EEG)\n",
        "ecg_data_dir_pattern = os.path.join(data_dir, 'P{i:02d}', 'P{i:02d}', 'S{s}', 'ecg')\n",
        "\n",
        "# List to store all loaded ECG data (format will depend on the actual file type)\n",
        "all_ecg_data = []\n",
        "\n",
        "print(\"\\nLoading and preprocessing ECG files...\")\n",
        "\n",
        "for i in range(1, 16): # Iterate through participants P01 to P15\n",
        "    for s in range(1, 3): # Iterate through sessions S1 and S2\n",
        "        current_ecg_dir = ecg_data_dir_pattern.format(i=i, s=s)\n",
        "        print(f\"Checking directory for ECG files: {current_ecg_dir}\")\n",
        "\n",
        "        if os.path.exists(current_ecg_dir):\n",
        "            # *** Need to verify actual ECG file extension and loading method ***\n",
        "            # Common formats might be .csv, .txt, .wfdb, etc.\n",
        "            # For now, let's search for any files in the directory and assume they are the ECG data.\n",
        "            # You will likely need to adjust the file pattern and loading code below\n",
        "            # based on the actual ECG file format in the dataset.\n",
        "            ecg_files = glob.glob(os.path.join(current_ecg_dir, '*')) # Search for any file\n",
        "\n",
        "            if ecg_files:\n",
        "                print(f\"Found {len(ecg_files)} potential ECG files in {current_ecg_dir}. Loading the first one as an example.\")\n",
        "                # *** Adjust loading based on actual file format ***\n",
        "                ecg_file_path = ecg_files[0] # Assuming the first file is the ECG data\n",
        "\n",
        "                try:\n",
        "                    # *** Example loading for CSV - Replace with appropriate loader ***\n",
        "                    # If it's a CSV:\n",
        "                    # ecg_data = pd.read_csv(ecg_file_path)\n",
        "                    # If it's another format, use the relevant library (e.g., wfdb for .dat/.hea)\n",
        "                    # For now, just reading as text to inspect (will likely fail for binary data)\n",
        "                    with open(ecg_file_path, 'r', errors='ignore') as f:\n",
        "                         ecg_data_sample = f.read(500) # Read first 500 characters as a sample\n",
        "                    print(f\"Sample of ECG file content ({os.path.basename(ecg_file_path)}):\")\n",
        "                    print(ecg_data_sample)\n",
        "                    print(\"-\" * 20)\n",
        "\n",
        "                    # *** Placeholder for actual ECG data loading ***\n",
        "                    # After identifying the correct format and loader, replace the above text reading\n",
        "                    # with code to load the actual numerical ECG data into a suitable structure (e.g., numpy array, pandas DataFrame)\n",
        "                    # For now, we'll just append a placeholder indicating a file was found.\n",
        "                    all_ecg_data.append({'file_path': ecg_file_path, 'status': 'File found, loading needed'})\n",
        "\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading or sampling file {ecg_file_path}: {e}\")\n",
        "                    all_ecg_data.append({'file_path': ecg_file_path, 'status': f'Error: {e}'})\n",
        "\n",
        "            else:\n",
        "                print(f\"No files found in {current_ecg_dir}. Skipping.\")\n",
        "        else:\n",
        "            print(f\"Directory not found: {current_ecg_dir}. Skipping.\")\n",
        "\n",
        "print(f\"\\nFinished checking all potential ECG directories. Found information for {len(all_ecg_data)} potential ECG files.\")\n",
        "\n",
        "# ===============================\n",
        "# Preprocessing Placeholder for ECG\n",
        "# ===============================\n",
        "print(\"\\nProceeding with ECG Preprocessing steps (placeholders):\")\n",
        "\n",
        "def preprocess_ecg(raw_ecg_data):\n",
        "    \"\"\"\n",
        "    Placeholder function to preprocess raw ECG data.\n",
        "    (Adapt this based on the actual loaded ECG data format and requirements)\n",
        "\n",
        "    Args:\n",
        "        raw_ecg_data: Input raw ECG data (format TBD based on actual data).\n",
        "\n",
        "    Returns:\n",
        "        Preprocessed ECG sequences (format TBD).\n",
        "    \"\"\"\n",
        "    print(\"Preprocessing ECG data...\")\n",
        "\n",
        "    # 1. Filtering (Example - adapt as needed)\n",
        "    # Apply filtering to remove baseline wander, powerline interference, and high-frequency noise.\n",
        "    # Specific filter parameters would be defined here.\n",
        "    # Example placeholder:\n",
        "    # filtered_ecg = apply_ecg_filters(raw_ecg_data)\n",
        "    filtered_ecg = raw_ecg_data # Placeholder\n",
        "\n",
        "    # 2. Segmentation (Example - adapt as needed)\n",
        "    # Segment continuous ECG data into sequences (e.g., fixed-length sequences or R-R interval based).\n",
        "    # The segmentation approach depends on the type of analysis (e.g., time-series analysis, HRV).\n",
        "    # Example placeholder:\n",
        "    # sequence_length_seconds = 10\n",
        "    # sampling_rate = 200 # Hz (example, verify actual sampling rate)\n",
        "    # sequence_length_samples = int(sequence_length_seconds * sampling_rate)\n",
        "    # ecg_sequences = segment_data(filtered_ecg, segment_length=sequence_length_samples, overlap=0)\n",
        "    ecg_sequences = filtered_ecg # Placeholder\n",
        "\n",
        "    # 3. Handle Artifacts/Missing Values (Example - adapt as needed)\n",
        "    # Implement strategies for handling artifacts (e.g., motion artifacts) or missing data.\n",
        "    # This could involve identification and correction of ectopic beats or imputation.\n",
        "    # The specific strategy depends on the nature of the artifacts and missing data.\n",
        "    # Example placeholder:\n",
        "    # cleaned_sequences = handle_ecg_artifacts_and_missing_values(ecg_sequences)\n",
        "    cleaned_sequences = ecg_sequences # Placeholder\n",
        "\n",
        "    # 4. Normalization (Example - adapt as needed)\n",
        "    # Normalize the amplitude of ECG sequences.\n",
        "    # Example placeholder:\n",
        "    # normalized_sequences = normalize_ecg_amplitude(cleaned_sequences)\n",
        "    normalized_sequences = cleaned_sequences # Placeholder\n",
        "\n",
        "    print(\"ECG preprocessing steps defined (placeholders).\")\n",
        "    return normalized_sequences\n",
        "\n",
        "# Note: Actual execution of preprocess_ecg would happen after successfully loading the raw ECG data for all files.\n",
        "print(\"\\nPlaceholder ECG preprocessing function defined.\")\n",
        "\n",
        "# Next step would be to load the actual ECG data using the correct loader and then apply preprocessing."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading and preprocessing ECG files...\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P01/P01/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P01/P01/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P01/P01/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P01/P01/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P02/P02/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P02/P02/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P02/P02/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P02/P02/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P03/P03/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P03/P03/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P03/P03/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P03/P03/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P04/P04/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P04/P04/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P04/P04/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P04/P04/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P05/P05/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P05/P05/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P05/P05/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P05/P05/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P06/P06/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P06/P06/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P06/P06/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P06/P06/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P07/P07/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P07/P07/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P07/P07/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P07/P07/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P08/P08/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P08/P08/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P08/P08/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P08/P08/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P09/P09/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P09/P09/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P09/P09/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P09/P09/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P10/P10/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P10/P10/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P10/P10/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P10/P10/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P11/P11/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P11/P11/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P11/P11/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P11/P11/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P12/P12/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P12/P12/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P12/P12/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P12/P12/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P13/P13/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P13/P13/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P13/P13/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P13/P13/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P14/P14/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P14/P14/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P14/P14/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P14/P14/S2/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P15/P15/S1/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P15/P15/S1/ecg. Skipping.\n",
            "Checking directory for ECG files: /content/EEG_BCI_Hackathon/P15/P15/S2/ecg\n",
            "Directory not found: /content/EEG_BCI_Hackathon/P15/P15/S2/ecg. Skipping.\n",
            "\n",
            "Finished checking all potential ECG directories. Found information for 0 potential ECG files.\n",
            "\n",
            "Proceeding with ECG Preprocessing steps (placeholders):\n",
            "\n",
            "Placeholder ECG preprocessing function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "d71cc40d",
        "outputId": "b9679e58-716f-45e7-be3d-e5ebd3e8f2f4"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Measurement  \\\n",
              "0                                        Duration (h)   \n",
              "1                                        % Efficiency   \n",
              "2                                         Latency (h)   \n",
              "3                                             WASO **   \n",
              "4                                             Quality   \n",
              "5                                Number of Awakenings   \n",
              "6                                                 NaN   \n",
              "7                *  Values are Mean SEM of 8 subjects   \n",
              "8                          **  Wake after sleep onset   \n",
              "9                                                 NaN   \n",
              "10                                                NaN   \n",
              "11                                         Reference:   \n",
              "12  Putcha L, Nimmagudda R, and Rivera C. Assessme...   \n",
              "13  In : Lane HW, Sauer RL, and Feeback DL, eds. I...   \n",
              "14  American Astronautical Society Science and Tec...   \n",
              "\n",
              "   Objective Measurement - Baseline Objective Measurement - Chamber  \\\n",
              "0                         6.62±0.31                       6.00±0.24   \n",
              "1                        88.50±1.44                      88.10±1.73   \n",
              "2                         0.27±0.06                       0.20±0.05   \n",
              "3                         0.90±0.12                       0.86±0.15   \n",
              "4                               NaN                             NaN   \n",
              "5                         4.65±1.43                       4.22±0.59   \n",
              "6                               NaN                             NaN   \n",
              "7                               NaN                             NaN   \n",
              "8                               NaN                             NaN   \n",
              "9                               NaN                             NaN   \n",
              "10                              NaN                             NaN   \n",
              "11                              NaN                             NaN   \n",
              "12                              NaN                             NaN   \n",
              "13                              NaN                             NaN   \n",
              "14                              NaN                             NaN   \n",
              "\n",
              "   Subjective Measurement - Baseline Subjective Measurement - Chamber  \n",
              "0                          6.78±0.27                        6.21±0.21  \n",
              "1                         96.40±1.16                       95.66±1.03  \n",
              "2                          0.20±0.05                        0.24±0.05  \n",
              "3                                NaN                              NaN  \n",
              "4                          1.31±0.11                        1.08±0.21  \n",
              "5                          7.11±0.31                        7.33±0.30  \n",
              "6                                NaN                              NaN  \n",
              "7                                NaN                              NaN  \n",
              "8                                NaN                              NaN  \n",
              "9                                NaN                              NaN  \n",
              "10                               NaN                              NaN  \n",
              "11                               NaN                              NaN  \n",
              "12                               NaN                              NaN  \n",
              "13                               NaN                              NaN  \n",
              "14                               NaN                              NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35aa58c9-91ff-40c1-a1cf-4054e5872612\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Objective Measurement - Baseline</th>\n",
              "      <th>Objective Measurement - Chamber</th>\n",
              "      <th>Subjective Measurement - Baseline</th>\n",
              "      <th>Subjective Measurement - Chamber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>6.62±0.31</td>\n",
              "      <td>6.00±0.24</td>\n",
              "      <td>6.78±0.27</td>\n",
              "      <td>6.21±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>88.50±1.44</td>\n",
              "      <td>88.10±1.73</td>\n",
              "      <td>96.40±1.16</td>\n",
              "      <td>95.66±1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>0.27±0.06</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.24±0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>0.90±0.12</td>\n",
              "      <td>0.86±0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.31±0.11</td>\n",
              "      <td>1.08±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Number of Awakenings</td>\n",
              "      <td>4.65±1.43</td>\n",
              "      <td>4.22±0.59</td>\n",
              "      <td>7.11±0.31</td>\n",
              "      <td>7.33±0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>*  Values are Mean SEM of 8 subjects</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>**  Wake after sleep onset</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Reference:</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Putcha L, Nimmagudda R, and Rivera C. Assessme...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>In : Lane HW, Sauer RL, and Feeback DL, eds. I...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>American Astronautical Society Science and Tec...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35aa58c9-91ff-40c1-a1cf-4054e5872612')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35aa58c9-91ff-40c1-a1cf-4054e5872612 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35aa58c9-91ff-40c1-a1cf-4054e5872612');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bb1cc41d-ce81-4503-9ef3-fbeb0857c359\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb1cc41d-ce81-4503-9ef3-fbeb0857c359')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bb1cc41d-ce81-4503-9ef3-fbeb0857c359 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"In : Lane HW, Sauer RL, and Feeback DL, eds. Isolation: NASA Experiments in Closed-Environment Living.  \",\n          \"Putcha L, Nimmagudda R, and Rivera C. Assessment Of Sleep Dynamics In A Simulated Space Station Environment\",\n          \"Duration (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"88.50\\u00b11.44\",\n          \"4.65\\u00b11.43\",\n          \"0.27\\u00b10.06\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"88.10\\u00b11.73\",\n          \"4.22\\u00b10.59\",\n          \"0.20\\u00b10.05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"96.40\\u00b11.16\",\n          \"7.11\\u00b10.31\",\n          \"0.20\\u00b10.05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"95.66\\u00b11.03\",\n          \"7.33\\u00b10.30\",\n          \"0.24\\u00b10.05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96e9d26b",
        "outputId": "2e4e4752-ee01-45f9-be3e-236ab08176eb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "excel_file_path = '/content/unzipped_data/JMGROUNDLMLSTP34_115/JMGROUNDLMLSTP34_115.xls'\n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(excel_file_path, engine='xlrd')\n",
        "    print(df.head())\n",
        "except Exception as e:\n",
        "    print(f\"Error loading the Excel file: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NASA Life Sciences Data Archive (http://lsda.jsc.nasa.gov) Unnamed: 1  \\\n",
            "0                 Investigator Name:  Lakshmi Putcha                NaN   \n",
            "1                Mission (Payload):  GROUND (LMLSTP)                NaN   \n",
            "2  Experiment Name (ID):  Assessment of Sleep Dyn...                NaN   \n",
            "3  File Name/Inventory ID:  JMGROUNDLMLSTP34 _115...                NaN   \n",
            "4                                                NaN                NaN   \n",
            "\n",
            "  Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN        NaN  \n",
            "1        NaN        NaN        NaN  \n",
            "2        NaN        NaN        NaN  \n",
            "3        NaN        NaN        NaN  \n",
            "4        NaN        NaN        NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f85721d5",
        "outputId": "265c9241-8aa2-48d5-dc78-32fadee3ed0c"
      },
      "source": [
        "!unzip /content/10012025-13-42.zip -d /content/unzipped_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/10012025-13-42.zip\n",
            "  inflating: /content/unzipped_data/9d7d6ed8_6419_bdfa_510_44b33c55bfd3.md5sum  \n",
            "   creating: /content/unzipped_data/JMGROUNDLMLSTP34_1/\n",
            "  inflating: /content/unzipped_data/JMGROUNDLMLSTP34_1/JMGROUNDLMLSTP341.xls  \n",
            "   creating: /content/unzipped_data/JMGROUNDLMLSTP34_115/\n",
            "  inflating: /content/unzipped_data/JMGROUNDLMLSTP34_115/JMGROUNDLMLSTP34_115.xls  \n",
            "   creating: /content/unzipped_data/JMGROUNDLMLSTP34_116/\n",
            "  inflating: /content/unzipped_data/JMGROUNDLMLSTP34_116/JMGROUNDLMLSTP34_116.tif  \n",
            "   creating: /content/unzipped_data/JMGROUNDLMLSTP34_117/\n",
            "  inflating: /content/unzipped_data/JMGROUNDLMLSTP34_117/JMGROUNDLMLSTP34_117.tif  \n",
            "   creating: /content/unzipped_data/JMGROUNDLMLSTP34_118/\n",
            "  inflating: /content/unzipped_data/JMGROUNDLMLSTP34_118/JMGROUNDLMLSTP34_118.tif  \n",
            "   creating: /content/unzipped_data/JMGROUNDLMLSTP34_119/\n",
            "  inflating: /content/unzipped_data/JMGROUNDLMLSTP34_119/JMGROUNDLMLSTP34_119.tif  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "962ae524"
      },
      "source": [
        "# Task\n",
        "Clean the data in the DataFrame by removing initial rows and setting the correct header, using the file \"/content/10012025-13-42.zip\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c960abd"
      },
      "source": [
        "## Inspect the dataframe to identify the header rows\n",
        "\n",
        "### Subtask:\n",
        "Inspect the dataframe to identify the header rows.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39457c6f"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the first 20 rows of the dataframe to identify the header row.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "8c9f1f17",
        "outputId": "6e2573ba-1631-429a-c710-dbb1cce656d9"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   NASA Life Sciences Data Archive (http://lsda.jsc.nasa.gov)  \\\n",
              "0                  Investigator Name:  Lakshmi Putcha           \n",
              "1                 Mission (Payload):  GROUND (LMLSTP)           \n",
              "2   Experiment Name (ID):  Assessment of Sleep Dyn...           \n",
              "3   File Name/Inventory ID:  JMGROUNDLMLSTP34 _115...           \n",
              "4                                                 NaN           \n",
              "5                                                 NaN           \n",
              "6              Sleep Variables in Chamber Crewmembers           \n",
              "7                                                 NaN           \n",
              "8                                                 NaN           \n",
              "9                                                 NaN           \n",
              "10                                       Duration (h)           \n",
              "11                                       % Efficiency           \n",
              "12                                        Latency (h)           \n",
              "13                                            WASO **           \n",
              "14                                            Quality           \n",
              "15                               Number of Awakenings           \n",
              "16                                                NaN           \n",
              "17               *  Values are Mean SEM of 8 subjects           \n",
              "18                         **  Wake after sleep onset           \n",
              "19                                                NaN           \n",
              "\n",
              "               Unnamed: 1  Unnamed: 2              Unnamed: 3  Unnamed: 4  \n",
              "0                     NaN         NaN                     NaN         NaN  \n",
              "1                     NaN         NaN                     NaN         NaN  \n",
              "2                     NaN         NaN                     NaN         NaN  \n",
              "3                     NaN         NaN                     NaN         NaN  \n",
              "4                     NaN         NaN                     NaN         NaN  \n",
              "5                     NaN         NaN                     NaN         NaN  \n",
              "6                     NaN         NaN                     NaN         NaN  \n",
              "7                     NaN         NaN                     NaN         NaN  \n",
              "8   Objective Measurement         NaN  Subjective Measurement         NaN  \n",
              "9                Baseline     Chamber                Baseline     Chamber  \n",
              "10              6.62±0.31   6.00±0.24               6.78±0.27   6.21±0.21  \n",
              "11             88.50±1.44  88.10±1.73              96.40±1.16  95.66±1.03  \n",
              "12              0.27±0.06   0.20±0.05               0.20±0.05   0.24±0.05  \n",
              "13              0.90±0.12   0.86±0.15                     NaN         NaN  \n",
              "14                    NaN         NaN               1.31±0.11   1.08±0.21  \n",
              "15              4.65±1.43   4.22±0.59               7.11±0.31   7.33±0.30  \n",
              "16                    NaN         NaN                     NaN         NaN  \n",
              "17                    NaN         NaN                     NaN         NaN  \n",
              "18                    NaN         NaN                     NaN         NaN  \n",
              "19                    NaN         NaN                     NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2fcbca1-464c-45db-a8c3-dcd721370465\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NASA Life Sciences Data Archive (http://lsda.jsc.nasa.gov)</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Investigator Name:  Lakshmi Putcha</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mission (Payload):  GROUND (LMLSTP)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Experiment Name (ID):  Assessment of Sleep Dyn...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>File Name/Inventory ID:  JMGROUNDLMLSTP34 _115...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sleep Variables in Chamber Crewmembers</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Objective Measurement</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Subjective Measurement</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>Chamber</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>Chamber</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>6.62±0.31</td>\n",
              "      <td>6.00±0.24</td>\n",
              "      <td>6.78±0.27</td>\n",
              "      <td>6.21±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>88.50±1.44</td>\n",
              "      <td>88.10±1.73</td>\n",
              "      <td>96.40±1.16</td>\n",
              "      <td>95.66±1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>0.27±0.06</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.24±0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>0.90±0.12</td>\n",
              "      <td>0.86±0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Quality</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.31±0.11</td>\n",
              "      <td>1.08±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Number of Awakenings</td>\n",
              "      <td>4.65±1.43</td>\n",
              "      <td>4.22±0.59</td>\n",
              "      <td>7.11±0.31</td>\n",
              "      <td>7.33±0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>*  Values are Mean SEM of 8 subjects</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>**  Wake after sleep onset</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2fcbca1-464c-45db-a8c3-dcd721370465')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2fcbca1-464c-45db-a8c3-dcd721370465 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2fcbca1-464c-45db-a8c3-dcd721370465');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-40bdc12e-6543-4e13-b15c-813023476998\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40bdc12e-6543-4e13-b15c-813023476998')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-40bdc12e-6543-4e13-b15c-813023476998 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"NASA Life Sciences Data Archive (http://lsda.jsc.nasa.gov)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Investigator Name:  Lakshmi Putcha\",\n          \"Mission (Payload):  GROUND (LMLSTP)\",\n          \"Duration (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Objective Measurement\",\n          \"Baseline\",\n          \"0.90\\u00b10.12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Chamber\",\n          \"6.00\\u00b10.24\",\n          \"4.22\\u00b10.59\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Subjective Measurement\",\n          \"Baseline\",\n          \"1.31\\u00b10.11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Chamber\",\n          \"6.21\\u00b10.21\",\n          \"7.33\\u00b10.30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df6257df"
      },
      "source": [
        "## Load the data again with the correct header\n",
        "\n",
        "### Subtask:\n",
        "Load the data again with the correct header.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a080bdea"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the Excel file again, this time specifying the header row identified in the previous step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "98d6880d",
        "outputId": "e0e0429b-09fb-43dc-c65d-bef8681b30f8"
      },
      "source": [
        "excel_file_path = '/content/unzipped_data/JMGROUNDLMLSTP34_115/JMGROUNDLMLSTP34_115.xls'\n",
        "df = pd.read_excel(excel_file_path, header=9, engine='xlrd')\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Unnamed: 0 Objective Measurement  Unnamed: 2 Subjective Measurement  \\\n",
              "0           NaN              Baseline     Chamber               Baseline   \n",
              "1  Duration (h)             6.62±0.31   6.00±0.24              6.78±0.27   \n",
              "2  % Efficiency            88.50±1.44  88.10±1.73             96.40±1.16   \n",
              "3   Latency (h)             0.27±0.06   0.20±0.05              0.20±0.05   \n",
              "4       WASO **             0.90±0.12   0.86±0.15                    NaN   \n",
              "\n",
              "   Unnamed: 4  \n",
              "0     Chamber  \n",
              "1   6.21±0.21  \n",
              "2  95.66±1.03  \n",
              "3   0.24±0.05  \n",
              "4         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65ae96c0-73e5-4a88-8b08-94f61bc6a140\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Objective Measurement</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Subjective Measurement</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>Chamber</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>Chamber</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>6.62±0.31</td>\n",
              "      <td>6.00±0.24</td>\n",
              "      <td>6.78±0.27</td>\n",
              "      <td>6.21±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>88.50±1.44</td>\n",
              "      <td>88.10±1.73</td>\n",
              "      <td>96.40±1.16</td>\n",
              "      <td>95.66±1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>0.27±0.06</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.24±0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>0.90±0.12</td>\n",
              "      <td>0.86±0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65ae96c0-73e5-4a88-8b08-94f61bc6a140')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65ae96c0-73e5-4a88-8b08-94f61bc6a140 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65ae96c0-73e5-4a88-8b08-94f61bc6a140');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f6f0b336-5a2e-4453-9784-d29523fb2c7b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6f0b336-5a2e-4453-9784-d29523fb2c7b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f6f0b336-5a2e-4453-9784-d29523fb2c7b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"% Efficiency\",\n          \"WASO **\",\n          \"Duration (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"6.62\\u00b10.31\",\n          \"0.90\\u00b10.12\",\n          \"88.50\\u00b11.44\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"6.00\\u00b10.24\",\n          \"0.86\\u00b10.15\",\n          \"88.10\\u00b11.73\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"6.78\\u00b10.27\",\n          \"0.20\\u00b10.05\",\n          \"Baseline\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 4\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"6.21\\u00b10.21\",\n          \"0.24\\u00b10.05\",\n          \"Chamber\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "846b7a59"
      },
      "source": [
        "## Handle multi-level headers (if necessary)\n",
        "\n",
        "### Subtask:\n",
        "Handle multi-level headers (if necessary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "238331ed"
      },
      "source": [
        "**Reasoning**:\n",
        "Inspect the DataFrame's columns to confirm if a multi-level header exists.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "fb09ec02",
        "outputId": "004c8a27-473e-470d-ea7e-5996ce83a990"
      },
      "source": [
        "display(df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Objective Measurement', 'Unnamed: 2',\n",
              "       'Subjective Measurement', 'Unnamed: 4'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b74b621"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous output shows that a multi-level header was not created, but the column names are not descriptive. Rename the columns to be more meaningful.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "7cbceb0e",
        "outputId": "fbf7bbb3-2ecd-4b5e-8b76-d8e98229f4ea"
      },
      "source": [
        "new_column_names = ['Measurement', 'Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                    'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "df.columns = new_column_names\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement Objective Measurement - Baseline  \\\n",
              "0           NaN                         Baseline   \n",
              "1  Duration (h)                        6.62±0.31   \n",
              "2  % Efficiency                       88.50±1.44   \n",
              "3   Latency (h)                        0.27±0.06   \n",
              "4       WASO **                        0.90±0.12   \n",
              "\n",
              "  Objective Measurement - Chamber Subjective Measurement - Baseline  \\\n",
              "0                         Chamber                          Baseline   \n",
              "1                       6.00±0.24                         6.78±0.27   \n",
              "2                      88.10±1.73                        96.40±1.16   \n",
              "3                       0.20±0.05                         0.20±0.05   \n",
              "4                       0.86±0.15                               NaN   \n",
              "\n",
              "  Subjective Measurement - Chamber  \n",
              "0                          Chamber  \n",
              "1                        6.21±0.21  \n",
              "2                       95.66±1.03  \n",
              "3                        0.24±0.05  \n",
              "4                              NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81e214ca-0a0a-42be-9fed-073370576946\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Objective Measurement - Baseline</th>\n",
              "      <th>Objective Measurement - Chamber</th>\n",
              "      <th>Subjective Measurement - Baseline</th>\n",
              "      <th>Subjective Measurement - Chamber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>Chamber</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>Chamber</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>6.62±0.31</td>\n",
              "      <td>6.00±0.24</td>\n",
              "      <td>6.78±0.27</td>\n",
              "      <td>6.21±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>88.50±1.44</td>\n",
              "      <td>88.10±1.73</td>\n",
              "      <td>96.40±1.16</td>\n",
              "      <td>95.66±1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>0.27±0.06</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.24±0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>0.90±0.12</td>\n",
              "      <td>0.86±0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81e214ca-0a0a-42be-9fed-073370576946')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81e214ca-0a0a-42be-9fed-073370576946 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81e214ca-0a0a-42be-9fed-073370576946');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5a5ba69c-1496-4c9f-adaf-6b5695932516\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a5ba69c-1496-4c9f-adaf-6b5695932516')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5a5ba69c-1496-4c9f-adaf-6b5695932516 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"% Efficiency\",\n          \"WASO **\",\n          \"Duration (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"6.62\\u00b10.31\",\n          \"0.90\\u00b10.12\",\n          \"88.50\\u00b11.44\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"6.00\\u00b10.24\",\n          \"0.86\\u00b10.15\",\n          \"88.10\\u00b11.73\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"6.78\\u00b10.27\",\n          \"0.20\\u00b10.05\",\n          \"Baseline\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"6.21\\u00b10.21\",\n          \"0.24\\u00b10.05\",\n          \"Chamber\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f3a4a79"
      },
      "source": [
        "**Reasoning**:\n",
        "The column names have been updated, but the first row still contains redundant header information. Remove the first row to clean the data further.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "509d54ed",
        "outputId": "7a94b595-efbc-4658-e190-5f19019db3ce"
      },
      "source": [
        "df = df.iloc[1:].reset_index(drop=True)\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement Objective Measurement - Baseline  \\\n",
              "0  Duration (h)                        6.62±0.31   \n",
              "1  % Efficiency                       88.50±1.44   \n",
              "2   Latency (h)                        0.27±0.06   \n",
              "3       WASO **                        0.90±0.12   \n",
              "4       Quality                              NaN   \n",
              "\n",
              "  Objective Measurement - Chamber Subjective Measurement - Baseline  \\\n",
              "0                       6.00±0.24                         6.78±0.27   \n",
              "1                      88.10±1.73                        96.40±1.16   \n",
              "2                       0.20±0.05                         0.20±0.05   \n",
              "3                       0.86±0.15                               NaN   \n",
              "4                             NaN                         1.31±0.11   \n",
              "\n",
              "  Subjective Measurement - Chamber  \n",
              "0                        6.21±0.21  \n",
              "1                       95.66±1.03  \n",
              "2                        0.24±0.05  \n",
              "3                              NaN  \n",
              "4                        1.08±0.21  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d90afb4-5448-41fa-96c6-736570f29565\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Objective Measurement - Baseline</th>\n",
              "      <th>Objective Measurement - Chamber</th>\n",
              "      <th>Subjective Measurement - Baseline</th>\n",
              "      <th>Subjective Measurement - Chamber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>6.62±0.31</td>\n",
              "      <td>6.00±0.24</td>\n",
              "      <td>6.78±0.27</td>\n",
              "      <td>6.21±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>88.50±1.44</td>\n",
              "      <td>88.10±1.73</td>\n",
              "      <td>96.40±1.16</td>\n",
              "      <td>95.66±1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>0.27±0.06</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.24±0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>0.90±0.12</td>\n",
              "      <td>0.86±0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.31±0.11</td>\n",
              "      <td>1.08±0.21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d90afb4-5448-41fa-96c6-736570f29565')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d90afb4-5448-41fa-96c6-736570f29565 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d90afb4-5448-41fa-96c6-736570f29565');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-96d040f9-8c69-4c1e-a406-0c30c5e05bd5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96d040f9-8c69-4c1e-a406-0c30c5e05bd5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-96d040f9-8c69-4c1e-a406-0c30c5e05bd5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"% Efficiency\",\n          \"Quality\",\n          \"Latency (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"88.50\\u00b11.44\",\n          \"0.90\\u00b10.12\",\n          \"6.62\\u00b10.31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"88.10\\u00b11.73\",\n          \"0.86\\u00b10.15\",\n          \"6.00\\u00b10.24\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"96.40\\u00b11.16\",\n          \"1.31\\u00b10.11\",\n          \"6.78\\u00b10.27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"95.66\\u00b11.03\",\n          \"1.08\\u00b10.21\",\n          \"6.21\\u00b10.21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fdfadba"
      },
      "source": [
        "## Inspect the cleaned dataframe\n",
        "\n",
        "### Subtask:\n",
        "Inspect the cleaned dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4950840b"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the first few rows and the info of the dataframe to inspect the cleaned data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "a2bd3836",
        "outputId": "bc3a1feb-25ea-41bf-f7de-4f3faa532d7e"
      },
      "source": [
        "display(df.head())\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement Objective Measurement - Baseline  \\\n",
              "0  Duration (h)                        6.62±0.31   \n",
              "1  % Efficiency                       88.50±1.44   \n",
              "2   Latency (h)                        0.27±0.06   \n",
              "3       WASO **                        0.90±0.12   \n",
              "4       Quality                              NaN   \n",
              "\n",
              "  Objective Measurement - Chamber Subjective Measurement - Baseline  \\\n",
              "0                       6.00±0.24                         6.78±0.27   \n",
              "1                      88.10±1.73                        96.40±1.16   \n",
              "2                       0.20±0.05                         0.20±0.05   \n",
              "3                       0.86±0.15                               NaN   \n",
              "4                             NaN                         1.31±0.11   \n",
              "\n",
              "  Subjective Measurement - Chamber  \n",
              "0                        6.21±0.21  \n",
              "1                       95.66±1.03  \n",
              "2                        0.24±0.05  \n",
              "3                              NaN  \n",
              "4                        1.08±0.21  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db4622cd-da67-4477-b067-b8c0c9eedd82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Objective Measurement - Baseline</th>\n",
              "      <th>Objective Measurement - Chamber</th>\n",
              "      <th>Subjective Measurement - Baseline</th>\n",
              "      <th>Subjective Measurement - Chamber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>6.62±0.31</td>\n",
              "      <td>6.00±0.24</td>\n",
              "      <td>6.78±0.27</td>\n",
              "      <td>6.21±0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>88.50±1.44</td>\n",
              "      <td>88.10±1.73</td>\n",
              "      <td>96.40±1.16</td>\n",
              "      <td>95.66±1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>0.27±0.06</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.20±0.05</td>\n",
              "      <td>0.24±0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>0.90±0.12</td>\n",
              "      <td>0.86±0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.31±0.11</td>\n",
              "      <td>1.08±0.21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db4622cd-da67-4477-b067-b8c0c9eedd82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db4622cd-da67-4477-b067-b8c0c9eedd82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db4622cd-da67-4477-b067-b8c0c9eedd82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9a087f08-9f01-4f9a-b3fb-d1951f0526f7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a087f08-9f01-4f9a-b3fb-d1951f0526f7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9a087f08-9f01-4f9a-b3fb-d1951f0526f7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"% Efficiency\",\n          \"Quality\",\n          \"Latency (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"88.50\\u00b11.44\",\n          \"0.90\\u00b10.12\",\n          \"6.62\\u00b10.31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"88.10\\u00b11.73\",\n          \"0.86\\u00b10.15\",\n          \"6.00\\u00b10.24\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"96.40\\u00b11.16\",\n          \"1.31\\u00b10.11\",\n          \"6.78\\u00b10.27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"95.66\\u00b11.03\",\n          \"1.08\\u00b10.21\",\n          \"6.21\\u00b10.21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15 entries, 0 to 14\n",
            "Data columns (total 5 columns):\n",
            " #   Column                             Non-Null Count  Dtype \n",
            "---  ------                             --------------  ----- \n",
            " 0   Measurement                        12 non-null     object\n",
            " 1   Objective Measurement - Baseline   5 non-null      object\n",
            " 2   Objective Measurement - Chamber    5 non-null      object\n",
            " 3   Subjective Measurement - Baseline  5 non-null      object\n",
            " 4   Subjective Measurement - Chamber   5 non-null      object\n",
            "dtypes: object(5)\n",
            "memory usage: 732.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f4fc0a2"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The header information was spread across multiple rows in the original data, with specific column names located in row 10 (0-based index 9).\n",
        "*   Loading the data with `header=9` correctly set the row at index 9 as the header, but did not create a multi-level header.\n",
        "*   The first row of the loaded DataFrame contained redundant header information from the original file structure.\n",
        "*   After cleaning, the DataFrame has 15 rows and the columns are named 'Measurement', 'Objective Measurement - Baseline', 'Objective Measurement - Chamber', 'Subjective Measurement - Baseline', and 'Subjective Measurement - Chamber'.\n",
        "*   Only the 'Measurement' column has a significant number of non-null values (12 out of 15), while the other measurement columns each have only 5 non-null values.\n",
        "*   All columns in the cleaned DataFrame are currently of the 'object' data type.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Convert the measurement columns to a numeric data type to enable quantitative analysis.\n",
        "*   Investigate the reason for the high number of missing values in the measurement columns and determine how to handle them (e.g., imputation, removal of rows/columns).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6106bc24"
      },
      "source": [
        "# Task\n",
        "Handle missing values in the measurement columns of the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "636db770"
      },
      "source": [
        "## Convert measurement columns to numeric\n",
        "\n",
        "### Subtask:\n",
        "Convert the data type of the measurement columns to numeric, handling any errors by coercing them to NaN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8938d05"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the measurement columns to numeric, coercing errors to NaN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "b0280363",
        "outputId": "b7f005a0-458c-406d-92c1-e4ef9b21953b"
      },
      "source": [
        "measurement_columns = ['Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                       'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "\n",
        "for col in measurement_columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "display(df.head())\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement  Objective Measurement - Baseline  \\\n",
              "0  Duration (h)                               NaN   \n",
              "1  % Efficiency                               NaN   \n",
              "2   Latency (h)                               NaN   \n",
              "3       WASO **                               NaN   \n",
              "4       Quality                               NaN   \n",
              "\n",
              "   Objective Measurement - Chamber  Subjective Measurement - Baseline  \\\n",
              "0                              NaN                                NaN   \n",
              "1                              NaN                                NaN   \n",
              "2                              NaN                                NaN   \n",
              "3                              NaN                                NaN   \n",
              "4                              NaN                                NaN   \n",
              "\n",
              "   Subjective Measurement - Chamber  \n",
              "0                               NaN  \n",
              "1                               NaN  \n",
              "2                               NaN  \n",
              "3                               NaN  \n",
              "4                               NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66b8ce1b-9a18-4ffa-986f-d278081963ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Objective Measurement - Baseline</th>\n",
              "      <th>Objective Measurement - Chamber</th>\n",
              "      <th>Subjective Measurement - Baseline</th>\n",
              "      <th>Subjective Measurement - Chamber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66b8ce1b-9a18-4ffa-986f-d278081963ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66b8ce1b-9a18-4ffa-986f-d278081963ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66b8ce1b-9a18-4ffa-986f-d278081963ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f0b16dbb-8480-47da-9871-ec2fd3e90ffd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0b16dbb-8480-47da-9871-ec2fd3e90ffd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f0b16dbb-8480-47da-9871-ec2fd3e90ffd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"% Efficiency\",\n          \"Quality\",\n          \"Latency (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Objective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15 entries, 0 to 14\n",
            "Data columns (total 5 columns):\n",
            " #   Column                             Non-Null Count  Dtype  \n",
            "---  ------                             --------------  -----  \n",
            " 0   Measurement                        12 non-null     object \n",
            " 1   Objective Measurement - Baseline   0 non-null      float64\n",
            " 2   Objective Measurement - Chamber    0 non-null      float64\n",
            " 3   Subjective Measurement - Baseline  0 non-null      float64\n",
            " 4   Subjective Measurement - Chamber   0 non-null      float64\n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 732.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d6f15eb"
      },
      "source": [
        "## Inspect missing values\n",
        "\n",
        "### Subtask:\n",
        "Check the number and percentage of missing values in each column.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53c64d66"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate and display the number and percentage of missing values for each column in the dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "160e985f",
        "outputId": "ab5bdd2d-be81-4d44-bce2-0a03c6410164"
      },
      "source": [
        "missing_values = df.isnull().sum()\n",
        "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "print(\"Number of missing values per column:\")\n",
        "print(missing_values)\n",
        "\n",
        "print(\"\\nPercentage of missing values per column:\")\n",
        "print(missing_percentage)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values per column:\n",
            "Measurement                           3\n",
            "Objective Measurement - Baseline     15\n",
            "Objective Measurement - Chamber      15\n",
            "Subjective Measurement - Baseline    15\n",
            "Subjective Measurement - Chamber     15\n",
            "dtype: int64\n",
            "\n",
            "Percentage of missing values per column:\n",
            "Measurement                           20.0\n",
            "Objective Measurement - Baseline     100.0\n",
            "Objective Measurement - Chamber      100.0\n",
            "Subjective Measurement - Baseline    100.0\n",
            "Subjective Measurement - Chamber     100.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fcb96c3"
      },
      "source": [
        "## Handle missing values\n",
        "\n",
        "### Subtask:\n",
        "Handle missing values in the measurement columns of the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0991da30"
      },
      "source": [
        "**Reasoning**:\n",
        "Examine the missing_percentage Series to identify columns with a high percentage of missing values, and then drop those columns as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "7d7ff69a",
        "outputId": "6fa2e61b-cc1e-45ae-8670-2cc8bae7b0f4"
      },
      "source": [
        "print(\"\\nPercentage of missing values per column:\")\n",
        "print(missing_percentage)\n",
        "\n",
        "# Identify columns to drop based on high missing percentage (> 50% as per inspection)\n",
        "columns_to_drop = missing_percentage[missing_percentage > 50].index.tolist()\n",
        "\n",
        "# Drop the identified columns\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "display(df.head())\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Percentage of missing values per column:\n",
            "Measurement                           20.0\n",
            "Objective Measurement - Baseline     100.0\n",
            "Objective Measurement - Chamber      100.0\n",
            "Subjective Measurement - Baseline    100.0\n",
            "Subjective Measurement - Chamber     100.0\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement\n",
              "0  Duration (h)\n",
              "1  % Efficiency\n",
              "2   Latency (h)\n",
              "3       WASO **\n",
              "4       Quality"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6af418b3-69d1-45d3-b469-92f71d2ac998\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6af418b3-69d1-45d3-b469-92f71d2ac998')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6af418b3-69d1-45d3-b469-92f71d2ac998 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6af418b3-69d1-45d3-b469-92f71d2ac998');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-da912fcd-be60-4ec7-811c-8aa417ba12f5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da912fcd-be60-4ec7-811c-8aa417ba12f5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-da912fcd-be60-4ec7-811c-8aa417ba12f5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"% Efficiency\",\n          \"Quality\",\n          \"Latency (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15 entries, 0 to 14\n",
            "Data columns (total 1 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Measurement  12 non-null     object\n",
            "dtypes: object(1)\n",
            "memory usage: 252.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f28bc93"
      },
      "source": [
        "## Inspect the dataframe after handling missing values\n",
        "\n",
        "### Subtask:\n",
        "Inspect the dataframe after handling missing values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cbf2e0"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the head and info of the dataframe to inspect the cleaned data after handling missing values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "d49b2d3f",
        "outputId": "f0af4801-51c7-4dc0-e732-0c3b64938dbb"
      },
      "source": [
        "display(df.head())\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement\n",
              "0  Duration (h)\n",
              "1  % Efficiency\n",
              "2   Latency (h)\n",
              "3       WASO **\n",
              "4       Quality"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1b74f06-6a54-4333-8135-f67b29609fff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1b74f06-6a54-4333-8135-f67b29609fff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1b74f06-6a54-4333-8135-f67b29609fff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1b74f06-6a54-4333-8135-f67b29609fff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cf797fe0-2ee8-49be-a672-e7411d7ee6ab\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf797fe0-2ee8-49be-a672-e7411d7ee6ab')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cf797fe0-2ee8-49be-a672-e7411d7ee6ab button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"% Efficiency\",\n          \"Quality\",\n          \"Latency (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15 entries, 0 to 14\n",
            "Data columns (total 1 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Measurement  12 non-null     object\n",
            "dtypes: object(1)\n",
            "memory usage: 252.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7de71f7"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The data type of the measurement columns ('Objective Measurement - Baseline', 'Objective Measurement - Chamber', 'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber') was successfully converted to numeric (float64), with non-numeric values being coerced to NaN.\n",
        "*   All four original measurement columns ('Objective Measurement - Baseline', 'Objective Measurement - Chamber', 'Subjective Measurement - Baseline', and 'Subjective Measurement - Chamber') were found to have 100% missing values.\n",
        "*   The columns with 100% missing values were successfully dropped from the dataframe.\n",
        "*   After dropping the columns with high missing percentages, the resulting dataframe contains only the 'Measurement' column, which has 12 non-null values out of 15.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Investigate the reason for 100% missing values in the original measurement columns.\n",
        "*   Determine a strategy for handling the remaining missing values in the 'Measurement' column (e.g., imputation, removal of rows).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5d2ede1"
      },
      "source": [
        "# Task\n",
        "Load the EEG and ECG data from the specified NASA datasets (HC2S, SHARP-1, SHARP-2), preprocess the data by filtering and segmentation, extract hand-crafted features, build and train a CNN model on EEG segments, an LSTM model on ECG sequences, and a Random Forest model on hand-crafted features, combine the predictions from these models using voting or stacking, and evaluate the performance of the combined model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2f44a94"
      },
      "source": [
        "## Load eeg/ecg data\n",
        "\n",
        "### Subtask:\n",
        "Load the EEG and ECG data from the specified NASA datasets (HC2S, SHARP-1, SHARP-2).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d4071ec"
      },
      "source": [
        "**Reasoning**:\n",
        "Identify the file paths for the EEG and ECG data from the HC2S, SHARP-1, and SHARP-2 datasets from the unzipped files and then load each of the identified data files into separate pandas DataFrames. Finally, store these DataFrames in a dictionary for easy access and management and display the head and info of each loaded DataFrame to understand their structure and initial content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "d57ca33e",
        "outputId": "e47eace6-8928-41ce-eeba-39df2dc1a700"
      },
      "source": [
        "# File paths for the EEG and ECG data (assuming they are in the unzipped_data directory)\n",
        "# Based on previous steps, we know the sleep data file path. We need to find paths for EEG and ECG.\n",
        "# Let's assume a directory structure or naming convention based on the task description.\n",
        "# If the file names are not immediately obvious from the unzip output, further inspection might be needed.\n",
        "# However, based on the previous code cell that tried to load HRV and ECG files from Google Drive,\n",
        "# let's assume those filenames are correct for the unzipped data as well, potentially in subdirectories.\n",
        "\n",
        "# Based on the unzip output, the structure seems to be /content/unzipped_data/<dataset_name>/<filename>\n",
        "# The previous code attempted to load HRV_dataset_file.xls and ECG_dataset_file.xls.\n",
        "# Let's assume these exist within the relevant dataset folders if not directly in unzipped_data.\n",
        "# Since the task mentions HC2S, SHARP-1, and SHARP-2, and the unzip output shows JMGROUNDLMLSTP34_115 which seems to be related to sleep,\n",
        "# we need to figure out which unzipped files correspond to EEG/ECG for the mentioned datasets.\n",
        "# Let's check the unzipped folders for potential EEG/ECG files.\n",
        "\n",
        "# Given the available files from the unzip output, it seems like the provided zip file\n",
        "# might not contain all the specified datasets (HC2S, SHARP-1, SHARP-2) or the files are named differently.\n",
        "# However, the previous unsuccessful Google Drive mounting code did list 'HRV_dataset_file.xls' and 'ECG_dataset_file.xls'.\n",
        "# It's possible these were intended to be part of the data.\n",
        "# Let's re-examine the unzip output and the original problem description. The original problem description\n",
        "# says \"Load the EEG and ECG data from the specified NASA datasets (HC2S, SHARP-1, SHARP-2)\".\n",
        "# The unzip output shows files related to \"JMGROUNDLMLSTP34\". It does not explicitly mention HC2S, SHARP-1, or SHARP-2.\n",
        "# The previous cells attempted to load files named 'HRV_dataset_file.xls' and 'ECG_dataset_file.xls',\n",
        "# which were assumed to be in a 'NASA_LSDA' folder on Google Drive, but were not found.\n",
        "# The current available files are within '/content/unzipped_data/' and include 'JMGROUNDLMLSTP34_115.xls',\n",
        "# 'JMGROUNDLMLSTP34_1.xls', and .tif files. None of these are explicitly named 'EEG' or 'ECG' or relate to HC2S, SHARP-1, SHARP-2.\n",
        "\n",
        "# There seems to be a mismatch between the task description (HC2S, SHARP-1, SHARP-2 EEG/ECG data)\n",
        "# and the available data from the unzipped file (JMGROUNDLMLSTP34 sleep data and .tif files).\n",
        "# Since I cannot ask the user for clarification and must work with the available data,\n",
        "# I will proceed assuming that the 'JMGROUNDLMLSTP34_115.xls' file, which was used in previous steps and seems to contain sleep data, is the\n",
        "# relevant file for this task, even though the task specifies EEG/ECG and different dataset names.\n",
        "# It's possible the task description is aspirational and the provided data is a sample.\n",
        "\n",
        "# Based on the file names available in the unzipped directory and the previous successful loading of\n",
        "# 'JMGROUNDLMLSTP34_115.xls', I will attempt to load this file again.\n",
        "# I will also check for 'JMGROUNDLMLSTP34_1.xls' to see if it contains similar data, although it's not explicitly mentioned as EEG/ECG.\n",
        "# I will ignore the .tif files as they are image files and not data tables.\n",
        "\n",
        "excel_file_path_115 = '/content/unzipped_data/JMGROUNDLMLSTP34_115/JMGROUNDLMLSTP34_115.xls'\n",
        "excel_file_path_1 = '/content/unzipped_data/JMGROUNDLMLSTP34_1/JMGROUNDLMLSTP341.xls'\n",
        "\n",
        "# Initialize a dictionary to store the dataframes\n",
        "dataframes = {}\n",
        "\n",
        "try:\n",
        "    # Load the 115 file. Use header=9 as determined in previous steps for the relevant data.\n",
        "    df_115 = pd.read_excel(excel_file_path_115, header=9, engine='xlrd')\n",
        "    # Apply the same cleaning steps as before (rename columns, drop first row, drop columns with high missing values)\n",
        "    new_column_names = ['Measurement', 'Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                        'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "    df_115.columns = new_column_names\n",
        "    df_115 = df_115.iloc[1:].reset_index(drop=True)\n",
        "    # Convert measurement columns to numeric, coercing errors\n",
        "    measurement_columns = ['Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                           'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "    for col in measurement_columns:\n",
        "        df_115[col] = pd.to_numeric(df_115[col], errors='coerce')\n",
        "    # Drop columns with 100% missing values\n",
        "    missing_percentage_115 = (df_115.isnull().sum() / len(df_115)) * 100\n",
        "    columns_to_drop_115 = missing_percentage_115[missing_percentage_115 == 100].index.tolist()\n",
        "    df_115 = df_115.drop(columns=columns_to_drop_115)\n",
        "\n",
        "\n",
        "    dataframes['JMGROUNDLMLSTP34_115'] = df_115\n",
        "\n",
        "    print(\"Loaded and cleaned JMGROUNDLMLSTP34_115.xls:\")\n",
        "    display(df_115.head())\n",
        "    df_115.info()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading or cleaning {excel_file_path_115}: {e}\")\n",
        "\n",
        "try:\n",
        "    # Load the 1 file. Let's assume it has a similar structure and use header=9 as a starting point.\n",
        "    df_1 = pd.read_excel(excel_file_path_1, header=9, engine='xlrd')\n",
        "    # Apply similar cleaning steps\n",
        "    new_column_names = ['Measurement', 'Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                        'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "    df_1.columns = new_column_names\n",
        "    df_1 = df_1.iloc[1:].reset_index(drop=True)\n",
        "    # Convert measurement columns to numeric, coercing errors\n",
        "    measurement_columns = ['Objective Measurement - Baseline', 'Objective Measurement - Chamber',\n",
        "                           'Subjective Measurement - Baseline', 'Subjective Measurement - Chamber']\n",
        "    for col in measurement_columns:\n",
        "        df_1[col] = pd.to_numeric(df_1[col], errors='coerce')\n",
        "    # Drop columns with 100% missing values\n",
        "    missing_percentage_1 = (df_1.isnull().sum() / len(df_1)) * 100\n",
        "    columns_to_drop_1 = missing_percentage_1[missing_percentage_1 == 100].index.tolist()\n",
        "    df_1 = df_1.drop(columns=columns_to_drop_1)\n",
        "\n",
        "    dataframes['JMGROUNDLMLSTP34_1'] = df_1\n",
        "\n",
        "    print(\"\\nLoaded and cleaned JMGROUNDLMLSTP34_1.xls:\")\n",
        "    display(df_1.head())\n",
        "    df_1.info()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading or cleaning {excel_file_path_1}: {e}\")\n",
        "\n",
        "# Check if any dataframes were loaded\n",
        "if not dataframes:\n",
        "    print(\"\\nNo dataframes were successfully loaded.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded and cleaned JMGROUNDLMLSTP34_115.xls:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Measurement\n",
              "0  Duration (h)\n",
              "1  % Efficiency\n",
              "2   Latency (h)\n",
              "3       WASO **\n",
              "4       Quality"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8811a2a-fb5f-4546-82a5-702386cc1705\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duration (h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>% Efficiency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Latency (h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASO **</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quality</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8811a2a-fb5f-4546-82a5-702386cc1705')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f8811a2a-fb5f-4546-82a5-702386cc1705 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f8811a2a-fb5f-4546-82a5-702386cc1705');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3d6bcdcf-8a84-4072-a8a9-9cfb759cb077\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d6bcdcf-8a84-4072-a8a9-9cfb759cb077')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3d6bcdcf-8a84-4072-a8a9-9cfb759cb077 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\\\nNo dataframes were successfully loaded\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"% Efficiency\",\n          \"Quality\",\n          \"Latency (h)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15 entries, 0 to 14\n",
            "Data columns (total 1 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Measurement  12 non-null     object\n",
            "dtypes: object(1)\n",
            "memory usage: 252.0+ bytes\n",
            "\n",
            "Loaded and cleaned JMGROUNDLMLSTP34_1.xls:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                     Measurement  Subjective Measurement - Chamber\n",
              "0            Parameters Measured                               NaN\n",
              "1  Melatonin acrophase, saliva\\n                               NaN\n",
              "2                 Hardware Items                               NaN\n",
              "3          Saliva Collection Kit                             125.0\n",
              "4    Table of Sessions Performed                               NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0aa082a2-aa12-41cc-ab77-e338c0ff9410\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Subjective Measurement - Chamber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Parameters Measured</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Melatonin acrophase, saliva\\n</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hardware Items</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Saliva Collection Kit</td>\n",
              "      <td>125.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Table of Sessions Performed</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0aa082a2-aa12-41cc-ab77-e338c0ff9410')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0aa082a2-aa12-41cc-ab77-e338c0ff9410 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0aa082a2-aa12-41cc-ab77-e338c0ff9410');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-21a20a08-ddbe-423a-882f-57b63bb90da1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21a20a08-ddbe-423a-882f-57b63bb90da1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-21a20a08-ddbe-423a-882f-57b63bb90da1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\\\nNo dataframes were successfully loaded\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Measurement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Melatonin acrophase, saliva\\n\",\n          \"Table of Sessions Performed\",\n          \"Hardware Items\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective Measurement - Chamber\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 125.0,\n        \"max\": 125.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          125.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28 entries, 0 to 27\n",
            "Data columns (total 2 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   Measurement                       27 non-null     object \n",
            " 1   Subjective Measurement - Chamber  1 non-null      float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 580.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48e17a15"
      },
      "source": [
        "## Preprocess eeg/ecg data\n",
        "\n",
        "### Subtask:\n",
        "Preprocess eeg/ecg data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2382611"
      },
      "source": [
        "**Reasoning**:\n",
        "Define placeholder functions for EEG and ECG preprocessing steps as instructed, including comments about where specific parameters would be implemented.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a858987",
        "outputId": "846cb9de-0c80-41da-e2d1-e7995efe6907"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_eeg(raw_eeg_data):\n",
        "    \"\"\"\n",
        "    Placeholder function to preprocess raw EEG data.\n",
        "\n",
        "    Args:\n",
        "        raw_eeg_data: Input raw EEG data (format TBD based on actual data).\n",
        "\n",
        "    Returns:\n",
        "        Preprocessed EEG segments (format TBD).\n",
        "    \"\"\"\n",
        "    print(\"Preprocessing EEG data...\")\n",
        "\n",
        "    # 1. Filtering\n",
        "    # Apply band-pass filter to remove unwanted frequencies (e.g., 0.5-40 Hz for sleep EEG)\n",
        "    # Specific filter parameters (cutoff frequencies, filter order, type) would be defined here.\n",
        "    # Example placeholder:\n",
        "    # filtered_eeg = apply_bandpass_filter(raw_eeg_data, lowcut=0.5, highcut=40, fs=sampling_rate)\n",
        "    filtered_eeg = raw_eeg_data # Placeholder\n",
        "\n",
        "    # 2. Segmentation\n",
        "    # Segment continuous EEG data into fixed-length epochs (e.g., 30-second epochs for sleep staging)\n",
        "    # Epoch length and overlap would be defined here.\n",
        "    # Example placeholder:\n",
        "    # epoch_length_seconds = 30\n",
        "    # sampling_rate = 100 # Hz (example)\n",
        "    # epoch_length_samples = epoch_length_seconds * sampling_rate\n",
        "    # eeg_segments = segment_data(filtered_eeg, segment_length=epoch_length_samples, overlap=0)\n",
        "    eeg_segments = filtered_eeg # Placeholder\n",
        "\n",
        "    # 3. Handle Artifacts/Missing Values\n",
        "    # Implement strategies for handling artifacts (e.g., eye blinks, muscle activity) or missing data.\n",
        "    # This could involve rejection of contaminated epochs, imputation, or correction methods.\n",
        "    # The specific strategy depends on the nature of the artifacts and missing data in the actual dataset.\n",
        "    # Example placeholder:\n",
        "    # cleaned_segments = handle_artifacts_and_missing_values(eeg_segments)\n",
        "    cleaned_segments = eeg_segments # Placeholder\n",
        "\n",
        "    # 4. Normalization\n",
        "    # Normalize the amplitude of EEG segments (e.g., z-score normalization, min-max scaling).\n",
        "    # The normalization method would be chosen based on the data distribution and model requirements.\n",
        "    # Example placeholder:\n",
        "    # normalized_segments = z_score_normalize(cleaned_segments)\n",
        "    normalized_segments = cleaned_segments # Placeholder\n",
        "\n",
        "    print(\"EEG preprocessing steps defined.\")\n",
        "    return normalized_segments\n",
        "\n",
        "def preprocess_ecg(raw_ecg_data):\n",
        "    \"\"\"\n",
        "    Placeholder function to preprocess raw ECG data.\n",
        "\n",
        "    Args:\n",
        "        raw_ecg_data: Input raw ECG data (format TBD based on actual data).\n",
        "\n",
        "    Returns:\n",
        "        Preprocessed ECG sequences (format TBD).\n",
        "    \"\"\"\n",
        "    print(\"Preprocessing ECG data...\")\n",
        "\n",
        "    # 1. Filtering\n",
        "    # Apply filtering to remove baseline wander, powerline interference, and high-frequency noise.\n",
        "    # Specific filter parameters would be defined here.\n",
        "    # Example placeholder:\n",
        "    # filtered_ecg = apply_ecg_filters(raw_ecg_data)\n",
        "    filtered_ecg = raw_ecg_data # Placeholder\n",
        "\n",
        "    # 2. Segmentation\n",
        "    # Segment continuous ECG data into sequences (e.g., fixed-length sequences or R-R interval based).\n",
        "    # The segmentation approach depends on the type of analysis (e.g., time-series analysis, HRV).\n",
        "    # Example placeholder:\n",
        "    # sequence_length_seconds = 10\n",
        "    # sampling_rate = 200 # Hz (example)\n",
        "    # sequence_length_samples = sequence_length_seconds * sampling_rate\n",
        "    # ecg_sequences = segment_data(filtered_ecg, segment_length=sequence_length_samples, overlap=0)\n",
        "    ecg_sequences = filtered_ecg # Placeholder\n",
        "\n",
        "    # 3. Handle Artifacts/Missing Values\n",
        "    # Implement strategies for handling artifacts (e.g., motion artifacts) or missing data.\n",
        "    # This could involve identification and correction of ectopic beats or imputation.\n",
        "    # The specific strategy depends on the nature of the artifacts and missing data.\n",
        "    # Example placeholder:\n",
        "    # cleaned_sequences = handle_ecg_artifacts_and_missing_values(ecg_sequences)\n",
        "    cleaned_sequences = ecg_sequences # Placeholder\n",
        "\n",
        "    # 4. Normalization\n",
        "    # Normalize the amplitude of ECG sequences.\n",
        "    # Example placeholder:\n",
        "    # normalized_sequences = normalize_ecg_amplitude(cleaned_sequences)\n",
        "    normalized_sequences = cleaned_sequences # Placeholder\n",
        "\n",
        "    print(\"ECG preprocessing steps defined.\")\n",
        "    return normalized_sequences\n",
        "\n",
        "print(\"Placeholder preprocessing functions for EEG and ECG defined.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Placeholder preprocessing functions for EEG and ECG defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "999cc774"
      },
      "source": [
        "## Extract hand-crafted features\n",
        "\n",
        "### Subtask:\n",
        "Identify and compute relevant hand-crafted features from the preprocessed EEG and ECG data for use with the Random Forest model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f630b7d1"
      },
      "source": [
        "**Reasoning**:\n",
        "Define placeholder functions for extracting hand-crafted features from preprocessed EEG and ECG data, including comments about potential features and print statements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0523a305",
        "outputId": "58d2aa2b-4dea-45b8-dc4a-3b89e47a54ff"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def extract_eeg_features(preprocessed_eeg_segments):\n",
        "    \"\"\"\n",
        "    Placeholder function to extract hand-crafted features from preprocessed EEG segments.\n",
        "\n",
        "    Args:\n",
        "        preprocessed_eeg_segments: Preprocessed EEG data segments (format TBD).\n",
        "\n",
        "    Returns:\n",
        "        DataFrame containing extracted EEG features.\n",
        "    \"\"\"\n",
        "    print(\"Extracting hand-crafted features from EEG data...\")\n",
        "\n",
        "    # Initialize a list to store features for each segment\n",
        "    features_list = []\n",
        "\n",
        "    # Assuming preprocessed_eeg_segments is an iterable of segments\n",
        "    # for segment in preprocessed_eeg_segments:\n",
        "        # Placeholder for feature calculations:\n",
        "        # Calculate Power Spectral Density (PSD) in different frequency bands (e.g., Delta, Theta, Alpha, Beta, Gamma)\n",
        "        # psd_features = calculate_psd(segment)\n",
        "\n",
        "        # Calculate Hjorth parameters (Activity, Mobility, Complexity)\n",
        "        # hjorth_features = calculate_hjorth_parameters(segment)\n",
        "\n",
        "        # Calculate statistical features (mean, variance, skewness, kurtosis, min, max)\n",
        "        # statistical_features = calculate_statistical_features(segment)\n",
        "\n",
        "        # Combine features for the current segment\n",
        "        # segment_features = {**psd_features, **hjorth_features, **statistical_features}\n",
        "        # features_list.append(segment_features)\n",
        "\n",
        "    # Create a DataFrame from the extracted features\n",
        "    # features_df = pd.DataFrame(features_list)\n",
        "\n",
        "    # Placeholder: Return an empty DataFrame or a placeholder structure\n",
        "    features_df = pd.DataFrame() # Replace with actual feature extraction logic\n",
        "\n",
        "    print(\"EEG feature extraction steps defined.\")\n",
        "    return features_df\n",
        "\n",
        "def extract_ecg_features(preprocessed_ecg_sequences):\n",
        "    \"\"\"\n",
        "    Placeholder function to extract hand-crafted features from preprocessed ECG sequences.\n",
        "\n",
        "    Args:\n",
        "        preprocessed_ecg_sequences: Preprocessed ECG data sequences (format TBD).\n",
        "\n",
        "    Returns:\n",
        "        DataFrame containing extracted ECG features.\n",
        "    \"\"\"\n",
        "    print(\"Extracting hand-crafted features from ECG data...\")\n",
        "\n",
        "    # Initialize a list to store features for each sequence\n",
        "    features_list = []\n",
        "\n",
        "    # Assuming preprocessed_ecg_sequences is an iterable of sequences\n",
        "    # for sequence in preprocessed_ecg_sequences:\n",
        "        # Placeholder for feature calculations:\n",
        "        # Calculate Heart Rate Variability (HRV) metrics in time domain (e.g., SDNN, RMSSD, pNN50, HR_mean)\n",
        "        # time_domain_hrv = calculate_time_domain_hrv(sequence)\n",
        "\n",
        "        # Calculate HRV metrics in frequency domain (e.g., LF, HF, LF/HF ratio, Total Power)\n",
        "        # frequency_domain_hrv = calculate_frequency_domain_hrv(sequence)\n",
        "\n",
        "        # Calculate morphological features of the ECG waveform (e.g., QRS duration, PR interval, QT interval, R-peak amplitude)\n",
        "        # morphological_features = calculate_morphological_features(sequence)\n",
        "\n",
        "        # Combine features for the current sequence\n",
        "        # sequence_features = {**time_domain_hrv, **frequency_domain_hrv, **morphological_features}\n",
        "        # features_list.append(sequence_features)\n",
        "\n",
        "    # Create a DataFrame from the extracted features\n",
        "    # features_df = pd.DataFrame(features_list)\n",
        "\n",
        "    # Placeholder: Return an empty DataFrame or a placeholder structure\n",
        "    features_df = pd.DataFrame() # Replace with actual feature extraction logic\n",
        "\n",
        "    print(\"ECG feature extraction steps defined.\")\n",
        "    return features_df\n",
        "\n",
        "print(\"Placeholder feature extraction functions for EEG and ECG defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Placeholder feature extraction functions for EEG and ECG defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8888bac4"
      },
      "source": [
        "## Prepare data for models\n",
        "\n",
        "### Subtask:\n",
        "Format the preprocessed and feature-engineered data into the appropriate input shapes and types required for the CNN, LSTM, and Random Forest models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69b09041"
      },
      "source": [
        "**Reasoning**:\n",
        "Define placeholder variables for the preprocessed data and labels, and outline the steps for splitting the data for model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3c815c6",
        "outputId": "57dcb7c4-eea3-435a-db53-e6be4159bffa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Define placeholder variables for preprocessed data and labels\n",
        "# These placeholders represent the expected data structures after preprocessing and feature extraction.\n",
        "\n",
        "# Placeholder for preprocessed EEG segments\n",
        "# Assuming a shape like (number_of_eeg_segments, number_of_channels, number_of_timesteps)\n",
        "# The actual shape might vary depending on the CNN architecture (1D or 2D) and data format.\n",
        "eeg_segments_placeholder = np.random.rand(100, 16, 500) # Example: 100 segments, 16 channels, 500 timesteps per segment\n",
        "\n",
        "# Placeholder for preprocessed ECG sequences\n",
        "# Assuming a shape like (number_of_ecg_sequences, number_of_timesteps, number_of_features)\n",
        "# If each sequence is just the raw signal, num_features would be 1.\n",
        "ecg_sequences_placeholder = np.random.rand(100, 1000, 1) # Example: 100 sequences, 1000 timesteps, 1 feature (raw signal)\n",
        "\n",
        "# Placeholder for hand-crafted features (combined from EEG and ECG)\n",
        "# Assuming a shape like (number_of_samples, number_of_features)\n",
        "# The number of samples should match the number of segments/sequences if they correspond one-to-one.\n",
        "# The number of features is the total count of hand-crafted features extracted.\n",
        "handcrafted_features_placeholder = pd.DataFrame(np.random.rand(100, 50)) # Example: 100 samples, 50 features\n",
        "\n",
        "# Placeholder for target labels (e.g., sleep stages, stress levels)\n",
        "# Assuming one label per segment/sequence/sample.\n",
        "target_labels_placeholder = np.random.randint(0, 5, 100) # Example: 100 labels, 5 possible classes (0-4)\n",
        "\n",
        "print(\"Placeholder data and labels created.\")\n",
        "\n",
        "# 2. Outline steps for splitting the data into training, validation, and testing sets\n",
        "\n",
        "print(\"\\nSteps for splitting data:\")\n",
        "print(\"Typically, data is split into training, validation, and testing sets.\")\n",
        "print(\"Common splitting ratios:\")\n",
        "print(\"- 80% Training, 10% Validation, 10% Testing\")\n",
        "print(\"- 70% Training, 15% Validation, 15% Testing\")\n",
        "print(\"The split should be applied consistently across all data types (EEG segments, ECG sequences, hand-crafted features) and labels.\")\n",
        "print(\"Stratified splitting is recommended for classification tasks to maintain class distribution.\")\n",
        "\n",
        "# Example (commented out as this is just outlining the steps, not executing the split on placeholders)\n",
        "\"\"\"\n",
        "# First split: Training + Validation vs. Testing (e.g., 80% vs 20%)\n",
        "eeg_train_val, eeg_test, ecg_train_val, ecg_test, features_train_val, features_test, labels_train_val, labels_test = train_test_split(\n",
        "    eeg_segments_placeholder,\n",
        "    ecg_sequences_placeholder,\n",
        "    handcrafted_features_placeholder,\n",
        "    target_labels_placeholder,\n",
        "    test_size=0.2, # Example: 20% for testing\n",
        "    random_state=42, # for reproducibility\n",
        "    stratify=target_labels_placeholder # Stratify if classification\n",
        ")\n",
        "\n",
        "# Second split: Training vs. Validation (e.g., split the 80% into 60% train and 20% validation relative to original size,\n",
        "# which is 75% train and 25% validation of the train_val set)\n",
        "eeg_train, eeg_val, ecg_train, ecg_val, features_train, features_val, labels_train, labels_val = train_test_split(\n",
        "    eeg_train_val,\n",
        "    ecg_train_val,\n",
        "    features_train_val,\n",
        "    labels_train_val,\n",
        "    test_size=0.25, # Example: 25% of train_val set for validation (0.25 * 0.80 = 0.20 of original)\n",
        "    random_state=42,\n",
        "    stratify=labels_train_val # Stratify if classification\n",
        ")\n",
        "\n",
        "print(\"\\nExample split sizes (based on 100 samples with 75/25 train/val split of 80% train_val set):\")\n",
        "print(f\"EEG Train shape: {eeg_train.shape}\")\n",
        "print(f\"EEG Validation shape: {eeg_val.shape}\")\n",
        "print(f\"EEG Test shape: {eeg_test.shape}\")\n",
        "print(f\"ECG Train shape: {ecg_train.shape}\")\n",
        "print(f\"ECG Validation shape: {ecg_val.shape}\")\n",
        "print(f\"ECG Test shape: {ecg_test.shape}\")\n",
        "print(f\"Features Train shape: {features_train.shape}\")\n",
        "print(f\"Features Validation shape: {features_val.shape}\")\n",
        "print(f\"Features Test shape: {features_test.shape}\")\n",
        "print(f\"Labels Train shape: {labels_train.shape}\")\n",
        "print(f\"Labels Validation shape: {labels_val.shape}\")\n",
        "print(f\"Labels Test shape: {labels_test.shape}\")\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nData splitting steps outlined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Placeholder data and labels created.\n",
            "\n",
            "Steps for splitting data:\n",
            "Typically, data is split into training, validation, and testing sets.\n",
            "Common splitting ratios:\n",
            "- 80% Training, 10% Validation, 10% Testing\n",
            "- 70% Training, 15% Validation, 15% Testing\n",
            "The split should be applied consistently across all data types (EEG segments, ECG sequences, hand-crafted features) and labels.\n",
            "Stratified splitting is recommended for classification tasks to maintain class distribution.\n",
            "\n",
            "Data splitting steps outlined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a77de8d8"
      },
      "source": [
        "**Reasoning**:\n",
        "Describe the required input shapes for the CNN, LSTM, and Random Forest models based on the placeholder data structures.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9c4039d",
        "outputId": "6816205b-cf66-4924-c68d-ed565711682b"
      },
      "source": [
        "# 3. Describe input shapes required for each model\n",
        "\n",
        "print(\"\\nDescribing input shapes for models:\")\n",
        "\n",
        "# CNN Model Input Shape (for preprocessed EEG segments)\n",
        "print(\"\\nCNN Model Input Shape (for EEG segments):\")\n",
        "print(\"The required input shape for a CNN depends on its architecture (1D or 2D) and the data format.\")\n",
        "print(f\"Assuming the placeholder EEG segments have shape: {eeg_segments_placeholder.shape}\")\n",
        "print(\"If using a 1D CNN, the input shape typically needs to be `(num_samples, num_timesteps, num_channels)`.\")\n",
        "print(f\"To achieve this from the placeholder, the shape would need to be potentially transposed or rearranged to match: (100, 500, 16)\")\n",
        "print(\"If using a 2D CNN (treating channels as a spatial dimension), the input shape might be `(num_samples, num_channels, num_timesteps, 1)` (for grayscale-like input) or `(num_samples, num_channels, num_timesteps)`.\")\n",
        "print(f\"For the placeholder, this could be: (100, 16, 500, 1) or (100, 16, 500)\")\n",
        "print(\"The exact reshaping/formatting depends on the chosen CNN library (e.g., TensorFlow/Keras, PyTorch) and layer types.\")\n",
        "\n",
        "# LSTM Model Input Shape (for preprocessed ECG sequences)\n",
        "print(\"\\nLSTM Model Input Shape (for ECG sequences):\")\n",
        "print(\"The required input shape for an LSTM model is typically `(num_samples, num_timesteps, num_features)`.\")\n",
        "print(f\"The placeholder ECG sequences have shape: {ecg_sequences_placeholder.shape}\")\n",
        "print(\"This shape is already in the standard format for LSTM input, assuming `num_features` is 1 for the raw signal.\")\n",
        "print(f\"Expected LSTM input shape: (100, 1000, 1)\")\n",
        "print(\"If additional features were extracted per timestep, `num_features` would be greater than 1.\")\n",
        "\n",
        "# Random Forest Model Input Shape (for hand-crafted features)\n",
        "print(\"\\nRandom Forest Model Input Shape (for hand-crafted features):\")\n",
        "print(\"Random Forest models typically expect a 2D input array or DataFrame.\")\n",
        "print(\"The required input shape is `(num_samples, num_features)`.\")\n",
        "print(f\"The placeholder hand-crafted features have shape: {handcrafted_features_placeholder.shape}\")\n",
        "print(\"This shape is already in the standard format for Random Forest input.\")\n",
        "print(f\"Expected Random Forest input shape: (100, 50)\")\n",
        "print(\"The data should be in a numerical format.\")\n",
        "\n",
        "print(\"\\nInput shape descriptions completed.\")\n",
        "\n",
        "# 4. The subtask is completed as we have defined placeholders and described formatting."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Describing input shapes for models:\n",
            "\n",
            "CNN Model Input Shape (for EEG segments):\n",
            "The required input shape for a CNN depends on its architecture (1D or 2D) and the data format.\n",
            "Assuming the placeholder EEG segments have shape: (100, 16, 500)\n",
            "If using a 1D CNN, the input shape typically needs to be `(num_samples, num_timesteps, num_channels)`.\n",
            "To achieve this from the placeholder, the shape would need to be potentially transposed or rearranged to match: (100, 500, 16)\n",
            "If using a 2D CNN (treating channels as a spatial dimension), the input shape might be `(num_samples, num_channels, num_timesteps, 1)` (for grayscale-like input) or `(num_samples, num_channels, num_timesteps)`.\n",
            "For the placeholder, this could be: (100, 16, 500, 1) or (100, 16, 500)\n",
            "The exact reshaping/formatting depends on the chosen CNN library (e.g., TensorFlow/Keras, PyTorch) and layer types.\n",
            "\n",
            "LSTM Model Input Shape (for ECG sequences):\n",
            "The required input shape for an LSTM model is typically `(num_samples, num_timesteps, num_features)`.\n",
            "The placeholder ECG sequences have shape: (100, 1000, 1)\n",
            "This shape is already in the standard format for LSTM input, assuming `num_features` is 1 for the raw signal.\n",
            "Expected LSTM input shape: (100, 1000, 1)\n",
            "If additional features were extracted per timestep, `num_features` would be greater than 1.\n",
            "\n",
            "Random Forest Model Input Shape (for hand-crafted features):\n",
            "Random Forest models typically expect a 2D input array or DataFrame.\n",
            "The required input shape is `(num_samples, num_features)`.\n",
            "The placeholder hand-crafted features have shape: (100, 50)\n",
            "This shape is already in the standard format for Random Forest input.\n",
            "Expected Random Forest input shape: (100, 50)\n",
            "The data should be in a numerical format.\n",
            "\n",
            "Input shape descriptions completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a93c077f"
      },
      "source": [
        "## Build and train cnn model on eeg segments\n",
        "\n",
        "### Subtask:\n",
        "Build and train a Convolutional Neural Network (CNN) model on the prepared EEG segments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d83c751c"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary deep learning libraries, define the CNN model architecture, compile it with an optimizer and loss function, and then train the model using the placeholder data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "91795b1d",
        "outputId": "03511507-d2cf-4a9a-9281-2a5c3ea72046"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input\n",
        "\n",
        "# Assuming the preprocessed EEG segments have the shape (num_samples, num_timesteps, num_channels)\n",
        "# Based on the placeholder from the previous step: eeg_segments_placeholder = np.random.rand(100, 16, 500)\n",
        "# We need to adjust the input shape for the CNN. Let's assume a 1D CNN is suitable for time series data,\n",
        "# and the input shape should be (num_timesteps, num_channels).\n",
        "\n",
        "input_shape = (eeg_segments_placeholder.shape[2], eeg_segments_placeholder.shape[1]) # (500, 16)\n",
        "num_classes = len(np.unique(target_labels_placeholder)) # Number of unique classes in the target labels\n",
        "\n",
        "# Define the CNN model\n",
        "cnn_model = Sequential([\n",
        "    Input(shape=input_shape),\n",
        "    Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(filters=64, kernel_size=5, activation='relu', padding='same'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax') # Use softmax for multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy', # Use sparse_categorical_crossentropy for integer labels\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "print(\"CNN Model Summary:\")\n",
        "cnn_model.summary()\n",
        "\n",
        "# Train the model using placeholder data\n",
        "# Note: This training is on placeholder data and will not yield meaningful results\n",
        "# In a real scenario, you would use your actual train and validation data splits.\n",
        "\n",
        "# Assuming placeholder data needs to be split for training and validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the placeholder data\n",
        "# The CNN expects input shape (num_samples, num_timesteps, num_channels)\n",
        "# Our placeholder is (num_samples, num_channels, num_timesteps)\n",
        "# We need to transpose the placeholder data to match the expected CNN input shape\n",
        "eeg_segments_transposed = np.transpose(eeg_segments_placeholder, (0, 2, 1)) # (100, 500, 16)\n",
        "\n",
        "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(\n",
        "    eeg_segments_transposed,\n",
        "    target_labels_placeholder,\n",
        "    test_size=0.2, # Using 20% for validation as an example\n",
        "    random_state=42,\n",
        "    stratify=target_labels_placeholder # Stratify if classification\n",
        ")\n",
        "\n",
        "print(\"\\nTraining CNN model with placeholder data...\")\n",
        "\n",
        "# Train the model\n",
        "history = cnn_model.fit(X_train_cnn, y_train_cnn,\n",
        "                        epochs=10, # Example: Train for 10 epochs\n",
        "                        batch_size=32, # Example: Batch size of 32\n",
        "                        validation_data=(X_val_cnn, y_val_cnn))\n",
        "\n",
        "print(\"\\nCNN model training completed on placeholder data.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m2,592\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m10,304\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m41,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7936\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,015,936\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,592</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7936</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,015,936</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,070,565\u001b[0m (4.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,070,565</span> (4.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,070,565\u001b[0m (4.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,070,565</span> (4.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training CNN model with placeholder data...\n",
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - accuracy: 0.1414 - loss: 1.9641 - val_accuracy: 0.2000 - val_loss: 1.6468\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.1828 - loss: 1.6898 - val_accuracy: 0.2000 - val_loss: 1.6258\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2164 - loss: 1.6270 - val_accuracy: 0.2000 - val_loss: 1.6030\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.2250 - loss: 1.5864 - val_accuracy: 0.2000 - val_loss: 1.5994\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.3086 - loss: 1.5596 - val_accuracy: 0.2000 - val_loss: 1.6067\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.3234 - loss: 1.5565 - val_accuracy: 0.2000 - val_loss: 1.6015\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.3688 - loss: 1.5071 - val_accuracy: 0.3000 - val_loss: 1.6019\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.4398 - loss: 1.4791 - val_accuracy: 0.2500 - val_loss: 1.5988\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.4469 - loss: 1.4260 - val_accuracy: 0.2500 - val_loss: 1.6016\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.4477 - loss: 1.3962 - val_accuracy: 0.3000 - val_loss: 1.6026\n",
            "\n",
            "CNN model training completed on placeholder data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7deb1dce"
      },
      "source": [
        "## Build and train lstm model on ecg sequences\n",
        "\n",
        "### Subtask:\n",
        "Build and train a Long Short-Term Memory (LSTM) model on the prepared ECG sequences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b74a87a"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the input shape and number of classes, build the LSTM model, compile it, print the summary, split the data, and train the model using the placeholder data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "e177ae2f",
        "outputId": "75782981-c0fb-414d-8ac9-95b8e95a0e65"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define the input shape for the LSTM model\n",
        "# Assuming the preprocessed ECG sequences have the shape (num_samples, num_timesteps, num_features)\n",
        "# Based on the placeholder from the previous step: ecg_sequences_placeholder = np.random.rand(100, 1000, 1)\n",
        "# The input shape for the LSTM layer should be (num_timesteps, num_features).\n",
        "\n",
        "input_shape_lstm = (ecg_sequences_placeholder.shape[1], ecg_sequences_placeholder.shape[2]) # (1000, 1)\n",
        "print(f\"LSTM Input Shape: {input_shape_lstm}\")\n",
        "\n",
        "# 2. Define the number of output classes\n",
        "num_classes = len(np.unique(target_labels_placeholder))\n",
        "print(f\"Number of Output Classes: {num_classes}\")\n",
        "\n",
        "# 3. Build a Sequential Keras model for the LSTM\n",
        "lstm_model = Sequential()\n",
        "\n",
        "# 4. Add an LSTM layer\n",
        "lstm_model.add(Input(shape=input_shape_lstm))\n",
        "lstm_model.add(LSTM(units=64, return_sequences=False)) # Using 64 units as an example, return_sequences=False for classification after the last timestep\n",
        "\n",
        "# 5. Add a Dropout layer\n",
        "lstm_model.add(Dropout(0.5)) # Using 50% dropout as an example\n",
        "\n",
        "# 6. Add a Dense output layer\n",
        "lstm_model.add(Dense(num_classes, activation='softmax')) # Use softmax for multi-class classification\n",
        "\n",
        "# 7. Compile the LSTM model\n",
        "lstm_model.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy', # Use sparse_categorical_crossentropy for integer labels\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "# 8. Print the summary of the LSTM model\n",
        "print(\"\\nLSTM Model Summary:\")\n",
        "lstm_model.summary()\n",
        "\n",
        "# 9. Split the ecg_sequences_placeholder and target_labels_placeholder into training and validation sets\n",
        "# Using the placeholder data for demonstration. In a real scenario, use your actual split data.\n",
        "\n",
        "X_train_lstm, X_val_lstm, y_train_lstm, y_val_lstm = train_test_split(\n",
        "    ecg_sequences_placeholder,\n",
        "    target_labels_placeholder,\n",
        "    test_size=0.2, # Using 20% for validation as an example\n",
        "    random_state=42,\n",
        "    stratify=target_labels_placeholder # Stratify if classification\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining data shape: {X_train_lstm.shape}\")\n",
        "print(f\"Validation data shape: {X_val_lstm.shape}\")\n",
        "\n",
        "# 10. Train the compiled LSTM model using the training data and validate on the validation data\n",
        "print(\"\\nTraining LSTM model with placeholder data...\")\n",
        "\n",
        "history_lstm = lstm_model.fit(X_train_lstm, y_train_lstm,\n",
        "                              epochs=10, # Example: Train for 10 epochs\n",
        "                              batch_size=32, # Example: Batch size of 32\n",
        "                              validation_data=(X_val_lstm, y_val_lstm))\n",
        "\n",
        "# 11. Print a message indicating the completion of LSTM model training on placeholder data\n",
        "print(\"\\nLSTM model training completed on placeholder data.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Input Shape: (1000, 1)\n",
            "Number of Output Classes: 5\n",
            "\n",
            "LSTM Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,221\u001b[0m (67.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,221</span> (67.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,221\u001b[0m (67.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,221</span> (67.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training data shape: (80, 1000, 1)\n",
            "Validation data shape: (20, 1000, 1)\n",
            "\n",
            "Training LSTM model with placeholder data...\n",
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 629ms/step - accuracy: 0.2242 - loss: 1.6055 - val_accuracy: 0.2500 - val_loss: 1.6050\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - accuracy: 0.2797 - loss: 1.5943 - val_accuracy: 0.2500 - val_loss: 1.6027\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - accuracy: 0.2516 - loss: 1.6057 - val_accuracy: 0.2500 - val_loss: 1.6020\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - accuracy: 0.3063 - loss: 1.5956 - val_accuracy: 0.2500 - val_loss: 1.6005\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - accuracy: 0.2656 - loss: 1.6052 - val_accuracy: 0.2500 - val_loss: 1.5996\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - accuracy: 0.2242 - loss: 1.6019 - val_accuracy: 0.2500 - val_loss: 1.5991\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 521ms/step - accuracy: 0.2344 - loss: 1.5973 - val_accuracy: 0.2500 - val_loss: 1.5987\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 341ms/step - accuracy: 0.2703 - loss: 1.5919 - val_accuracy: 0.2500 - val_loss: 1.5985\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - accuracy: 0.2641 - loss: 1.5859 - val_accuracy: 0.2500 - val_loss: 1.5983\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - accuracy: 0.2602 - loss: 1.5942 - val_accuracy: 0.2500 - val_loss: 1.5985\n",
            "\n",
            "LSTM model training completed on placeholder data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b88dc18a"
      },
      "source": [
        "## Build and train random forest model on hand-crafted features\n",
        "\n",
        "### Subtask:\n",
        "Build and train a Random Forest model on the prepared hand-crafted features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9901f803"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the placeholder hand-crafted features and target labels into training and validation sets using `train_test_split` with a test size of 0.2 and `random_state=42`, ensuring stratification. Instantiate a `RandomForestClassifier` with `n_estimators=100` and `random_state=42`. Train the Random Forest model on the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3cfcbf1",
        "outputId": "4c5516d2-1664-4bc0-f5ee-0564717e1d0c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the hand-crafted features and target labels into training and validation sets\n",
        "# Using the placeholder data from the previous step: handcrafted_features_placeholder, target_labels_placeholder\n",
        "X_train_rf, X_val_rf, y_train_rf, y_val_rf = train_test_split(\n",
        "    handcrafted_features_placeholder,\n",
        "    target_labels_placeholder,\n",
        "    test_size=0.2, # Using 20% for validation as an example\n",
        "    random_state=42, # for reproducibility\n",
        "    stratify=target_labels_placeholder # Stratify for classification\n",
        ")\n",
        "\n",
        "print(f\"Handcrafted features training data shape: {X_train_rf.shape}\")\n",
        "print(f\"Handcrafted features validation data shape: {X_val_rf.shape}\")\n",
        "print(f\"Target labels training data shape: {y_train_rf.shape}\")\n",
        "print(f\"Target labels validation data shape: {y_val_rf.shape}\")\n",
        "\n",
        "# Instantiate a RandomForestClassifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest model on the training data\n",
        "print(\"\\nTraining Random Forest model with placeholder data...\")\n",
        "rf_model.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "# Print a message indicating the completion of Random Forest model training on placeholder data\n",
        "print(\"\\nRandom Forest model training completed on placeholder data.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Handcrafted features training data shape: (80, 50)\n",
            "Handcrafted features validation data shape: (20, 50)\n",
            "Target labels training data shape: (80,)\n",
            "Target labels validation data shape: (20,)\n",
            "\n",
            "Training Random Forest model with placeholder data...\n",
            "\n",
            "Random Forest model training completed on placeholder data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bcc8525"
      },
      "source": [
        "## Combine predictions\n",
        "\n",
        "### Subtask:\n",
        "Develop a strategy to combine the predictions from the trained CNN, LSTM, and Random Forest models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a88b9911"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the trained models to make predictions on the validation datasets and then combine these predictions using a voting strategy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a22a4bb",
        "outputId": "d3922bd8-0a5f-47ec-e03f-4674a56a4ca8"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# 1. Generate predictions from each model on the validation datasets\n",
        "\n",
        "# CNN predictions (output probabilities for each class)\n",
        "# The CNN model outputs probabilities for each class\n",
        "cnn_predictions_proba = cnn_model.predict(X_val_cnn)\n",
        "\n",
        "# LSTM predictions (output probabilities for each class)\n",
        "# The LSTM model outputs probabilities for each class\n",
        "lstm_predictions_proba = lstm_model.predict(X_val_lstm)\n",
        "\n",
        "# Random Forest predictions (output class labels)\n",
        "# The Random Forest model directly outputs predicted class labels.\n",
        "# We need probability estimates for voting.\n",
        "rf_predictions_proba = rf_model.predict_proba(X_val_rf)\n",
        "\n",
        "print(\"Predictions generated from CNN, LSTM, and Random Forest models.\")\n",
        "\n",
        "# 2. Implement a voting strategy (Averaging Probabilities)\n",
        "# Since all models can provide probability distributions, we will average the probabilities\n",
        "# and select the class with the highest average probability.\n",
        "\n",
        "# Ensure all probability arrays have the same number of classes and samples\n",
        "# Check shapes and adjust if necessary. Based on previous steps, all models were trained\n",
        "# on the same number of classes and the splits were consistent, so shapes should match\n",
        "# (num_validation_samples, num_classes).\n",
        "\n",
        "print(f\"CNN prediction probabilities shape: {cnn_predictions_proba.shape}\")\n",
        "print(f\"LSTM prediction probabilities shape: {lstm_predictions_proba.shape}\")\n",
        "print(f\"Random Forest prediction probabilities shape: {rf_predictions_proba.shape}\")\n",
        "\n",
        "\n",
        "# Calculate the average probabilities across the three models\n",
        "# Sum the probability arrays and divide by the number of models (3)\n",
        "average_predictions_proba = (cnn_predictions_proba + lstm_predictions_proba + rf_predictions_proba) / 3\n",
        "\n",
        "# Get the class label with the highest average probability for each sample\n",
        "combined_predictions = np.argmax(average_predictions_proba, axis=1)\n",
        "\n",
        "print(\"\\nPredictions combined using averaging of probabilities.\")\n",
        "\n",
        "# 3. Store the combined predictions\n",
        "# The combined_predictions variable now holds the final predicted class labels from the ensemble.\n",
        "\n",
        "print(f\"\\nShape of combined predictions: {combined_predictions.shape}\")\n",
        "print(f\"Combined predictions (first 10): {combined_predictions[:10]}\")\n",
        "\n",
        "# Note: For evaluation, these combined_predictions would be compared against the true labels (y_val_cnn, y_val_lstm, or y_val_rf, which should all be the same)."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
            "Predictions generated from CNN, LSTM, and Random Forest models.\n",
            "CNN prediction probabilities shape: (20, 5)\n",
            "LSTM prediction probabilities shape: (20, 5)\n",
            "Random Forest prediction probabilities shape: (20, 5)\n",
            "\n",
            "Predictions combined using averaging of probabilities.\n",
            "\n",
            "Shape of combined predictions: (20,)\n",
            "Combined predictions (first 10): [2 2 0 0 2 2 0 0 0 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "436f75e0"
      },
      "source": [
        "## Evaluate combined model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the combined model using appropriate metrics on the testing set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad5ea4c9"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the performance of the combined model using appropriate metrics on the validation set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "id": "e6b05060",
        "outputId": "a1ff1252-4ef4-4c17-909a-67b395480247"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Assuming y_val_rf (or y_val_cnn, y_val_lstm) holds the true labels for the validation set.\n",
        "# Since the data splits were stratified and applied consistently across all models,\n",
        "# the true labels for the validation set should be the same regardless of which model's y_val is used.\n",
        "true_labels_val = y_val_rf # Using y_val_rf as the representative true labels for the validation set\n",
        "\n",
        "# 1. Calculate and print the accuracy\n",
        "accuracy = accuracy_score(true_labels_val, combined_predictions)\n",
        "print(f\"Combined Model Accuracy on Validation Set: {accuracy:.4f}\")\n",
        "\n",
        "# 2. Calculate and print the classification report\n",
        "print(\"\\nClassification Report for Combined Model on Validation Set:\")\n",
        "print(classification_report(true_labels_val, combined_predictions))\n",
        "\n",
        "# 3. Calculate and print the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels_val, combined_predictions)\n",
        "print(\"\\nConfusion Matrix for Combined Model on Validation Set:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Optional: Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nCombined model evaluation completed on the validation set.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Model Accuracy on Validation Set: 0.2000\n",
            "\n",
            "Classification Report for Combined Model on Validation Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.60      0.33         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.14      0.25      0.18         4\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.20        20\n",
            "   macro avg       0.07      0.17      0.10        20\n",
            "weighted avg       0.09      0.20      0.12        20\n",
            "\n",
            "\n",
            "Confusion Matrix for Combined Model on Validation Set:\n",
            "[[3 0 2 0 0]\n",
            " [2 0 2 0 0]\n",
            " [3 0 1 0 0]\n",
            " [1 0 2 0 0]\n",
            " [4 0 0 0 0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined model evaluation completed on the validation set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Folder to store data in Colab\n",
        "data_dir = \"/content/EEG_BCI_Hackathon/\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Zenodo direct download URLs (replace with the actual ones from Zenodo)\n",
        "zenodo_urls = [\n",
        "    \"https://zenodo.org/record/4611017/files/P01.zip\",\n",
        "    \"https://zenodo.org/record/4611017/files/P02.zip\",\n",
        "    \"https://zenodo.org/record/4611017/files/P03.zip\",\n",
        "    # ... add P04.zip up to P15.zip\n",
        "]\n",
        "\n",
        "for url in zenodo_urls:\n",
        "    filename = url.split(\"/\")[-1]\n",
        "    filepath = os.path.join(data_dir, filename)\n",
        "\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Downloading {filename} ...\")\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(filepath, \"wb\") as f:\n",
        "            for chunk in r.iter_content(chunk_size=1024):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "        print(f\"Downloaded {filename}\")\n",
        "\n",
        "    # Extract the zip file\n",
        "    extract_path = os.path.join(data_dir, filename.replace(\".zip\",\"\"))\n",
        "    if not os.path.exists(extract_path):\n",
        "        print(f\"Extracting {filename} ...\")\n",
        "        with ZipFile(filepath, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(f\"Extracted {filename}\")"
      ],
      "metadata": {
        "id": "ZRR3eb8hKpfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/content/EEG_BCI_Hackathon/\" # Ensure data_dir is defined\n",
        "\n",
        "for item_name in os.listdir(data_dir):\n",
        "    item_path = os.path.join(data_dir, item_name)\n",
        "    # Check if the item is a directory before calling os.listdir\n",
        "    if os.path.isdir(item_path):\n",
        "        print(item_name, \"contains:\", os.listdir(item_path))\n",
        "    else:\n",
        "        # Optionally print a message for non-directory items\n",
        "        print(f\"{item_name} is not a directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRaj77DsKxug",
        "outputId": "78df78d6-9b31-4c67-f43b-9836e53261a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P09.zip is not a directory.\n",
            "P11.zip is not a directory.\n",
            "P04 contains: ['P04']\n",
            "P02.zip is not a directory.\n",
            "P13.zip is not a directory.\n",
            "P14.zip is not a directory.\n",
            "P10.zip is not a directory.\n",
            "P07.zip is not a directory.\n",
            "P06 contains: ['P06']\n",
            "P07 contains: ['P07']\n",
            "P05.zip is not a directory.\n",
            "P05 contains: ['P05']\n",
            "P15.zip is not a directory.\n",
            "P01 contains: ['P01']\n",
            "P03.zip is not a directory.\n",
            "P10 contains: ['P10']\n",
            "P15 contains: ['P15']\n",
            "P06.zip is not a directory.\n",
            "P03 contains: ['P03']\n",
            "P12 contains: ['P12']\n",
            "P14 contains: ['P14']\n",
            "P01.zip is not a directory.\n",
            "P11 contains: ['P11']\n",
            "P08.zip is not a directory.\n",
            "P08 contains: ['P08']\n",
            "P12.zip is not a directory.\n",
            "P13 contains: ['P13']\n",
            "P04.zip is not a directory.\n",
            "P09 contains: ['P09']\n",
            "P02 contains: ['P02']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "coH8NTxFLKyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob # Import glob to find files\n",
        "\n",
        "data_dir = \"/content/EEG_BCI_Hackathon/\" # Ensure data_dir is defined\n",
        "\n",
        "all_eeg_epochs_list = [] # Use a list of epoch objects\n",
        "all_labels_list = []\n",
        "\n",
        "# Iterate through participants and sessions\n",
        "# Based on the directory structure: PXX/PXX/SX/eeg/\n",
        "for i in range(1, 16): # Participants P01 to P15\n",
        "    participant = f\"P{i:02d}\"\n",
        "    participant_inner_dir = os.path.join(data_dir, participant, participant) # This matches the PXX/PXX/ structure\n",
        "\n",
        "    for session_folder in [\"S1\", \"S2\"]: # Sessions S1 and S2\n",
        "        eeg_session_path = os.path.join(participant_inner_dir, session_folder, \"eeg\") # Correct path to eeg folder\n",
        "        label_file_path = os.path.join(participant_inner_dir, session_folder, \"labels.csv\") # Path to labels.csv\n",
        "\n",
        "\n",
        "        if os.path.exists(eeg_session_path):\n",
        "            print(f\"Checking directory: {eeg_session_path}\")\n",
        "            # Load .set EEG files\n",
        "            # Use glob to find all .set files in the directory\n",
        "            eeg_files = glob.glob(os.path.join(eeg_session_path, \"*.set\"))\n",
        "\n",
        "\n",
        "            if eeg_files:\n",
        "                print(f\"Found {len(eeg_files)} EEG files in {eeg_session_path}. Loading...\")\n",
        "                for file in eeg_files:\n",
        "                    print(f\"Loading file: {file}\")\n",
        "                    try:\n",
        "                        # Use read_epochs_eeglab for epoch files (as determined previously)\n",
        "                        epochs = mne.io.read_epochs_eeglab(file)\n",
        "\n",
        "                        # Get data from epochs\n",
        "                        eeg_data = epochs.get_data() # shape: (n_epochs, n_channels, n_times)\n",
        "                        n_epochs = len(epochs)\n",
        "\n",
        "                        if n_epochs > 0:\n",
        "                            all_eeg_epochs_list.append(epochs) # Append the MNE Epochs object\n",
        "\n",
        "                            # Attempt to load labels from events within the epochs object\n",
        "                            if epochs.events is not None:\n",
        "                                # Assuming the event ID is in the third column of the events array\n",
        "                                labels = epochs.events[:, 2]\n",
        "                                if len(labels) == n_epochs: # Ensure number of labels matches epochs\n",
        "                                    all_labels_list.append(labels)\n",
        "                                else:\n",
        "                                     print(f\"Warning: Number of extracted labels ({len(labels)}) does not match number of epochs ({n_epochs}) in {os.path.basename(file)}. Skipping labels for this file.\")\n",
        "                                     # Append dummy labels if label count mismatch\n",
        "                                     all_labels_list.append(np.zeros(n_epochs))\n",
        "                            else:\n",
        "                                print(f\"No events found in {os.path.basename(file)}. Using dummy labels.\")\n",
        "                                # If no events, assign dummy label 0 for all epochs from this file\n",
        "                                all_labels_list.append(np.zeros(n_epochs))\n",
        "                        else:\n",
        "                            print(f\"No epochs found in {os.path.basename(file)}. Skipping.\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error loading {file}: {e}\")\n",
        "            else:\n",
        "                print(f\"No .set files found in {eeg_session_path}.\")\n",
        "        else:\n",
        "            print(f\"Directory not found: {eeg_session_path}. Skipping.\")\n",
        "\n",
        "# Concatenate all epochs into a single Epochs object\n",
        "if all_eeg_epochs_list:\n",
        "    try:\n",
        "        combined_eeg_epochs = mne.concatenate_epochs(all_eeg_epochs_list)\n",
        "        print(\"\\nSuccessfully concatenated all EEG epochs.\")\n",
        "        print(\"Combined EEG Epochs Info:\")\n",
        "        print(combined_eeg_epochs.info)\n",
        "        print(\"Combined EEG Epochs shape:\", combined_eeg_epochs.get_data().shape)\n",
        "    except Exception as e:\n",
        "        print(f\"Error concatenating epochs: {e}\")\n",
        "        combined_eeg_epochs = None # Set to None if concatenation fails\n",
        "else:\n",
        "    combined_eeg_epochs = None\n",
        "    print(\"\\nNo EEG epochs were loaded.\")\n",
        "\n",
        "\n",
        "# Concatenate all labels\n",
        "if all_labels_list:\n",
        "    y_eeg = np.concatenate(all_labels_list)\n",
        "    print(\"\\nSuccessfully concatenated all labels.\")\n",
        "    print(\"Combined EEG Labels shape:\", y_eeg.shape)\n",
        "    unique_labels = np.unique(y_eeg)\n",
        "    print(\"Unique labels in combined data:\", unique_labels)\n",
        "    if len(unique_labels) < 2:\n",
        "        print(\"Warning: Only one unique label found. Classification models require at least two classes.\")\n",
        "else:\n",
        "    y_eeg = None\n",
        "    print(\"\\nNo labels were loaded successfully.\")\n",
        "\n",
        "print(\"\\nFinished loading and combining EEG data and labels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buMdMy7eLLNy",
        "outputId": "b100f953-d30f-4a6b-db63-6cff39844c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking directory: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P01/P01/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P01/P01/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBdiff.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n",
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RS.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P02/P02/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P02/P02/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P03/P03/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P03/P03/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P04/P04/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RS.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n",
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P04/P04/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n",
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P05/P05/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P05/P05/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P06/P06/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P06/P06/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P07/P07/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P07/P07/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P08/P08/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n",
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P08/P08/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n",
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P09/P09/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P09/P09/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P10/P10/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBdiff.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n",
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P10/P10/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P11/P11/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P11/P11/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n",
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P12/P12/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P12/P12/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P13/P13/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P13/P13/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBdiff.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n",
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P14/P14/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RS.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-426548931.py:36: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P14/P14/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P15/P15/S1/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg\n",
            "Found 5 EEG files in /content/EEG_BCI_Hackathon/P15/P15/S2/eeg. Loading...\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Loading file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RSraw.set\n",
            "Error loading /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RSraw.set: The file does not seem to contain epochs (trials less than 2). You should try using read_raw_eeglab function.\n",
            "Not setting metadata\n",
            "14310 matching events found\n",
            "No baseline correction applied\n",
            "\n",
            "Successfully concatenated all EEG epochs.\n",
            "Combined EEG Epochs Info:\n",
            "<Info | 8 non-empty values\n",
            " bads: []\n",
            " ch_names: Fp1, Fz, F3, F7, FT9, FC5, FC1, C3, T7, CP5, CP1, Pz, P3, P7, ...\n",
            " chs: 61 EEG\n",
            " custom_ref_applied: False\n",
            " dig: 64 items (3 Cardinal, 61 EEG)\n",
            " highpass: 0.0 Hz\n",
            " lowpass: 125.0 Hz\n",
            " meas_date: unspecified\n",
            " nchan: 61\n",
            " projs: []\n",
            " sfreq: 250.0 Hz\n",
            ">\n",
            "Combined EEG Epochs shape: (14310, 61, 500)\n",
            "\n",
            "Successfully concatenated all labels.\n",
            "Combined EEG Labels shape: (14310,)\n",
            "Unique labels in combined data: [1]\n",
            "Warning: Only one unique label found. Classification models require at least two classes.\n",
            "\n",
            "Finished loading and combining EEG data and labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data_dir = \"/content/EEG_BCI_Hackathon/\"\n",
        "\n",
        "all_eeg_epochs = []\n",
        "all_labels = []\n",
        "\n",
        "# Iterate over participants\n",
        "for participant in os.listdir(data_dir):\n",
        "    participant_path = os.path.join(data_dir, participant)\n",
        "    if not os.path.isdir(participant_path):\n",
        "        continue\n",
        "\n",
        "    # Detect session folders automatically\n",
        "    session_folders = [d for d in os.listdir(participant_path) if os.path.isdir(os.path.join(participant_path, d))]\n",
        "\n",
        "    for session in session_folders:\n",
        "        session_path = os.path.join(participant_path, session)\n",
        "\n",
        "        # Detect EEG subfolder automatically\n",
        "        eeg_folders = [d for d in os.listdir(session_path) if 'EEG' in d or 'eeg' in d]\n",
        "        if not eeg_folders:\n",
        "            continue\n",
        "        eeg_path = os.path.join(session_path, eeg_folders[0])\n",
        "\n",
        "        # Load all .set EEG files in this folder\n",
        "        for file in os.listdir(eeg_path):\n",
        "            if file.endswith(\".set\"):\n",
        "                file_path = os.path.join(eeg_path, file)\n",
        "                print(f\"Loading {file_path} ...\")\n",
        "                raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
        "\n",
        "                # Select EEG channels only\n",
        "                eeg_chs = [ch for ch in raw.info['ch_names'] if 'EEG' in ch or 'eeg' in ch]\n",
        "                if not eeg_chs:\n",
        "                    continue\n",
        "                eeg_data = raw.get_data(picks=eeg_chs)\n",
        "\n",
        "                # Epoch into 2-second segments\n",
        "                sfreq = raw.info['sfreq']\n",
        "                epoch_len = int(2 * sfreq)\n",
        "                n_epochs = eeg_data.shape[1] // epoch_len\n",
        "                eeg_epochs = eeg_data[:, :n_epochs*epoch_len].reshape(len(eeg_chs), n_epochs, epoch_len).transpose(1,0,2)\n",
        "\n",
        "                all_eeg_epochs.append(eeg_epochs)\n",
        "\n",
        "                # Attempt to load labels (if exist)\n",
        "                label_file = os.path.join(session_path, \"labels.csv\")\n",
        "                if os.path.exists(label_file):\n",
        "                    df = pd.read_csv(label_file)\n",
        "                    labels = df['workload'].values[:n_epochs]\n",
        "                    all_labels.append(labels)\n",
        "                else:\n",
        "                    # Use dummy labels if no file found\n",
        "                    all_labels.append(np.zeros(n_epochs))\n",
        "\n",
        "# Stack everything\n",
        "if all_eeg_epochs:\n",
        "    X_eeg = np.vstack(all_eeg_epochs)\n",
        "    y = np.hstack(all_labels)\n",
        "    print(\"EEG data loaded successfully!\")\n",
        "    print(\"EEG shape:\", X_eeg.shape)\n",
        "    print(\"Labels shape:\", y.shape, \"Unique labels:\", np.unique(y))\n",
        "else:\n",
        "    print(\"No EEG data found. Check folder structure.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_OrJ4FhL1LR",
        "outputId": "b551f6de-2191-48f4-88ec-f578643cfbc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG data found. Check folder structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data_dir = \"/content/EEG_BCI_Hackathon/\"\n",
        "\n",
        "all_eeg_epochs = []\n",
        "all_labels = []\n",
        "\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    set_files = [f for f in files if f.endswith(\".set\")]\n",
        "    if not set_files:\n",
        "        continue\n",
        "\n",
        "    for file in set_files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        print(f\"Processing EEG file: {file_path}\")\n",
        "\n",
        "        # First, try reading as epochs\n",
        "        try:\n",
        "            epochs = mne.read_epochs_eeglab(file_path)\n",
        "            eeg_chs = [ch for ch in epochs.ch_names if 'EEG' in ch or 'eeg' in ch]\n",
        "            if not eeg_chs:\n",
        "                print(\"No EEG channels found in\", file_path)\n",
        "                continue\n",
        "            eeg_data = epochs.get_data(picks=eeg_chs)\n",
        "\n",
        "            # Load labels if available\n",
        "            if epochs.event_id:\n",
        "                labels = np.array([list(epochs.event_id.values()).index(v) for v in epochs.events[:,2]])\n",
        "            else:\n",
        "                labels = np.zeros(eeg_data.shape[0])\n",
        "\n",
        "        except ValueError:\n",
        "            # Fallback: read as raw EEG and manually epoch\n",
        "            raw = mne.io.read_raw_eeglab(file_path)\n",
        "            eeg_chs = [ch for ch in raw.info['ch_names'] if 'EEG' in ch or 'eeg' in ch]\n",
        "            if not eeg_chs:\n",
        "                print(\"No EEG channels found in\", file_path)\n",
        "                continue\n",
        "            raw.pick_channels(eeg_chs)\n",
        "\n",
        "            # Apply simple bandpass filter (optional)\n",
        "            raw.filter(1, 40, fir_design='firwin')\n",
        "\n",
        "            # Manual epoching into 2-second non-overlapping windows\n",
        "            sfreq = raw.info['sfreq']\n",
        "            epoch_len = int(2 * sfreq)\n",
        "            n_epochs = raw.n_times // epoch_len\n",
        "            data = raw.get_data()[:, :n_epochs*epoch_len]\n",
        "            eeg_data = data.reshape(len(eeg_chs), n_epochs, epoch_len).transpose(1,0,2)\n",
        "            labels = np.zeros(n_epochs)  # dummy labels\n",
        "\n",
        "        all_eeg_epochs.append(eeg_data)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "# Stack all EEG epochs\n",
        "if all_eeg_epochs:\n",
        "    X_eeg = np.vstack(all_eeg_epochs)\n",
        "    y = np.hstack(all_labels)\n",
        "    print(\"EEG data loaded successfully!\")\n",
        "    print(\"EEG shape:\", X_eeg.shape)\n",
        "    print(\"Labels shape:\", y.shape, \"Unique labels:\", np.unique(y))\n",
        "else:\n",
        "    print(\"No EEG data found. Check that the Zenodo zip was extracted correctly and contains .set files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS6hbTxxMM2K",
        "outputId": "c33d0726-f7a6-4ba7-8b7b-0f88e242f8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing EEG file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBdiff.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P04/P04/S2/eeg/alldata_sbj04_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBeasy.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P06/P06/S1/eeg/alldata_sbj06_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P06/P06/S2/eeg/alldata_sbj06_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P07/P07/S1/eeg/alldata_sbj07_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P07/P07/S2/eeg/alldata_sbj07_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P05/P05/S1/eeg/alldata_sbj05_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P05/P05/S2/eeg/alldata_sbj05_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RS.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P10/P10/S1/eeg/alldata_sbj10_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P10/P10/S2/eeg/alldata_sbj10_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P15/P15/S1/eeg/alldata_sbj15_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P15/P15/S2/eeg/alldata_sbj15_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBdiff.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RSraw.set\n",
            "No EEG channels found in"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P03/P03/S1/eeg/alldata_sbj03_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBmed.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P03/P03/S2/eeg/alldata_sbj03_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P12/P12/S1/eeg/alldata_sbj12_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBeasy.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P12/P12/S2/eeg/alldata_sbj12_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P14/P14/S1/eeg/alldata_sbj14_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P14/P14/S2/eeg/alldata_sbj14_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBdiff.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBmed.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P11/P11/S1/eeg/alldata_sbj11_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBmed.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBeasy.set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P11/P11/S2/eeg/alldata_sbj11_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P08/P08/S1/eeg/alldata_sbj08_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P08/P08/S2/eeg/alldata_sbj08_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P13/P13/S1/eeg/alldata_sbj13_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Estimated head radius (11.4 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:22: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P13/P13/S2/eeg/alldata_sbj13_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P09/P09/S1/eeg/alldata_sbj09_sess1_RSraw.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing EEG file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No EEG channels found in /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P09/P09/S2/eeg/alldata_sbj09_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBmed.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBeasy.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RSraw.set\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RSraw.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBdiff.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n",
            "/tmp/ipython-input-2944792109.py:37: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  raw = mne.io.read_raw_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBdiff.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_RS.set\n",
            "Processing EEG file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "No EEG channels found in /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBmed.set\n",
            "No EEG data found. Check that the Zenodo zip was extracted correctly and contains .set files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define the root directory where you extracted the data (e.g., from Zenodo)\n",
        "data_dir = \"/content/PassiveBCI_data/\"\n",
        "\n",
        "all_eeg_epochs = []\n",
        "all_labels = []\n",
        "\n",
        "# --- Define non-EEG channels to exclude ---\n",
        "# These are common names for non-EEG channels in this type of biomedical dataset.\n",
        "EXCLUDE_CHANNELS = ['ECG', 'ecg', 'Trigger', 'Status', 'MARKER', 'M_STATUS']\n",
        "\n",
        "print(f\"Starting data loading from: {data_dir}\")\n",
        "\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    set_files = [f for f in files if f.endswith(\".set\")]\n",
        "    if not set_files:\n",
        "        continue\n",
        "\n",
        "    for file in set_files:\n",
        "        file_path = os.path.join(root, file)\n",
        "\n",
        "        # --- DEBUG: Print channel names from the first file you encounter ---\n",
        "        # This helps confirm the channel naming convention\n",
        "        # if not all_eeg_epochs:\n",
        "        #     try:\n",
        "        #         raw_debug = mne.io.read_raw_eeglab(file_path, preload=False)\n",
        "        #         print(f\"\\nDEBUG: Full list of channel names in {file}: {raw_debug.info['ch_names']}\\n\")\n",
        "        #     except:\n",
        "        #         pass\n",
        "        # --------------------------------------------------------------------\n",
        "\n",
        "        # --- Channel Selection Helper Function ---\n",
        "        def select_eeg_channels(channel_names):\n",
        "            return [ch for ch in channel_names if ch.upper() not in EXCLUDE_CHANNELS]\n",
        "\n",
        "        # --- Loading Logic ---\n",
        "        try:\n",
        "            # 1. Try reading as epochs\n",
        "            epochs = mne.read_epochs_eeglab(file_path, verbose='WARNING')\n",
        "\n",
        "            eeg_chs = select_eeg_channels(epochs.ch_names)\n",
        "            if not eeg_chs:\n",
        "                print(f\"Skipping {file_path}: No valid EEG channels after exclusion.\")\n",
        "                continue\n",
        "\n",
        "            eeg_data = epochs.get_data(picks=eeg_chs)\n",
        "\n",
        "            # Load labels\n",
        "            if epochs.event_id:\n",
        "                # Map event IDs to 0, 1, 2 based on their order\n",
        "                event_values = epochs.events[:, 2]\n",
        "                unique_ids = sorted(np.unique(event_values))\n",
        "                id_map = {uid: i for i, uid in enumerate(unique_ids)}\n",
        "                labels = np.array([id_map.get(v, -1) for v in event_values]) # Use -1 for unknown\n",
        "                labels = labels[labels != -1] # Filter out unknown labels\n",
        "                eeg_data = eeg_data[labels != -1] # Filter corresponding data\n",
        "            else:\n",
        "                labels = np.zeros(eeg_data.shape[0])\n",
        "\n",
        "        except ValueError:\n",
        "            # 2. Fallback: read as raw EEG and manually epoch\n",
        "            raw = mne.io.read_raw_eeglab(file_path, preload=True, verbose='WARNING')\n",
        "\n",
        "            eeg_chs = select_eeg_channels(raw.info['ch_names'])\n",
        "            if not eeg_chs:\n",
        "                print(f\"Skipping {file_path}: No valid EEG channels after exclusion.\")\n",
        "                continue\n",
        "\n",
        "            raw.pick_channels(eeg_chs)\n",
        "            raw.filter(1, 40, fir_design='firwin', verbose='WARNING')\n",
        "\n",
        "            # Manual epoching into 2-second non-overlapping windows\n",
        "            sfreq = raw.info['sfreq']\n",
        "            epoch_sec = 2\n",
        "            epoch_len = int(epoch_sec * sfreq)\n",
        "            n_epochs = raw.n_times // epoch_len\n",
        "\n",
        "            if n_epochs == 0: continue\n",
        "\n",
        "            data = raw.get_data()[:, :n_epochs*epoch_len]\n",
        "            # Shape: Epochs x Channels x Samples\n",
        "            eeg_data = data.reshape(len(eeg_chs), n_epochs, epoch_len).transpose(1,0,2)\n",
        "            labels = np.zeros(n_epochs) # Dummy labels for raw data fallback\n",
        "\n",
        "        # Append results\n",
        "        all_eeg_epochs.append(eeg_data)\n",
        "        all_labels.append(labels)\n",
        "        print(f\"Successfully processed {file}: {eeg_data.shape[0]} epochs added.\")\n",
        "\n",
        "# Stack all EEG epochs\n",
        "if all_eeg_epochs:\n",
        "    X_eeg = np.vstack(all_eeg_epochs)\n",
        "    y = np.hstack(all_labels)\n",
        "    print(\"\\n==================================\")\n",
        "    print(\"EEG data loaded successfully!\")\n",
        "    print(\"EEG shape (Epochs x Channels x Samples):\", X_eeg.shape)\n",
        "    print(f\"Labels shape: {y.shape}. Unique labels: {np.unique(y)}\")\n",
        "    print(\"==================================\")\n",
        "else:\n",
        "    print(\"\\nNo EEG data found. Check data directory and file integrity.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abktHTYsNVa9",
        "outputId": "0f81a301-14ff-4ae7-934b-0be35b18cb0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data loading from: /content/PassiveBCI_data/\n",
            "\n",
            "No EEG data found. Check data directory and file integrity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# PHASE 1: DOWNLOAD, EXTRACTION, AND VERIFICATION\n",
        "# ====================================================================\n",
        "\n",
        "import os, zipfile, requests\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import sys # To exit on critical failure\n",
        "\n",
        "# --- Download Parameters ---\n",
        "base_url = \"https://zenodo.org/records/4917218/files/\"\n",
        "participants = [f\"P{i:02d}.zip\" for i in range(1,16)]\n",
        "data_dir = \"/content/PassiveBCI_data\" # The expected root directory\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# 1. Download and Extract (Re-run just in case the previous attempt failed)\n",
        "print(\"--- Phase 1: Downloading and Extracting Data (Zenodo) ---\")\n",
        "for p in participants:\n",
        "    url = base_url + p\n",
        "    zip_path = os.path.join(data_dir, p)\n",
        "\n",
        "    if not os.path.exists(zip_path) or os.path.getsize(zip_path) == 0:\n",
        "        print(f\"Downloading {p}...\")\n",
        "        try:\n",
        "            r = requests.get(url, stream=True)\n",
        "            r.raise_for_status()\n",
        "            with open(zip_path, \"wb\") as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"ERROR downloading {p}: {e}\")\n",
        "            sys.exit(1) # Critical failure\n",
        "\n",
        "    print(f\"Extracting {p}...\")\n",
        "    try:\n",
        "        # Extract to a folder named P01, P02, etc.\n",
        "        extract_to_path = os.path.join(data_dir, p.replace(\".zip\", \"\"))\n",
        "        os.makedirs(extract_to_path, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "            zip_ref.extractall(extract_to_path)\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"ERROR: {p} is a corrupt zip file. Cannot proceed.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "# 2. Verify File Structure\n",
        "first_set_file = glob.glob(os.path.join(data_dir, \"**\", \"*.set\"), recursive=True)\n",
        "if not first_set_file:\n",
        "    print(\"\\nCRITICAL ERROR: Extraction failed. No .set files were found.\")\n",
        "    print(\"Please check the contents of:\", data_dir)\n",
        "    sys.exit(1)\n",
        "\n",
        "print(f\"\\nVerification Success: Found first .set file at: {first_set_file[0]}\")\n",
        "print(\"------------------------------------------------------------------\")\n",
        "\n",
        "# ====================================================================\n",
        "# PHASE 2: ROBUST EEG LOADING\n",
        "# ====================================================================\n",
        "\n",
        "all_eeg_epochs = []\n",
        "all_labels = []\n",
        "\n",
        "# --- Channels to Exclude ---\n",
        "# Ensures we pick up correctly named EEG electrodes while ignoring ECG/Marker channels.\n",
        "EXCLUDE_CHANNELS = ['ECG', 'ecg', 'Trigger', 'Status', 'MARKER', 'M_STATUS']\n",
        "\n",
        "def select_eeg_channels(channel_names):\n",
        "    # Selects all channels that are NOT in the exclusion list\n",
        "    return [ch for ch in channel_names if ch.upper() not in EXCLUDE_CHANNELS]\n",
        "\n",
        "print(\"--- Phase 2: Loading and Processing EEG Data ---\")\n",
        "\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    set_files = [f for f in files if f.endswith(\".set\")]\n",
        "    if not set_files:\n",
        "        continue\n",
        "\n",
        "    for file in set_files:\n",
        "        file_path = os.path.join(root, file)\n",
        "\n",
        "        # --- Loading Logic ---\n",
        "        try:\n",
        "            # 1. Try reading as epochs\n",
        "            epochs = mne.read_epochs_eeglab(file_path, verbose='ERROR')\n",
        "            eeg_chs = select_eeg_channels(epochs.ch_names)\n",
        "\n",
        "            if not eeg_chs: raise ValueError(\"No EEG channels found after filtering.\")\n",
        "\n",
        "            eeg_data = epochs.get_data(picks=eeg_chs)\n",
        "\n",
        "            # Label Extraction (assuming 3 labels: 0, 1, 2)\n",
        "            if epochs.event_id:\n",
        "                event_values = epochs.events[:, 2]\n",
        "                unique_ids = sorted(np.unique(event_values))\n",
        "                id_map = {uid: i for i, uid in enumerate(unique_ids)}\n",
        "                labels = np.array([id_map.get(v, -1) for v in event_values])\n",
        "\n",
        "                # Filter out any epochs with unknown labels\n",
        "                eeg_data = eeg_data[labels != -1]\n",
        "                labels = labels[labels != -1]\n",
        "            else:\n",
        "                labels = np.zeros(eeg_data.shape[0])\n",
        "\n",
        "        except (ValueError, FileNotFoundError, RuntimeError):\n",
        "            # 2. Fallback: read as raw EEG and manually epoch\n",
        "            try:\n",
        "                raw = mne.io.read_raw_eeglab(file_path, preload=True, verbose='ERROR')\n",
        "            except Exception:\n",
        "                # If reading raw also fails (corrupt file, etc.), skip\n",
        "                continue\n",
        "\n",
        "            eeg_chs = select_eeg_channels(raw.info['ch_names'])\n",
        "            if not eeg_chs: continue\n",
        "\n",
        "            raw.pick_channels(eeg_chs)\n",
        "            raw.filter(1, 40, fir_design='firwin', verbose='ERROR')\n",
        "\n",
        "            sfreq = raw.info['sfreq']\n",
        "            epoch_sec = 2\n",
        "            epoch_len = int(epoch_sec * sfreq)\n",
        "            n_epochs = raw.n_times // epoch_len\n",
        "\n",
        "            if n_epochs == 0: continue\n",
        "\n",
        "            data = raw.get_data()[:, :n_epochs*epoch_len]\n",
        "            eeg_data = data.reshape(len(eeg_chs), n_epochs, epoch_len).transpose(1,0,2)\n",
        "            labels = np.zeros(n_epochs) # Dummy labels\n",
        "\n",
        "        # Append results\n",
        "        all_eeg_epochs.append(eeg_data)\n",
        "        all_labels.append(labels)\n",
        "        # print(f\"-> Processed {file}: {eeg_data.shape[0]} epochs added.\") # Optional: print success for every file\n",
        "\n",
        "# Stack all EEG epochs\n",
        "if all_eeg_epochs:\n",
        "    X_eeg = np.vstack(all_eeg_epochs)\n",
        "    y = np.hstack(all_labels)\n",
        "    print(\"\\n==================================\")\n",
        "    print(\"EEG data loaded successfully!\")\n",
        "    print(\"EEG shape (Epochs x Channels x Samples):\", X_eeg.shape)\n",
        "    print(f\"Labels shape: {y.shape}. Unique labels: {np.unique(y)}\")\n",
        "    print(\"==================================\")\n",
        "else:\n",
        "    print(\"\\nFINAL ERROR: Despite file verification, no valid EEG data could be processed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FK__IVuzNhIP",
        "outputId": "a930faea-e1f3-4095-ba5f-813b0458a033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Phase 1: Downloading and Extracting Data (Zenodo) ---\n",
            "Extracting P01.zip...\n",
            "ERROR: P01.zip is a corrupt zip file. Cannot proceed.\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-493886062.py\", line 41, in <cell line: 0>\n",
            "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/zipfile/__init__.py\", line 1354, in __init__\n",
            "    self._RealGetContents()\n",
            "  File \"/usr/lib/python3.12/zipfile/__init__.py\", line 1421, in _RealGetContents\n",
            "    raise BadZipFile(\"File is not a zip file\")\n",
            "zipfile.BadZipFile: File is not a zip file\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-493886062.py\", line 45, in <cell line: 0>\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1701, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-493886062.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-493886062.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ERROR: {p} is a corrupt zip file. Cannot proceed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lh /content/PassiveBCI_data/P01.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqSUSLKtN0kw",
        "outputId": "4dd639c6-cd86-44d0-9c13-c136c88e251c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 287K Oct  1 09:19 /content/PassiveBCI_data/P01.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rm /content/PassiveBCI_data/P01.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvbVpmEIN-yR",
        "outputId": "89fdab5f-9dfb-4dc5-e6d3-7a94045729fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/PassiveBCI_data/P01.zip': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# PHASE 1: DOWNLOAD, EXTRACTION, AND VERIFICATION\n",
        "# NOTE: This section attempts to download the 15 large zip files from Zenodo.\n",
        "# ====================================================================\n",
        "\n",
        "import os, zipfile, requests\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import sys\n",
        "\n",
        "# --- Download Parameters ---\n",
        "base_url = \"https://zenodo.org/records/4917218/files/\"\n",
        "participants = [f\"P{i:02d}.zip\" for i in range(1,16)]\n",
        "data_dir = \"/content/PassiveBCI_data\" # The expected root directory\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# 1. Download and Extract (This will attempt to re-download P01.zip since it was removed)\n",
        "print(\"--- Phase 1: Downloading and Extracting Data (Zenodo) ---\")\n",
        "for p in participants:\n",
        "    url = base_url + p\n",
        "    zip_path = os.path.join(data_dir, p)\n",
        "\n",
        "    # Check if the file exists AND is a reasonable size (at least 100MB) before skipping download\n",
        "    # The actual size is ~120MB, so checking > 100MB avoids using the tiny, corrupt files.\n",
        "    expected_min_size_bytes = 100 * 1024 * 1024\n",
        "\n",
        "    if not os.path.exists(zip_path) or os.path.getsize(zip_path) < expected_min_size_bytes:\n",
        "        print(f\"Downloading {p}...\")\n",
        "        try:\n",
        "            r = requests.get(url, stream=True)\n",
        "            r.raise_for_status()\n",
        "            with open(zip_path, \"wb\") as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "\n",
        "            # Re-check size after download\n",
        "            if os.path.getsize(zip_path) < expected_min_size_bytes:\n",
        "                 print(f\"WARNING: {p} downloaded but size is too small. Deleting corrupt file and trying next.\")\n",
        "                 os.remove(zip_path) # Delete the bad file again\n",
        "                 continue # Skip extraction and try the next file/restart the script\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"ERROR downloading {p}: {e}\")\n",
        "            continue # Try the next file\n",
        "\n",
        "    print(f\"Extracting {p}...\")\n",
        "    try:\n",
        "        extract_to_path = os.path.join(data_dir, p.replace(\".zip\", \"\"))\n",
        "        os.makedirs(extract_to_path, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "            zip_ref.extractall(extract_to_path)\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"CRITICAL ERROR: {p} is a bad zip file, even after re-download. Please check file integrity manually.\")\n",
        "        sys.exit(1) # Stop script if a core file remains corrupt\n",
        "\n",
        "# 2. Verify File Structure (Search for at least one .set file)\n",
        "first_set_file = glob.glob(os.path.join(data_dir, \"**\", \"*.set\"), recursive=True)\n",
        "if not first_set_file:\n",
        "    print(\"\\nCRITICAL ERROR: No .set files found. Check extraction path.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(f\"\\nVerification Success: Found first .set file at: {first_set_file[0]}\")\n",
        "print(\"------------------------------------------------------------------\")\n",
        "\n",
        "# ====================================================================\n",
        "# PHASE 2: ROBUST EEG LOADING (Assuming Phase 1 succeeded)\n",
        "# ====================================================================\n",
        "\n",
        "all_eeg_epochs = []\n",
        "all_labels = []\n",
        "\n",
        "# --- Channels to Exclude ---\n",
        "EXCLUDE_CHANNELS = ['ECG', 'ecg', 'Trigger', 'Status', 'MARKER', 'M_STATUS']\n",
        "\n",
        "def select_eeg_channels(channel_names):\n",
        "    return [ch for ch in channel_names if ch.upper() not in EXCLUDE_CHANNELS]\n",
        "\n",
        "print(\"--- Phase 2: Loading and Processing EEG Data ---\")\n",
        "\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    set_files = [f for f in files if f.endswith(\".set\")]\n",
        "    if not set_files:\n",
        "        continue\n",
        "\n",
        "    for file in set_files:\n",
        "        file_path = os.path.join(root, file)\n",
        "\n",
        "        # --- Loading Logic ---\n",
        "        try:\n",
        "            # 1. Try reading as epochs\n",
        "            epochs = mne.read_epochs_eeglab(file_path, verbose='ERROR')\n",
        "            eeg_chs = select_eeg_channels(epochs.ch_names)\n",
        "\n",
        "            if not eeg_chs: raise ValueError(\"No EEG channels found after filtering.\")\n",
        "\n",
        "            eeg_data = epochs.get_data(picks=eeg_chs)\n",
        "\n",
        "            # Label Extraction\n",
        "            if epochs.event_id:\n",
        "                event_values = epochs.events[:, 2]\n",
        "                unique_ids = sorted(np.unique(event_values))\n",
        "                id_map = {uid: i for i, uid in enumerate(unique_ids)}\n",
        "                labels = np.array([id_map.get(v, -1) for v in event_values])\n",
        "                eeg_data = eeg_data[labels != -1]\n",
        "                labels = labels[labels != -1]\n",
        "            else:\n",
        "                labels = np.zeros(eeg_data.shape[0])\n",
        "\n",
        "        except (ValueError, FileNotFoundError, RuntimeError):\n",
        "            # 2. Fallback: read as raw EEG and manually epoch\n",
        "            try:\n",
        "                raw = mne.io.read_raw_eeglab(file_path, preload=True, verbose='ERROR')\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "            eeg_chs = select_eeg_channels(raw.info['ch_names'])\n",
        "            if not eeg_chs: continue\n",
        "\n",
        "            raw.pick_channels(eeg_chs)\n",
        "            raw.filter(1, 40, fir_design='firwin', verbose='ERROR')\n",
        "\n",
        "            sfreq = raw.info['sfreq']\n",
        "            epoch_sec = 2\n",
        "            epoch_len = int(epoch_sec * sfreq)\n",
        "            n_epochs = raw.n_times // epoch_len\n",
        "\n",
        "            if n_epochs == 0: continue\n",
        "\n",
        "            data = raw.get_data()[:, :n_epochs*epoch_len]\n",
        "            eeg_data = data.reshape(len(eeg_chs), n_epochs, epoch_len).transpose(1,0,2)\n",
        "            labels = np.zeros(n_epochs) # Dummy labels\n",
        "\n",
        "        all_eeg_epochs.append(eeg_data)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "# Stack all EEG epochs\n",
        "if all_eeg_epochs:\n",
        "    X_eeg = np.vstack(all_eeg_epochs)\n",
        "    y = np.hstack(all_labels)\n",
        "    print(\"\\n==================================\")\n",
        "    print(\"EEG data loaded successfully!\")\n",
        "    print(\"EEG shape (Epochs x Channels x Samples):\", X_eeg.shape)\n",
        "    print(f\"Labels shape: {y.shape}. Unique labels: {np.unique(y)}\")\n",
        "    print(\"==================================\")\n",
        "else:\n",
        "    print(\"\\nFINAL ERROR: No valid EEG data could be processed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ONrXN_EnOP67",
        "outputId": "6190816a-cb0e-4685-d4e7-0e58172f9070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Phase 1: Downloading and Extracting Data (Zenodo) ---\n",
            "Downloading P01.zip...\n",
            "Extracting P01.zip...\n",
            "Downloading P02.zip...\n",
            "Extracting P02.zip...\n",
            "Downloading P03.zip...\n",
            "Extracting P03.zip...\n",
            "Downloading P04.zip...\n",
            "Extracting P04.zip...\n",
            "Downloading P05.zip...\n",
            "Extracting P05.zip...\n",
            "Downloading P06.zip...\n",
            "Extracting P06.zip...\n",
            "Downloading P07.zip...\n",
            "Extracting P07.zip...\n",
            "Downloading P08.zip...\n",
            "Extracting P08.zip...\n",
            "Downloading P09.zip...\n",
            "Extracting P09.zip...\n",
            "Downloading P10.zip...\n",
            "Extracting P10.zip...\n",
            "Downloading P11.zip...\n",
            "Extracting P11.zip...\n",
            "Downloading P12.zip...\n",
            "Extracting P12.zip...\n",
            "Downloading P13.zip...\n",
            "Extracting P13.zip...\n",
            "Downloading P14.zip...\n",
            "Extracting P14.zip...\n",
            "Downloading P15.zip...\n",
            "Extracting P15.zip...\n",
            "\n",
            "Verification Success: Found first .set file at: /content/PassiveBCI_data/P04/P04/S1/eeg/alldata_sbj04_sess1_MATBeasy.set\n",
            "------------------------------------------------------------------\n",
            "--- Phase 2: Loading and Processing EEG Data ---\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 61 and the array at index 1 has size 62",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3809012014.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m# Stack all EEG epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mall_eeg_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mX_eeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_eeg_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n==================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcasting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 61 and the array at index 1 has size 62"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b6a3730",
        "outputId": "b28d5eb0-a9d6-43e7-a828-4562b242705a"
      },
      "source": [
        "# ===============================\n",
        "# 1. Install required packages\n",
        "# ===============================\n",
        "!pip install mne numpy pandas scikit-learn xgboost\n",
        "\n",
        "# ===============================\n",
        "# 2. Setup directories\n",
        "# ===============================\n",
        "import os\n",
        "data_dir = '/content/EEG_BCI_Hackathon'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# 3. Download all participant ZIPs\n",
        "# ===============================\n",
        "# This loop checks and downloads/extracts participant data from Zenodo.\n",
        "# We include the download and extraction here again to ensure the data is available,\n",
        "# but the print statements will indicate if files/directories already exist to avoid\n",
        "# unnecessary re-downloads/extractions.\n",
        "for i in range(1, 16):\n",
        "    url = f\"https://zenodo.org/record/4917218/files/P{i:02d}.zip?download=1\"\n",
        "    out_file = os.path.join(data_dir, f\"P{i:02d}.zip\")\n",
        "    # Check if the zip file already exists and is not empty\n",
        "    if not os.path.exists(out_file) or os.stat(out_file).st_size == 0:\n",
        "        print(f\"Downloading {os.path.basename(out_file)}...\")\n",
        "        # Use wget with --no-check-certificate in case of SSL issues (optional, but can help)\n",
        "        # Or use requests for more control over download\n",
        "        try:\n",
        "            r = requests.get(url, stream=True)\n",
        "            r.raise_for_status() # Raise an exception for bad status codes\n",
        "            with open(out_file, 'wb') as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            print(f\"Download of {os.path.basename(out_file)} completed.\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error downloading {os.path.basename(out_file)}: {e}\")\n",
        "            continue # Skip extraction if download failed\n",
        "\n",
        "\n",
        "    # Check if the downloaded file is a valid zip before extracting\n",
        "    if os.path.exists(out_file) and os.stat(out_file).st_size > 0:\n",
        "        if zipfile.is_zipfile(out_file):\n",
        "            extract_path = os.path.join(data_dir, f\"P{i:02d}\")\n",
        "            # Check if the extraction directory is empty or doesn't exist\n",
        "            if not os.path.exists(extract_path) or not os.listdir(extract_path):\n",
        "                print(f\"Extracting {os.path.basename(out_file)}...\")\n",
        "                os.makedirs(extract_path, exist_ok=True)\n",
        "                try:\n",
        "                    with zipfile.ZipFile(out_file, 'r') as zip_ref:\n",
        "                        zip_ref.extractall(extract_path)\n",
        "                    print(f\"Extraction of {os.path.basename(out_file)} completed.\")\n",
        "                except zipfile.BadZipFile as e:\n",
        "                    print(f\"Error extracting {os.path.basename(out_file)}: Bad zip file. {e}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error extracting {os.path.basename(out_file)}: {e}\")\n",
        "            else:\n",
        "                print(f\"{os.path.basename(extract_path)} directory is not empty, skipping extraction.\")\n",
        "        else:\n",
        "            print(f\"Downloaded file {os.path.basename(out_file)} is not a valid zip file, skipping extraction.\")\n",
        "    else:\n",
        "        print(f\"Downloaded file {os.path.basename(out_file)} is empty or does not exist, skipping extraction.\")\n",
        "\n",
        "\n",
        "print(\"All participants download and extraction check completed!\")\n",
        "\n",
        "# Add a command to list the contents of the extracted P01 directory to find the correct file path\n",
        "print(\"\\nListing contents of extracted P01 directory:\")\n",
        "!ls -R /content/EEG_BCI_Hackathon/P01\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 4. Load all EEG .set files with MNE\n",
        "# ===============================\n",
        "import mne\n",
        "import numpy as np\n",
        "import glob # Import glob to find files\n",
        "\n",
        "def load_eeg_epochs(file_path):\n",
        "    \"\"\"Load EEG .set file and return MNE Epochs object\"\"\"\n",
        "    # Use read_epochs_eeglab for files containing epochs\n",
        "    # Removed preload=True as it's not supported in this MNE version for read_epochs_eeglab\n",
        "    epochs = mne.io.read_epochs_eeglab(file_path)\n",
        "    return epochs\n",
        "\n",
        "# List to store all loaded epochs\n",
        "all_eeg_epochs = []\n",
        "# Corrected pattern for EEG data directories based on previous !ls output\n",
        "eeg_data_dir = os.path.join(data_dir, 'P{i:02d}', 'P{i:02d}', 'S{s}', 'eeg')\n",
        "task_patterns = ['*MATBeasy.set', '*MATBmed.set', '*MATBdiff.set', '*RS.set'] # Patterns for task files\n",
        "\n",
        "\n",
        "print(\"\\nLoading all EEG files...\")\n",
        "for i in range(1, 16): # Iterate through participants P01 to P15\n",
        "    for s in range(1, 3): # Iterate through sessions S1 and S2\n",
        "        current_eeg_dir = eeg_data_dir.format(i=i, s=s)\n",
        "        print(f\"Checking directory: {current_eeg_dir}\")\n",
        "        if os.path.exists(current_eeg_dir):\n",
        "            for pattern in task_patterns:\n",
        "                file_pattern = os.path.join(current_eeg_dir, pattern)\n",
        "                eeg_files = glob.glob(file_pattern)\n",
        "                for eeg_file in eeg_files:\n",
        "                    print(f\"Loading file: {eeg_file}\")\n",
        "                    try:\n",
        "                        epochs = load_eeg_epochs(eeg_file)\n",
        "                        all_eeg_epochs.append(epochs)\n",
        "                        print(f\"Successfully loaded {os.path.basename(eeg_file)}. Number of epochs: {len(epochs)}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error loading {e_eeg_file}: {e}\") # Corrected variable name here\n",
        "        else:\n",
        "            print(f\"Directory not found: {current_eeg_dir}\")\n",
        "\n",
        "print(f\"\\nFinished loading all EEG files. Total number of loaded Epochs objects: {len(all_eeg_epochs)}\")\n",
        "\n",
        "# Concatenate all epochs into a single Epochs object if needed for consistent processing\n",
        "if all_eeg_epochs:\n",
        "    try:\n",
        "        combined_eeg_epochs = mne.concatenate_epochs(all_eeg_epochs)\n",
        "        print(\"\\nSuccessfully concatenated all EEG epochs.\")\n",
        "        print(\"Combined EEG Epochs Info:\")\n",
        "        print(combined_eeg_epochs.info)\n",
        "        print(\"Combined EEG Epochs shape:\", combined_eeg_epochs.get_data().shape)\n",
        "    except Exception as e:\n",
        "        print(f\"Error concatenating epochs: {e}\")\n",
        "        combined_eeg_epochs = None # Set to None if concatenation fails\n",
        "else:\n",
        "    combined_eeg_epochs = None\n",
        "    print(\"\\nNo EEG epochs were loaded.\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 5. Preprocessing (Adapted for Epochs)\n",
        "# ===============================\n",
        "print(\"\\nProceeding with Preprocessing steps (adapted for epochs):\")\n",
        "# Apply filtering to the epochs if needed (e.g., band-pass filter)\n",
        "# if combined_eeg_epochs:\n",
        "#     print(\"Applying band-pass filter (1-40 Hz)...\")\n",
        "#     combined_eeg_epochs.filter(1., 40.) # Example: Apply a band-pass filter from 1 to 40 Hz\n",
        "\n",
        "# No need for manual segmentation as data is already in epochs.\n",
        "# Resampling can still be applied to epochs if needed\n",
        "# if combined_eeg_epochs:\n",
        "#     print(\"Resampling to 250 Hz...\")\n",
        "#     combined_eeg_epochs.resample(250) # Example: Resample to 250 Hz\n",
        "\n",
        "print(\"Preprocessing steps adapted for epoch data. Filtering/Resampling can be applied directly to eeg_epochs object if needed.\")\n",
        "\n",
        "# ===============================\n",
        "# 6. Feature Extraction for ML\n",
        "# ===============================\n",
        "print(\"\\nProceeding with Feature Extraction:\")\n",
        "# Extract data from epochs object for feature extraction\n",
        "if combined_eeg_epochs:\n",
        "    epochs_data = combined_eeg_epochs.get_data() # shape: (n_epochs, n_channels, n_times)\n",
        "\n",
        "    def extract_features(epoch):\n",
        "        \"\"\"Compute simple features: mean, std, min, max per channel\"\"\"\n",
        "        return np.concatenate([np.mean(epoch, axis=1),\n",
        "                               np.std(epoch, axis=1),\n",
        "                               np.min(epoch, axis=1),\n",
        "                               np.max(epoch, axis=1)])\n",
        "\n",
        "    X_eeg_features = np.array([extract_features(epoch) for epoch in epochs_data])\n",
        "\n",
        "    # Get labels from epochs metadata or events if available\n",
        "    # Assuming the event ID is in the third column of the events array\n",
        "    if combined_eeg_epochs.events is not None:\n",
        "        labels_eeg = combined_eeg_epochs.events[:, 2]\n",
        "        print(f\"\\nExtracted {len(labels_eeg)} labels from combined epoch events.\")\n",
        "        unique_labels = np.unique(labels_eeg)\n",
        "        print(f\"Unique labels: {unique_labels}\")\n",
        "        y_eeg = labels_eeg\n",
        "    else:\n",
        "         # If no events are found, use dummy labels as a placeholder\n",
        "        print(\"\\nNo events found in combined epochs. Cannot extract labels.\")\n",
        "        X_eeg_features = None # Set features to None if labels cannot be extracted\n",
        "        y_eeg = None\n",
        "\n",
        "\n",
        "    if X_eeg_features is not None:\n",
        "        print(\"EEG Feature matrix shape:\", X_eeg_features.shape)\n",
        "        print(\"EEG Labels shape:\", y_eeg.shape)\n",
        "    else:\n",
        "        print(\"EEG feature extraction skipped due to missing data or labels.\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 7. Split, Scale, and Train Multi-Model (Adapt for full data)\n",
        "# ===============================\n",
        "print(\"\\nProceeding with Model Training (Random Forest on EEG features):\")\n",
        "# We will use the extracted EEG features (X_eeg_features) and labels (y_eeg) for the Random Forest part.\n",
        "# The full multi-model ensemble requires loading and processing ECG data and building/training the CNN and LSTM models separately.\n",
        "# This part of the code now attempts to train the RF on features from all loaded EEG data.\n",
        "\n",
        "if X_eeg_features is not None and y_eeg is not None and len(np.unique(y_eeg)) > 1:\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    # Split data\n",
        "    X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_eeg_features, y_eeg, test_size=0.2, random_state=42, stratify=y_eeg)\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_rf = scaler.fit_transform(X_train_rf)\n",
        "    X_test_rf = scaler.transform(X_test_rf)\n",
        "\n",
        "    # Train Random Forest model\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    print(\"\\nTraining Random Forest model on extracted EEG features from all loaded data...\")\n",
        "    rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "    # Evaluate Random Forest model\n",
        "    y_pred_rf = rf.predict(X_test_rf)\n",
        "    print(\"\\nRandom Forest Model Accuracy on Test Set (EEG Features):\", accuracy_score(y_test_rf, y_pred_rf))\n",
        "\n",
        "    print(\"\\nRandom Forest model training and evaluation completed on extracted EEG features.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping Random Forest model training due to insufficient EEG features or labels.\")\n",
        "\n",
        "# Note: The CNN and LSTM models would require training on the preprocessed EEG segments and ECG sequences respectively.\n",
        "# The combination of models would happen after all models are trained."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.4)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "P01 directory is not empty, skipping extraction.\n",
            "P02 directory is not empty, skipping extraction.\n",
            "P03 directory is not empty, skipping extraction.\n",
            "P04 directory is not empty, skipping extraction.\n",
            "P05 directory is not empty, skipping extraction.\n",
            "P06 directory is not empty, skipping extraction.\n",
            "P07 directory is not empty, skipping extraction.\n",
            "P08 directory is not empty, skipping extraction.\n",
            "P09 directory is not empty, skipping extraction.\n",
            "P10 directory is not empty, skipping extraction.\n",
            "P11 directory is not empty, skipping extraction.\n",
            "P12 directory is not empty, skipping extraction.\n",
            "P13 directory is not empty, skipping extraction.\n",
            "P14 directory is not empty, skipping extraction.\n",
            "P15 directory is not empty, skipping extraction.\n",
            "All participants download and extraction check completed!\n",
            "\n",
            "Listing contents of extracted P01 directory:\n",
            "/content/EEG_BCI_Hackathon/P01:\n",
            "P01\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01:\n",
            "S1  S2\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S1:\n",
            "eeg  electrode_positions\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S1/eeg:\n",
            "alldata_sbj01_sess1_MATBdiff.set  alldata_sbj01_sess1_RSraw.set\n",
            "alldata_sbj01_sess1_MATBeasy.set  alldata_sbj01_sess1_RS.set\n",
            "alldata_sbj01_sess1_MATBmed.set\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S1/electrode_positions:\n",
            "get_chanlocs.txt\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S2:\n",
            "eeg  electrode_positions\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S2/eeg:\n",
            "alldata_sbj01_sess2_MATBdiff.set  alldata_sbj01_sess2_RSraw.set\n",
            "alldata_sbj01_sess2_MATBeasy.set  alldata_sbj01_sess2_RS.set\n",
            "alldata_sbj01_sess2_MATBmed.set\n",
            "\n",
            "/content/EEG_BCI_Hackathon/P01/P01/S2/electrode_positions:\n",
            "get_chanlocs.txt\n",
            "\n",
            "Loading all EEG files...\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1883069239.py:82: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBdiff.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1883069239.py:82: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S1/eeg/alldata_sbj01_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1883069239.py:82: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n",
            "/tmp/ipython-input-1883069239.py:82: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBmed.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1883069239.py:82: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess2_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBdiff.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1883069239.py:82: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1883069239.py:82: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded alldata_sbj01_sess2_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P01/P01/S2/eeg/alldata_sbj01_sess2_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj01_sess2_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBeasy.set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1883069239.py:82: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess1_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess1_MATBmed.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBdiff.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_MATBdiff.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess1_MATBdiff.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RS.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S1/eeg/alldata_sbj02_sess1_RS.set...\n",
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess1_RS.set. Number of epochs: 30\n",
            "Checking directory: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBeasy.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBeasy.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Ready.\n",
            "Successfully loaded alldata_sbj02_sess2_MATBeasy.set. Number of epochs: 149\n",
            "Loading file: /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBmed.set\n",
            "Extracting parameters from /content/EEG_BCI_Hackathon/P02/P02/S2/eeg/alldata_sbj02_sess2_MATBmed.set...\n",
            "Not setting metadata\n",
            "149 matching events found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "# Assuming 'mne' and 'tqdm' are already imported from your previous environment setup.\n",
        "\n",
        "# Define the root directory where your data is stored\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "\n",
        "# Create a directory to save the individual processed NumPy files\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# List of participants\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n"
      ],
      "metadata": {
        "id": "AvtIxoKeQ_2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_epochs_list = []\n",
        "all_labels_list = []\n",
        "sfreq = 250 # Sampling frequency is assumed to be 250 Hz for this dataset\n",
        "\n",
        "for p_id in tqdm(participant_ids, desc=\"Loading and Saving Participants\"):\n",
        "\n",
        "    X_eeg_p = [] # EEG data for this participant\n",
        "    y_p = []     # Labels for this participant\n",
        "\n",
        "    # Iterate through both sessions (S1 and S2)\n",
        "    for session in ['S1', 'S2']:\n",
        "        eeg_dir = os.path.join(DATA_ROOT, p_id, p_id, session, 'eeg')\n",
        "\n",
        "        if not os.path.isdir(eeg_dir):\n",
        "            print(f\"Directory not found: {eeg_dir}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(eeg_dir):\n",
        "            if filename.endswith('.set') and 'MATB' in filename:\n",
        "                file_path = os.path.join(eeg_dir, filename)\n",
        "\n",
        "                # 1. Load the EEG file\n",
        "                epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
        "\n",
        "                # 2. Extract Data (X) and determine Label (y)\n",
        "                # The data loading needs to be careful about channel selection if 64 channels were loaded.\n",
        "\n",
        "                # Filter to common 60 channels if a standard 60-channel montage was used\n",
        "                if epochs.info['nchan'] == 64:\n",
        "                    epochs.drop_channels(['ECG', 'HEOG', 'VEOG', 'GSR'])\n",
        "\n",
        "                # Downsample to 250 Hz just in case the file was 500 Hz (common for this data)\n",
        "                if epochs.info['sfreq'] > sfreq:\n",
        "                     epochs.resample(sfreq=sfreq, copy=False)\n",
        "\n",
        "                X_eeg_p.append(epochs.get_data())\n",
        "\n",
        "                # Get the stress level (Easy=0, Med=1, Diff=2)\n",
        "                if 'easy' in filename.lower():\n",
        "                    label = 0\n",
        "                elif 'med' in filename.lower():\n",
        "                    label = 1\n",
        "                elif 'diff' in filename.lower():\n",
        "                    label = 2\n",
        "                else:\n",
        "                    continue # Skip RS and other files\n",
        "\n",
        "                # Create labels for all epochs in this file\n",
        "                y_p.append(np.full(len(epochs), label))\n",
        "\n",
        "    # 3. Stack and Save the participant's data to disk\n",
        "    if X_eeg_p:\n",
        "        X_p_stacked = np.concatenate(X_eeg_p, axis=0)\n",
        "        y_p_stacked = np.concatenate(y_p, axis=0)\n",
        "\n",
        "        np.save(os.path.join(SAVE_DIR, f'{p_id}_X.npy'), X_p_stacked)\n",
        "        np.save(os.path.join(SAVE_DIR, f'{p_id}_y.npy'), y_p_stacked)\n",
        "\n",
        "        print(f\"\\n--- Success: {p_id} saved. Shape X: {X_p_stacked.shape}\")\n",
        "\n",
        "        # Explicitly delete variables to free up memory immediately\n",
        "        del X_p_stacked, y_p_stacked, X_eeg_p, y_p\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n--- Warning: No MATB data found for {p_id}. Skipping save.\")\n",
        "\n",
        "print(\"\\n\\n✅ Data saving complete! All participant files are now safely on disk.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "FvDfASvtREHt",
        "outputId": "380b5ec6-031c-4c8f-9b00-1b2ba438eb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tqdm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2115352507.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m \u001b[0;31m# Sampling frequency is assumed to be 250 Hz for this dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipant_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Loading and Saving Participants\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_eeg_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# EEG data for this participant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already run the imports for os and numpy,\n",
        "# and the setup for DATA_ROOT, SAVE_DIR, and participant_ids.\n",
        "\n",
        "all_epochs_list = []\n",
        "all_labels_list = []\n",
        "sfreq = 250 # Sampling frequency is assumed to be 250 Hz for this dataset\n",
        "\n",
        "for p_id in tqdm(participant_ids, desc=\"Loading and Saving Participants\"):\n",
        "\n",
        "    X_eeg_p = [] # EEG data for this participant\n",
        "    y_p = []     # Labels for this participant\n",
        "\n",
        "    # Iterate through both sessions (S1 and S2)\n",
        "    for session in ['S1', 'S2']:\n",
        "        eeg_dir = os.path.join(DATA_ROOT, p_id, p_id, session, 'eeg')\n",
        "\n",
        "        if not os.path.isdir(eeg_dir):\n",
        "            print(f\"Directory not found: {eeg_dir}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(eeg_dir):\n",
        "            if filename.endswith('.set') and 'MATB' in filename:\n",
        "                file_path = os.path.join(eeg_dir, filename)\n",
        "\n",
        "                # 1. Load the EEG file\n",
        "                # NOTE: You must have MNE imported for this line to work.\n",
        "                epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
        "\n",
        "                # 2. Extract Data (X) and determine Label (y)\n",
        "\n",
        "                # Filter to common 60 channels if a standard 60-channel montage was used\n",
        "                if epochs.info['nchan'] == 64:\n",
        "                    epochs.drop_channels(['ECG', 'HEOG', 'VEOG', 'GSR'])\n",
        "\n",
        "                # Downsample to 250 Hz just in case the file was 500 Hz\n",
        "                if epochs.info['sfreq'] > sfreq:\n",
        "                     epochs.resample(sfreq=sfreq, copy=False)\n",
        "\n",
        "                X_eeg_p.append(epochs.get_data())\n",
        "\n",
        "                # Get the stress level (Easy=0, Med=1, Diff=2)\n",
        "                if 'easy' in filename.lower():\n",
        "                    label = 0\n",
        "                elif 'med' in filename.lower():\n",
        "                    label = 1\n",
        "                elif 'diff' in filename.lower():\n",
        "                    label = 2\n",
        "                else:\n",
        "                    continue # Skip RS and other files\n",
        "\n",
        "                # Create labels for all epochs in this file\n",
        "                y_p.append(np.full(len(epochs), label))\n",
        "\n",
        "    # 3. Stack and Save the participant's data to disk\n",
        "    if X_eeg_p:\n",
        "        X_p_stacked = np.concatenate(X_eeg_p, axis=0)\n",
        "        y_p_stacked = np.concatenate(y_p, axis=0)\n",
        "\n",
        "        np.save(os.path.join(SAVE_DIR, f'{p_id}_X.npy'), X_p_stacked)\n",
        "        np.save(os.path.join(SAVE_DIR, f'{p_id}_y.npy'), y_p_stacked)\n",
        "\n",
        "        print(f\"\\n--- Success: {p_id} saved. Shape X: {X_p_stacked.shape}\")\n",
        "\n",
        "        # Explicitly delete variables to free up memory immediately\n",
        "        del X_p_stacked, y_p_stacked, X_eeg_p, y_p, epochs\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n--- Warning: No MATB data found for {p_id}. Skipping save.\")\n",
        "\n",
        "print(\"\\n\\n✅ Data saving complete! All participant files are now safely on disk.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "dy99dmveROPc",
        "outputId": "fe0def0e-345d-497f-a779-e1eea6dd5337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading and Saving Participants:   0%|          | 0/15 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mne' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-615933903.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;31m# 1. Load the EEG file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;31m# NOTE: You must have MNE imported for this line to work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_epochs_eeglab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# 2. Extract Data (X) and determine Label (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mne' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import mne          # <--- You were missing this one!\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "MpZzTNkcRUUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming DATA_ROOT, SAVE_DIR, and participant_ids are already set from previous steps.\n",
        "# If not, you need to set them:\n",
        "# DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "# SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "# participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n",
        "\n",
        "sfreq = 250 # Target Sampling frequency\n",
        "\n",
        "for p_id in tqdm(participant_ids, desc=\"Loading and Saving Participants\"):\n",
        "\n",
        "    X_eeg_p = [] # EEG data for this participant\n",
        "    y_p = []     # Labels for this participant\n",
        "\n",
        "    for session in ['S1', 'S2']:\n",
        "        eeg_dir = os.path.join(DATA_ROOT, p_id, p_id, session, 'eeg')\n",
        "\n",
        "        if not os.path.isdir(eeg_dir):\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(eeg_dir):\n",
        "            if filename.endswith('.set') and 'MATB' in filename:\n",
        "                file_path = os.path.join(eeg_dir, filename)\n",
        "\n",
        "                # 1. Load the EEG file\n",
        "                epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
        "\n",
        "                # 2. Preprocessing & Data Extraction\n",
        "                if epochs.info['nchan'] == 64:\n",
        "                    epochs.drop_channels(['ECG', 'HEOG', 'VEOG', 'GSR'], on_missing='ignore')\n",
        "\n",
        "                if epochs.info['sfreq'] > sfreq:\n",
        "                     epochs.resample(sfreq=sfreq, copy=False)\n",
        "\n",
        "                X_eeg_p.append(epochs.get_data())\n",
        "\n",
        "                # Determine Label (Easy=0, Med=1, Diff=2)\n",
        "                if 'easy' in filename.lower():\n",
        "                    label = 0\n",
        "                elif 'med' in filename.lower():\n",
        "                    label = 1\n",
        "                elif 'diff' in filename.lower():\n",
        "                    label = 2\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "                y_p.append(np.full(len(epochs), label))\n",
        "\n",
        "    # 3. Stack and Save the participant's data to disk\n",
        "    if X_eeg_p:\n",
        "        X_p_stacked = np.concatenate(X_eeg_p, axis=0)\n",
        "        y_p_stacked = np.concatenate(y_p, axis=0)\n",
        "\n",
        "        np.save(os.path.join(SAVE_DIR, f'{p_id}_X.npy'), X_p_stacked)\n",
        "        np.save(os.path.join(SAVE_DIR, f'{p_id}_y.npy'), y_p_stacked)\n",
        "\n",
        "        # Free up memory\n",
        "        del X_p_stacked, y_p_stacked, X_eeg_p, y_p, epochs\n",
        "\n",
        "    # Optional print for progress, as tqdm handles the main bar\n",
        "    # print(f\"\\n--- Success: {p_id} saved.\")\n",
        "\n",
        "print(\"\\n\\n✅ Data saving complete! All participant files are now safely on disk.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-0u1As_RWu6",
        "outputId": "7f1f7440-1124-44d4-a1b0-06e3b53ecea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rLoading and Saving Participants:   0%|          | 0/15 [00:00<?, ?it/s]/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "Loading and Saving Participants:  20%|██        | 3/15 [00:13<00:50,  4.23s/it]/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "Loading and Saving Participants:  47%|████▋     | 7/15 [00:24<00:21,  2.74s/it]/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.3 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.0 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "Loading and Saving Participants:  60%|██████    | 9/15 [00:33<00:22,  3.69s/it]/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "Loading and Saving Participants:  67%|██████▋   | 10/15 [00:35<00:15,  3.16s/it]/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (10.9 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "Loading and Saving Participants:  80%|████████  | 12/15 [00:40<00:08,  2.81s/it]/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "/tmp/ipython-input-3501901947.py:25: RuntimeWarning: Estimated head radius (11.5 cm) is above the 99th percentile for adult head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
            "  epochs = mne.io.read_epochs_eeglab(file_path, verbose=False)\n",
            "Loading and Saving Participants: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "✅ Data saving complete! All participant files are now safely on disk.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# A. Load all saved data from disk\n",
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "\n",
        "# Concatenate all data into the final arrays\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "print(\"\\n--- Final Data Shape ---\")\n",
        "print(f\"X_eeg (Full Data) shape: {X_eeg.shape}\")\n",
        "print(f\"y (Full Labels) shape: {y.shape}\")\n",
        "\n",
        "# B. Data Splitting (Train/Test Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_eeg,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# C. Feature Scaling (Standardization)\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# Reshape back to 3D\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final Scaled X_train shape: {X_train_final.shape}\")\n",
        "print(f\"Final Scaled X_test shape: {X_test_final.shape}\")\n",
        "print(\"Your data is ready for model training! 🎉\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "H0aSjyqgRq6G",
        "outputId": "c8426792-f7ce-440c-d50e-cb2647dff28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'participant_ids' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2795423718.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mall_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparticipant_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mX_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{p_id}_X.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{p_id}_y.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'participant_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Re-define the variables (based on the previous successful steps)\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n"
      ],
      "metadata": {
        "id": "QYaDjAONR-MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A. Load all saved data from disk\n",
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    # Check if the file exists before attempting to load\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "    else:\n",
        "        print(f\"Warning: Could not find saved file for {p_id}. Skipping.\")\n",
        "\n",
        "# Concatenate all data into the final arrays\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "print(\"\\n--- Final Data Shape ---\")\n",
        "print(f\"X_eeg (Full Data) shape: {X_eeg.shape}\")\n",
        "print(f\"y (Full Labels) shape: {y.shape}\")\n",
        "\n",
        "# B. Data Splitting (Train/Test Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_eeg,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# C. Feature Scaling (Standardization)\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# Reshape back to 3D\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final Scaled X_train shape: {X_train_final.shape}\")\n",
        "print(f\"Final Scaled X_test shape: {X_test_final.shape}\")\n",
        "print(\"Your data is ready for model training! 🎉\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNU26zxkSCK6",
        "outputId": "f4b077c6-dbe5-422e-9d38-9d133f3f7bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Data Shape ---\n",
            "X_eeg (Full Data) shape: (13410, 61, 500)\n",
            "y (Full Labels) shape: (13410,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_eeg and y are the variables created in the previous step and are in memory\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# A. Data Splitting (Train/Test Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_eeg,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Splitting Complete ---\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "# B. Feature Scaling (Standardization)\n",
        "# 1. Reshape 3D (Epochs, Channels, Samples) to 2D (Epochs, Features)\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "# 2. Fit and Transform\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# 3. Reshape back to 3D for use in deep learning models (e.g., CNNs)\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final Scaled X_train shape: {X_train_final.shape}\")\n",
        "print(f\"Final Scaled X_test shape: {X_test_final.shape}\")\n",
        "print(\"Your data is ready for model training! 🚀\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "g7_HjkLGSXp7",
        "outputId": "99f831e8-8be6-42c8-804d-aef28c534be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_eeg' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1016070906.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# A. Data Splitting (Train/Test Split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX_eeg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_eeg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Re-define the variables (based on the previous successful memory-safe saving)\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n"
      ],
      "metadata": {
        "id": "PD0-0v6xSiVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A. Load all saved data from disk\n",
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "print(\"Loading saved NumPy files from disk...\")\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "    else:\n",
        "        # This will happen for any participant files that weren't successfully saved\n",
        "        # before the initial crash (P06-P15 if you didn't re-run the save script).\n",
        "        print(f\"Warning: Could not find saved file for {p_id}. Skipping.\")\n",
        "\n",
        "# Concatenate all data into the final arrays (This creates X_eeg and y)\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "print(\"\\n--- Final Data Stacking Complete ---\")\n",
        "print(f\"X_eeg (Full Data) shape: {X_eeg.shape}\")\n",
        "print(f\"y (Full Labels) shape: {y.shape}\")\n",
        "\n",
        "# B. Data Splitting (Train/Test Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_eeg,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Splitting Complete ---\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "# C. Feature Scaling (Standardization)\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# Reshape back to 3D\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final Scaled X_train shape: {X_train_final.shape}\")\n",
        "print(f\"Final Scaled X_test shape: {X_test_final.shape}\")\n",
        "print(\"Your data is ready for model training! 🎉\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "pyLGUAgbSkiz",
        "outputId": "b1348c7d-3dd2-4b1d-fd5e-3793f742e84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading saved NumPy files from disk...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'participant_ids' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2744073275.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading saved NumPy files from disk...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparticipant_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mX_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{p_id}_X.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{p_id}_y.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'participant_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A. Load all saved data from disk\n",
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "print(\"Loading saved NumPy files from disk...\")\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "    else:\n",
        "        # If your memory-safe save script didn't run to P15, this warning is expected.\n",
        "        print(f\"Warning: Could not find saved file for {p_id}. Skipping.\")\n",
        "\n",
        "# Concatenate all data into the final arrays (This creates X_eeg and y)\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "print(\"\\n--- Final Data Stacking Complete ---\")\n",
        "print(f\"X_eeg (Full Data) shape: {X_eeg.shape}\")\n",
        "print(f\"y (Full Labels) shape: {y.shape}\")\n",
        "\n",
        "# B. Data Splitting (Train/Test Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_eeg,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Splitting Complete ---\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "# C. Feature Scaling (Standardization)\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# Reshape back to 3D\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final Scaled X_train shape: {X_train_final.shape}\")\n",
        "print(f\"Final Scaled X_test shape: {X_test_final.shape}\")\n",
        "print(\"Your data is ready for model training! 🎉\")\n",
        "# A. Load all saved data from disk\n",
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "print(\"Loading saved NumPy files from disk...\")\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "    else:\n",
        "        # If your memory-safe save script didn't run to P15, this warning is expected.\n",
        "        print(f\"Warning: Could not find saved file for {p_id}. Skipping.\")\n",
        "\n",
        "# Concatenate all data into the final arrays (This creates X_eeg and y)\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "print(\"\\n--- Final Data Stacking Complete ---\")\n",
        "print(f\"X_eeg (Full Data) shape: {X_eeg.shape}\")\n",
        "print(f\"y (Full Labels) shape: {y.shape}\")\n",
        "\n",
        "# B. Data Splitting (Train/Test Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_eeg,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Splitting Complete ---\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "# C. Feature Scaling (Standardization)\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# Reshape back to 3D\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final Scaled X_train shape: {X_train_final.shape}\")\n",
        "print(f\"Final Scaled X_test shape: {X_test_final.shape}\")\n",
        "print(\"Your data is ready for model training! 🎉\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Fjc2wx-2S1oF",
        "outputId": "5605590e-a9ee-4e24-9b58-e6803ec1aaac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading saved NumPy files from disk...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'participant_ids' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-131793201.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading saved NumPy files from disk...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparticipant_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mX_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{p_id}_X.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{p_id}_y.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'participant_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Re-define the variables\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n"
      ],
      "metadata": {
        "id": "FSProAMeS67z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A. Load all saved data from disk\n",
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "print(\"Loading saved NumPy files from disk...\")\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "    else:\n",
        "        # If your memory-safe save script didn't run to P15, this warning is expected.\n",
        "        print(f\"Warning: Could not find saved file for {p_id}. Skipping.\")\n",
        "\n",
        "# Concatenate all data into the final arrays (This creates X_eeg and y)\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "print(\"\\n--- Final Data Stacking Complete ---\")\n",
        "print(f\"X_eeg (Full Data) shape: {X_eeg.shape}\")\n",
        "print(f\"y (Full Labels) shape: {y.shape}\")\n",
        "\n",
        "# B. Data Splitting (Train/Test Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_eeg,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Splitting Complete ---\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "# C. Feature Scaling (Standardization)\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# Reshape back to 3D\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final Scaled X_train shape: {X_train_final.shape}\")\n",
        "print(f\"Final Scaled X_test shape: {X_test_final.shape}\")\n",
        "print(\"Your data is ready for model training! 🎉\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSO58vxfS-jt",
        "outputId": "64be63e8-28d9-497b-8264-d7631c1e49e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading saved NumPy files from disk...\n",
            "\n",
            "--- Final Data Stacking Complete ---\n",
            "X_eeg (Full Data) shape: (13410, 61, 500)\n",
            "y (Full Labels) shape: (13410,)\n",
            "\n",
            "--- Data Splitting Complete ---\n",
            "X_train shape: (10728, 61, 500)\n",
            "X_test shape: (2682, 61, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_train, X_test, y_train, and y_test are in memory.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# C. Feature Scaling (Standardization)\n",
        "# 1. Reshape 3D (Epochs, Channels, Samples) to 2D (Epochs, Features)\n",
        "# StandardScaler requires a 2D array (samples, features).\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "# 2. Fit and Transform\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# 3. Reshape back to 3D\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final Scaled X_train shape: {X_train_final.shape}\")\n",
        "print(f\"Final Scaled X_test shape: {X_test_final.shape}\")\n",
        "print(\"Your data is now fully preprocessed and ready for model definition and training! 🚀\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "XgsPlbcVTZvm",
        "outputId": "01501484-cae4-492e-9831-8d554d930d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-553345236.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 1. Reshape 3D (Epochs, Channels, Samples) to 2D (Epochs, Features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# StandardScaler requires a 2D array (samples, features).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mn_epochs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mX_train_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_test_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Re-define the variables used for paths and participant lists\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n"
      ],
      "metadata": {
        "id": "si1NdPDWTmKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Re-define the variables used for paths and participant lists\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n",
        "\n",
        "# A. Load all saved data from disk (to recreate X_eeg and y)\n",
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "print(\"Loading saved NumPy files from disk...\")\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "    # Warning for missing files is helpful but not critical if previous steps ran fully\n",
        "\n",
        "# Concatenate all data into the final arrays\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "print(\"\\n--- Final Data Stacking Complete ---\")\n",
        "print(f\"X_eeg (Full Data) shape: {X_eeg.shape}\")\n",
        "print(f\"y (Full Labels) shape: {y.shape}\")\n",
        "\n",
        "# B. Data Splitting (Train/Test Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_eeg,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Splitting Complete ---\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "# C. Feature Scaling (Standardization)\n",
        "# 1. Reshape 3D to 2D\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "# 2. Fit and Transform\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# 3. Reshape back to 3D\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final Scaled X_train shape: {X_train_final.shape}\")\n",
        "print(f\"Final Scaled X_test shape: {X_test_final.shape}\")\n",
        "print(\"Your data is ready for model training! 🎉\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7tfhe4nTo_6",
        "outputId": "914cec7d-a0e5-4682-8a1a-958cb9bc2bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading saved NumPy files from disk...\n",
            "\n",
            "--- Final Data Stacking Complete ---\n",
            "X_eeg (Full Data) shape: (13410, 61, 500)\n",
            "y (Full Labels) shape: (13410,)\n",
            "\n",
            "--- Data Splitting Complete ---\n",
            "X_train shape: (10728, 61, 500)\n",
            "X_test shape: (2682, 61, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d22b8b11"
      },
      "source": [
        "## Build and train LSTM model on ECG sequences\n",
        "\n",
        "Next, we will build and train a Long Short-Term Memory (LSTM) model on the preprocessed ECG sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "37bb4d0c",
        "outputId": "6df11397-67de-4ba3-c016-ea4e59144a08"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Re-define the variables used for paths and participant lists to ensure they are available\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n",
        "\n",
        "# A. Load all saved EEG data from disk (to recreate X_eeg and y)\n",
        "# This section is kept as it provides the labels (y) and number of samples\n",
        "# which are assumed to be consistent across modalities for this task.\n",
        "all_X_eeg = []\n",
        "all_y = []\n",
        "\n",
        "print(\"Loading saved EEG NumPy files from disk...\")\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    if os.path.exists(X_path):\n",
        "        all_X_eeg.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "    # Warning for missing files is helpful but not critical if previous steps ran fully\n",
        "\n",
        "# Concatenate all data into the final arrays\n",
        "X_eeg_full = np.concatenate(all_X_eeg, axis=0)\n",
        "y_full = np.concatenate(all_y, axis=0)\n",
        "\n",
        "print(\"\\n--- Final EEG Data Stacking Complete ---\")\n",
        "print(f\"X_eeg (Full Data) shape: {X_eeg_full.shape}\")\n",
        "print(f\"y (Full Labels) shape: {y_full.shape}\")\n",
        "\n",
        "\n",
        "# --- Placeholder for REAL ECG data loading and preprocessing ---\n",
        "# REPLACE THIS SECTION with your code to load and preprocess the actual ECG data.\n",
        "# Your code should produce two numpy arrays:\n",
        "# X_ecg_full: Preprocessed ECG sequences, shape (num_samples, num_timesteps, num_features)\n",
        "#             num_samples should match X_eeg_full.shape[0]\n",
        "# y_ecg_full: Corresponding labels, shape (num_samples,) or (num_samples, num_classes)\n",
        "#             These should ideally match y_full.\n",
        "\n",
        "print(\"\\n--- Placeholder for Real ECG Data Loading ---\")\n",
        "print(\"Please replace this section with your code to load and preprocess the actual ECG data.\")\n",
        "print(\"Ensure your preprocessed ECG data is stored in a numpy array named `X_ecg_full`\")\n",
        "print(\"with shape (num_samples, num_timesteps, num_features) where num_samples\")\n",
        "print(\"matches the number of EEG epochs, and num_timesteps and num_features are\")\n",
        "print(\"appropriate for your ECG data and LSTM model.\")\n",
        "print(\"Also, ensure you have a corresponding labels array `y_ecg_full`.\")\n",
        "\n",
        "# Example placeholder variables - REPLACE WITH REAL DATA LOADING\n",
        "# Assuming you will load and preprocess your ECG data into these variables:\n",
        "X_ecg_full = np.random.rand(y_full.shape[0], 1000, 1) # Example shape\n",
        "y_ecg_full = y_full # Assuming labels are the same as EEG\n",
        "\n",
        "\n",
        "print(\"\\n--- Placeholder ECG Data Loading Complete (Replace with Real Data) ---\")\n",
        "print(f\"Placeholder X_ecg_full shape: {X_ecg_full.shape}\")\n",
        "print(f\"Placeholder y_ecg_full shape: {y_ecg_full.shape}\")\n",
        "\n",
        "# Ensure the number of samples match between EEG labels and ECG data/labels\n",
        "if X_ecg_full.shape[0] != y_full.shape[0] or y_ecg_full.shape[0] != y_full.shape[0]:\n",
        "     print(\"Warning: Number of samples in placeholder ECG data/labels does not match EEG labels.\")\n",
        "     print(\"Ensure your real ECG data loading provides consistent sample counts.\")\n",
        "\n",
        "# --- End of Placeholder Section ---\n",
        "\n",
        "\n",
        "# Use the loaded/placeholder ECG data and the consistent labels (y_full) for LSTM training\n",
        "X_ecg_for_lstm = X_ecg_full\n",
        "y_for_lstm = y_full # Using the labels loaded from EEG data, assuming they apply to ECG as well\n",
        "\n",
        "# 1. Define the input shape for the LSTM model\n",
        "# The required input shape for an LSTM layer is typically (num_timesteps, num_features).\n",
        "input_shape_lstm = (X_ecg_for_lstm.shape[1], X_ecg_for_lstm.shape[2])\n",
        "\n",
        "print(f\"\\nLSTM Input Shape: {input_shape_lstm}\")\n",
        "\n",
        "# 2. Define the number of output classes\n",
        "num_classes = len(np.unique(y_for_lstm))\n",
        "print(f\"Number of Output Classes: {num_classes}\")\n",
        "\n",
        "# Convert labels to one-hot encoding if needed for the loss function\n",
        "# Check if y_for_lstm is already one-hot encoded (e.g., shape ends with number of classes)\n",
        "if y_for_lstm.ndim == 1 or y_for_lstm.shape[1] != num_classes:\n",
        "    lb_lstm = LabelBinarizer()\n",
        "    y_onehot_lstm = lb_lstm.fit_transform(y_for_lstm)\n",
        "    print(\"Labels converted to one-hot encoding for LSTM.\")\n",
        "else:\n",
        "    y_onehot_lstm = y_for_lstm\n",
        "    print(\"Labels are already in the expected format for LSTM.\")\n",
        "\n",
        "\n",
        "# 3. Build a Sequential Keras model for the LSTM\n",
        "lstm_model = Sequential()\n",
        "\n",
        "# 4. Add an LSTM layer\n",
        "# Using 64 units as an example, return_sequences=False for classification after the last timestep\n",
        "lstm_model.add(Input(shape=input_shape_lstm))\n",
        "lstm_model.add(LSTM(units=64, return_sequences=False))\n",
        "\n",
        "# 5. Add a Dropout layer\n",
        "lstm_model.add(Dropout(0.5)) # Using 50% dropout as an example\n",
        "\n",
        "# 6. Add a Dense output layer\n",
        "lstm_model.add(Dense(num_classes, activation='softmax')) # Use softmax for multi-class classification\n",
        "\n",
        "# 7. Compile the LSTM model\n",
        "# Use categorical_crossentropy for one-hot encoded labels\n",
        "lstm_model.compile(optimizer='adam',\n",
        "                   loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "# 8. Print the summary of the LSTM model\n",
        "print(\"\\nLSTM Model Summary:\")\n",
        "lstm_model.summary()\n",
        "\n",
        "# 9. Split the ECG data and labels into training and validation sets\n",
        "# Use the same random_state as the EEG split for consistency.\n",
        "X_train_lstm, X_test_lstm, y_train_lstm_onehot, y_test_lstm_onehot = train_test_split(\n",
        "    X_ecg_for_lstm,\n",
        "    y_onehot_lstm,\n",
        "    test_size=0.2, # Use the same test size as the EEG split\n",
        "    random_state=42,\n",
        "    stratify=y_onehot_lstm\n",
        ")\n",
        "\n",
        "# Split training data further for validation during training\n",
        "X_train_lstm_split, X_val_lstm_split, y_train_lstm_onehot_split, y_val_lstm_onehot_split = train_test_split(\n",
        "    X_train_lstm,\n",
        "    y_train_lstm_onehot,\n",
        "    test_size=0.15, # Using 15% of training data for validation\n",
        "    random_state=42,\n",
        "    stratify=y_train_lstm_onehot\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"\\nLSTM Training data shape: {X_train_lstm_split.shape}\")\n",
        "print(f\"LSTM Validation data shape: {X_val_lstm_split.shape}\")\n",
        "print(f\"LSTM Test data shape: {X_test_lstm.shape}\")\n",
        "\n",
        "\n",
        "# 10. Train the compiled LSTM model using the training data and validate on the validation data\n",
        "print(\"\\nTraining LSTM model...\") # Removed \"with placeholder data\"\n",
        "\n",
        "history_lstm = lstm_model.fit(X_train_lstm_split, y_train_lstm_onehot_split,\n",
        "                              epochs=20, # Example: Train for 20 epochs (same as CNN)\n",
        "                              batch_size=32, # Example: Batch size of 32 (same as CNN)\n",
        "                              validation_data=(X_val_lstm_split, y_val_lstm_onehot_split))\n",
        "\n",
        "# 11. Print a message indicating the completion of LSTM model training\n",
        "print(\"\\nLSTM model training completed.\") # Removed \"on placeholder data\"\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "print(\"\\nEvaluating LSTM model on test set...\")\n",
        "loss_lstm, accuracy_lstm = lstm_model.evaluate(X_test_lstm, y_test_lstm_onehot, verbose=0)\n",
        "print(f\"LSTM Model Test Accuracy: {accuracy_lstm:.4f}\")\n",
        "print(f\"LSTM Model Test Loss: {loss_lstm:.4f}\")\n",
        "\n",
        "\n",
        "# Store the trained LSTM model and test predictions for later ensemble\n",
        "trained_lstm_model = lstm_model\n",
        "lstm_test_predictions_proba = lstm_model.predict(X_test_lstm)\n",
        "print(\"\\nLSTM model and test predictions stored.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading saved EEG NumPy files from disk...\n",
            "\n",
            "--- Final EEG Data Stacking Complete ---\n",
            "X_eeg (Full Data) shape: (13410, 61, 500)\n",
            "y (Full Labels) shape: (13410,)\n",
            "\n",
            "--- Placeholder for Real ECG Data Loading ---\n",
            "Please replace this section with your code to load and preprocess the actual ECG data.\n",
            "Ensure your preprocessed ECG data is stored in a numpy array named `X_ecg_full`\n",
            "with shape (num_samples, num_timesteps, num_features) where num_samples\n",
            "matches the number of EEG epochs, and num_timesteps and num_features are\n",
            "appropriate for your ECG data and LSTM model.\n",
            "Also, ensure you have a corresponding labels array `y_ecg_full`.\n",
            "\n",
            "--- Placeholder ECG Data Loading Complete (Replace with Real Data) ---\n",
            "Placeholder X_ecg_full shape: (13410, 1000, 1)\n",
            "Placeholder y_ecg_full shape: (13410,)\n",
            "\n",
            "LSTM Input Shape: (1000, 1)\n",
            "Number of Output Classes: 3\n",
            "Labels converted to one-hot encoding for LSTM.\n",
            "\n",
            "LSTM Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,091\u001b[0m (66.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,091</span> (66.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,091\u001b[0m (66.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,091</span> (66.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LSTM Training data shape: (9118, 1000, 1)\n",
            "LSTM Validation data shape: (1610, 1000, 1)\n",
            "LSTM Test data shape: (2682, 1000, 1)\n",
            "\n",
            "Training LSTM model...\n",
            "Epoch 1/20\n",
            "\u001b[1m226/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22s\u001b[0m 388ms/step - accuracy: 0.3370 - loss: 1.1001"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4088884915.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining LSTM model...\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Removed \"with placeholder data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m history_lstm = lstm_model.fit(X_train_lstm_split, y_train_lstm_onehot_split,\n\u001b[0m\u001b[1;32m    151\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Example: Train for 20 epochs (same as CNN)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Example: Batch size of 32 (same as CNN)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_train_final, X_test_final, y_train, y_test are the scaled and split data arrays\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os # Import os for path joining\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Re-define the variables used for paths and participant lists to ensure they are available\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n",
        "\n",
        "# A. Load all saved data from disk (to recreate X_eeg and y)\n",
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "print(\"Loading saved NumPy files from disk...\")\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "    # Warning for missing files is helpful but not critical if previous steps ran fully\n",
        "\n",
        "# Concatenate all data into the final arrays\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "print(\"\\n--- Final Data Stacking Complete ---\")\n",
        "print(f\"X_eeg (Full Data) shape: {X_eeg.shape}\")\n",
        "print(f\"y (Full Labels) shape: {y.shape}\")\n",
        "\n",
        "# B. Data Splitting (Train/Test Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_eeg,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Splitting Complete ---\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "# C. Feature Scaling (Standardization)\n",
        "# 1. Reshape 3D (Epochs, Channels, Samples) to 2D (Epochs, Features)\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "# 2. Fit and Transform\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# 3. Reshape back to 3D\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final Scaled X_train shape: {X_train_final.shape}\")\n",
        "print(f\"Final Scaled X_test shape: {X_test_final.shape}\")\n",
        "\n",
        "\n",
        "# Reshape from (N, 61 Channels, 500 Samples) to (N, 500 Samples, 61 Channels)\n",
        "X_train_lstm = np.transpose(X_train_final, (0, 2, 1))\n",
        "X_test_lstm = np.transpose(X_test_final, (0, 2, 1))\n",
        "num_classes = len(np.unique(y)) # Get num_classes from the actual labels\n",
        "\n",
        "# One-Hot Encode Labels\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "print(\"Data Reshaping Complete.\")\n",
        "print(f\"Final Input Shape for LSTM: {X_train_lstm.shape[1:]}\")\n",
        "# This should confirm the correct shape: (500, 61)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88PUCiRjYUjp",
        "outputId": "bd6624db-adbd-4538-b2d2-1579b158e37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading saved NumPy files from disk...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- 1. Define Setup Variables and File Paths ---\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n",
        "num_classes = 3\n",
        "\n",
        "# Load data and labels for splitting (this part must fit in memory)\n",
        "all_X = []\n",
        "all_y = []\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "# --- 2. Split the INDEXES, not the huge X_eeg array ---\n",
        "# This saves memory by only storing integers (indexes)\n",
        "indices = np.arange(X_eeg.shape[0])\n",
        "X_train_idx, X_test_idx, y_train, y_test = train_test_split(\n",
        "    indices, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- 3. Fit the Scaler on a small sample or one participant's data (Memory-safe fit) ---\n",
        "# We use P01's data to fit the scaler, assuming it's representative.\n",
        "X_sample = np.load(os.path.join(SAVE_DIR, 'P01_X.npy'))\n",
        "X_sample_reshaped = X_sample.reshape(X_sample.shape[0], -1)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_sample_reshaped)\n",
        "print(\"Scaler fitted successfully on sample data.\")\n",
        "del X_sample, X_sample_reshaped\n",
        "\n",
        "# --- 4. Define the Data Generator Class (The memory-saver) ---\n",
        "\n",
        "class EEGSequence(Sequence):\n",
        "    def __init__(self, X_indices, y_labels, scaler, batch_size=64, shuffle=True):\n",
        "        self.X_indices = X_indices\n",
        "        self.y_labels = y_labels\n",
        "        self.scaler = scaler\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        # Remap global indices to their original arrays (simplification)\n",
        "        # For simplicity, we assume we load from the X_eeg array loaded above.\n",
        "        self.X_full = X_eeg\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.X_indices) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Generate indexes of the batch\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Load the batch data from the full array\n",
        "        X_batch_raw = self.X_full[batch_indices]\n",
        "        y_batch = self.y_labels[batch_indices]\n",
        "\n",
        "        # Preprocess and transform\n",
        "        X_batch = self._preprocess(X_batch_raw)\n",
        "\n",
        "        return X_batch, tf.keras.utils.to_categorical(y_batch, num_classes=num_classes)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.arange(len(self.X_indices))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def _preprocess(self, X_raw):\n",
        "        # Scale (must reshape to 2D for scaler)\n",
        "        N, C, S = X_raw.shape\n",
        "        X_reshaped = X_raw.reshape(N, C * S)\n",
        "        X_scaled = self.scaler.transform(X_reshaped)\n",
        "\n",
        "        # Reshape back to 3D and then transpose for LSTM (N, Samples, Channels)\n",
        "        X_final = X_scaled.reshape(N, C, S)\n",
        "        X_lstm = np.transpose(X_final, (0, 2, 1))\n",
        "        return X_lstm\n",
        "\n",
        "# --- 5. Create Generators ---\n",
        "train_generator = EEGSequence(X_train_idx, y_train, scaler, shuffle=True)\n",
        "validation_generator = EEGSequence(X_test_idx, y_test, scaler, shuffle=False)\n",
        "\n",
        "# --- 6. Define and Train Model with Generator ---\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "\n",
        "# Input shape is (500, 61)\n",
        "input_shape = (500, 61)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=input_shape))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n🚀 Starting Training using Memory-Safe Generator...\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=20,\n",
        "    verbose=1,\n",
        "    # Removed the 'workers' argument as it's not supported by the TensorFlowTrainer.fit method\n",
        ")"
      ],
      "metadata": {
        "id": "8IaN7JpsZopU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# --- 1. Define Setup Variables ---\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n",
        "num_classes = 3\n",
        "\n",
        "print(\"Starting full data pipeline...\")\n",
        "\n",
        "# --- 2. Load and Stack Data from Disk (Recreate X_eeg and y) ---\n",
        "all_X = []\n",
        "all_y = []\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "        all_y.append(np.load(y_path))\n",
        "\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "print(f\"Data Loaded: X_eeg shape {X_eeg.shape}\")\n",
        "\n",
        "# --- 3. Data Splitting ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_eeg,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# --- 4. Feature Scaling (Standardization) ---\n",
        "n_epochs_train, n_channels, n_samples = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(n_epochs_train, n_channels * n_samples)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], n_channels * n_samples)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "X_train_final = X_train_scaled.reshape(n_epochs_train, n_channels, n_samples)\n",
        "X_test_final = X_test_scaled.reshape(X_test.shape[0], n_channels, n_samples)\n",
        "print(f\"Data Scaled: X_train_final shape {X_train_final.shape}\")\n",
        "\n",
        "# --- 5. LSTM Reshape and One-Hot Encoding ---\n",
        "# Reshape from (N, Channels, Samples) to (N, Samples, Channels) for LSTM\n",
        "X_train_lstm = np.transpose(X_train_final, (0, 2, 1))\n",
        "X_test_lstm = np.transpose(X_test_final, (0, 2, 1))\n",
        "\n",
        "# One-Hot Encode Labels\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "print(f\"\\n✅ Final Correct Input Shape: {X_train_lstm.shape}\") # Should be (10728, 500, 61)\n",
        "print(f\"Test Data Shape: {X_test_lstm.shape}\") # Should be (2682, 500, 61)\n",
        "\n",
        "# --- 6. Define and Compile the Model (CORRECT SHAPE) ---\n",
        "input_shape = X_train_lstm.shape[1:] # This will be (500, 61)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=input_shape))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\n--- Corrected Model Summary ---\")\n",
        "model.summary()\n",
        "\n",
        "# --- 7. Start Training on ACTUAL EEG DATA ---\n",
        "print(\"\\n🚀 Starting Training on ACTUAL EEG Data...\")\n",
        "history = model.fit(\n",
        "    X_train_lstm,\n",
        "    y_train_one_hot,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test_lstm, y_test_one_hot),\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgOhl_JpZpcu",
        "outputId": "feeb010a-0cf3-4c44-dac0-847e6561c039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting full data pipeline...\n",
            "Data Loaded: X_eeg shape (13410, 61, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "\n",
        "# --- 1. Quick Data Setup (Assumes X_eeg and y_labels are in memory) ---\n",
        "# NOTE: This part requires the Keras Data Generator (EEGSequence) and\n",
        "# the train_generator/validation_generator objects to be accessible.\n",
        "# If you get an error here, you must run the data setup cell that defines these objects first.\n",
        "\n",
        "# Assuming the generators are available from the previous run:\n",
        "# X_eeg, y_labels, scaler, train_generator, validation_generator\n",
        "\n",
        "# --- 2. Model Definition (The core object needed for saving) ---\n",
        "input_shape = (500, 61)\n",
        "num_classes = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 5, activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"CNN Model Defined. Running for 2 epochs to restore object...\")\n",
        "\n",
        "# --- 3. Quick Re-Training (Set epochs=2 to run fast) ---\n",
        "# NOTE: If the generator variables (e.g., train_generator) are NOT in memory,\n",
        "# this will fail, and you need to run the data setup cell first.\n",
        "try:\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=validation_generator,\n",
        "        epochs=2,  # Set low for quick re-run\n",
        "        verbose=1,\n",
        "        workers=4\n",
        "    )\n",
        "    print(\"\\nModel training finished successfully.\")\n",
        "except NameError as e:\n",
        "    print(f\"\\n⚠️ ERROR: Generator object not found: {e}\")\n",
        "    print(\"Please go back and run the cell that created 'train_generator' and 'validation_generator' before re-running this save code.\")\n",
        "    # Exit the block to prevent saving an untrained model if training failed\n",
        "\n",
        "# --- 4. Save the Model ---\n",
        "model_save_path = '/content/task_risk_cnn_best_model.h5'\n",
        "\n",
        "if 'model' in locals() or 'model' in globals():\n",
        "    try:\n",
        "        model.save(model_save_path)\n",
        "        print(f\"\\n✅ BEST Model (CNN) successfully saved to: {model_save_path}\")\n",
        "        print(\"Your superior model is now ready for download!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n⚠️ ERROR during save: {e}\")\n",
        "else:\n",
        "    print(\"\\n⚠️ ERROR: Model object not in memory, even after re-run attempt.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WqiFf1Wgf9b",
        "outputId": "809ddb0d-0d1a-4ccf-aaa4-00b0f35a9d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Model Defined. Running for 2 epochs to restore object...\n",
            "\n",
            "⚠️ ERROR: Generator object not found: name 'train_generator' is not defined\n",
            "Please go back and run the cell that created 'train_generator' and 'validation_generator' before re-running this save code.\n",
            "\n",
            "✅ BEST Model (CNN) successfully saved to: /content/task_risk_cnn_best_model.h5\n",
            "Your superior model is now ready for download!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy.stats import iqr, skew\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- Define Setup Variables ---\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n",
        "\n",
        "# --- 2. Feature Extraction Function ---\n",
        "def extract_statistical_features(X_data):\n",
        "    \"\"\"\n",
        "    Extracts 6 statistical features per channel: Mean, Median, Std Dev, Min, Max, IQR, Skewness.\n",
        "    Input X_data shape: (n_epochs, n_channels, n_samples)\n",
        "    Output features shape: (n_epochs, n_channels * n_features)\n",
        "    \"\"\"\n",
        "    n_epochs, n_channels, n_samples = X_data.shape\n",
        "\n",
        "    # Calculate features across the sample dimension (axis=2)\n",
        "    features = {\n",
        "        'mean': np.mean(X_data, axis=2),\n",
        "        'median': np.median(X_data, axis=2),\n",
        "        'std': np.std(X_data, axis=2),\n",
        "        'min': np.min(X_data, axis=2),\n",
        "        'max': np.max(X_data, axis=2),\n",
        "        'iqr': iqr(X_data, axis=2),\n",
        "        'skew': skew(X_data, axis=2)\n",
        "    }\n",
        "\n",
        "    # Concatenate all features (resulting in shape (n_epochs, n_channels * 7))\n",
        "    feature_list = [v for k, v in features.items()]\n",
        "    X_features = np.concatenate(feature_list, axis=1)\n",
        "\n",
        "    return X_features\n",
        "\n",
        "print(\"Setup complete. Feature extraction function defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM9tP8uNggkH",
        "outputId": "a6650b9b-a750-4d26-e2f8-71c792f229e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Feature extraction function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_X_features = []\n",
        "all_y_labels = []\n",
        "\n",
        "print(\"Starting memory-efficient feature extraction (participant by participant)...\")\n",
        "\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    if os.path.exists(X_path):\n",
        "        # Load one participant's data (less memory burden)\n",
        "        X_eeg_participant = np.load(X_path)\n",
        "        y_labels_participant = np.load(y_path)\n",
        "\n",
        "        # Extract features\n",
        "        X_features_participant = extract_statistical_features(X_eeg_participant)\n",
        "\n",
        "        # Store features and labels\n",
        "        all_X_features.append(X_features_participant)\n",
        "        all_y_labels.append(y_labels_participant)\n",
        "\n",
        "        # Crucial step: Delete the large raw EEG array from memory\n",
        "        del X_eeg_participant\n",
        "\n",
        "        print(f\"Processed {p_id}. Features shape: {X_features_participant.shape}\")\n",
        "\n",
        "# Concatenate all features into final memory-friendly arrays\n",
        "X_features = np.concatenate(all_X_features, axis=0)\n",
        "y_labels = np.concatenate(all_y_labels, axis=0)\n",
        "\n",
        "print(\"\\nFeature Extraction Complete.\")\n",
        "print(f\"Final Feature Matrix shape (X): {X_features.shape}\")\n",
        "print(f\"Final Label Vector shape (y): {y_labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKdw2owignNR",
        "outputId": "f989b276-991b-491a-910b-ce27255a61ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting memory-efficient feature extraction (participant by participant)...\n",
            "Processed P01. Features shape: (894, 427)\n",
            "Processed P02. Features shape: (894, 427)\n",
            "Processed P03. Features shape: (894, 427)\n",
            "Processed P04. Features shape: (894, 427)\n",
            "Processed P05. Features shape: (894, 427)\n",
            "Processed P06. Features shape: (894, 427)\n",
            "Processed P07. Features shape: (894, 427)\n",
            "Processed P08. Features shape: (894, 427)\n",
            "Processed P09. Features shape: (894, 427)\n",
            "Processed P10. Features shape: (894, 427)\n",
            "Processed P11. Features shape: (894, 427)\n",
            "Processed P12. Features shape: (894, 427)\n",
            "Processed P13. Features shape: (894, 427)\n",
            "Processed P14. Features shape: (894, 427)\n",
            "Processed P15. Features shape: (894, 427)\n",
            "\n",
            "Feature Extraction Complete.\n",
            "Final Feature Matrix shape (X): (13410, 427)\n",
            "Final Label Vector shape (y): (13410,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Split the feature and label data\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n",
        "    X_features,\n",
        "    y_labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_labels\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set features shape: {X_train_rf.shape}\")\n",
        "\n",
        "# 2. Initialize and train the Random Forest Model\n",
        "print(\"Initializing and training Random Forest Classifier...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,      # Number of trees\n",
        "    max_depth=15,          # Maximum depth of trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1              # Use all available cores for speed\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "print(\"\\nRandom Forest Training Complete. Evaluating model...\")\n",
        "\n",
        "# 3. Evaluate the model\n",
        "y_pred_rf = rf_model.predict(X_test_rf)\n",
        "\n",
        "print(\"\\n--- Random Forest Classification Report ---\")\n",
        "print(classification_report(y_test_rf, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb26SVlIa6Nd",
        "outputId": "c9623809-9dc3-4bd1-d5ae-b662532690c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set features shape: (10728, 427)\n",
            "Initializing and training Random Forest Classifier...\n",
            "\n",
            "Random Forest Training Complete. Evaluating model...\n",
            "\n",
            "--- Random Forest Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.78      0.72       894\n",
            "           1       0.56      0.43      0.49       894\n",
            "           2       0.60      0.65      0.63       894\n",
            "\n",
            "    accuracy                           0.62      2682\n",
            "   macro avg       0.61      0.62      0.61      2682\n",
            "weighted avg       0.61      0.62      0.61      2682\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# --- Define the necessary variables from the Random Forest training block ---\n",
        "# These variables should still be in memory:\n",
        "# X_test_rf (Test features)\n",
        "# y_test_rf (True test labels)\n",
        "# rf_model (The trained Random Forest object)\n",
        "# y_pred_rf (Predicted test labels from the Random Forest)\n",
        "\n",
        "# 1. Store the Random Forest predictions for the report\n",
        "rf_results_df = pd.DataFrame({\n",
        "    'True_Label': y_test_rf,\n",
        "    'Predicted_Label': y_pred_rf\n",
        "})\n",
        "\n",
        "rf_results_df.to_csv('/content/rf_final_test_predictions.csv', index=False)\n",
        "print(\"✅ Random Forest test predictions (True vs. Predicted) saved to: /content/rf_final_test_predictions.csv\")\n",
        "\n",
        "# 2. Calculate and print the confusion matrix (Excellent addition to your report)\n",
        "cm = confusion_matrix(y_test_rf, y_pred_rf)\n",
        "print(\"\\n--- Final Random Forest Confusion Matrix ---\")\n",
        "print(\"Rows are True Labels (0, 1, 2); Columns are Predicted Labels (0, 1, 2)\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y73lqn8giKLS",
        "outputId": "a94505cc-3092-4cdc-b0d6-b078e84f0088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Random Forest test predictions (True vs. Predicted) saved to: /content/rf_final_test_predictions.csv\n",
            "\n",
            "--- Final Random Forest Confusion Matrix ---\n",
            "Rows are True Labels (0, 1, 2); Columns are Predicted Labels (0, 1, 2)\n",
            "[[695 115  84]\n",
            " [205 383 306]\n",
            " [126 184 584]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the path where you want to save the CNN model\n",
        "model_save_path = '/content/task_risk_cnn_best_model.h5'\n",
        "\n",
        "# Assuming your best CNN model object is still named 'model' from its training cell\n",
        "try:\n",
        "    # This line attempts to save the CNN model object\n",
        "    model.save(model_save_path)\n",
        "    print(f\"\\n✅ BEST Model (CNN) successfully saved to: {model_save_path}\")\n",
        "    print(\"Your project is now complete. You have successfully trained and evaluated two models and saved the best one.\")\n",
        "except NameError:\n",
        "    print(\"\\n⚠️ ERROR: CNN model object ('model') not found in memory.\")\n",
        "    print(\"You must re-run the final CNN training/definition cell one more time to redefine the model before saving.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mZutMIAiX_A",
        "outputId": "ed12e2c2-faba-4ca6-a936-273cf9b6cf58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⚠️ ERROR: CNN model object ('model') not found in memory.\n",
            "You must re-run the final CNN training/definition cell one more time to redefine the model before saving.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjFGNEVLjV6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kxoJ4pncjWfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MqZCd0RsjX1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8503c0"
      },
      "source": [
        "## Combine Predictions from Individual Models (Ensemble)\n",
        "\n",
        "Now that we have trained the individual models (CNN and Random Forest), we can combine their predictions to create an ensemble model. Since the LSTM model training is pending due to the lack of real ECG data, we will proceed by combining the predictions from the CNN and Random Forest models that are available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "890f1f71",
        "outputId": "acdcea24-42cc-4340-9829-dddd4577bb11"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import tensorflow as tf # Import tensorflow for to_categorical\n",
        "import os # Import os for path joining\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split\n",
        "\n",
        "\n",
        "# Re-define the variables used for paths and participant lists to ensure they are available\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n",
        "\n",
        "# A. Load all saved data from disk (to recreate X_eeg and y)\n",
        "# We only need 'y' for splitting the test set labels\n",
        "all_y = []\n",
        "\n",
        "print(\"Loading saved NumPy labels from disk for splitting...\")\n",
        "for p_id in participant_ids:\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "    if os.path.exists(y_path):\n",
        "        all_y.append(np.load(y_path))\n",
        "    # Warning for missing files is helpful but not critical if previous steps ran fully\n",
        "\n",
        "y_full = np.concatenate(all_y, axis=0)\n",
        "print(f\"Full Labels shape: {y_full.shape}\")\n",
        "\n",
        "# Split the INDEXES based on the full labels\n",
        "indices = np.arange(y_full.shape[0])\n",
        "# We only need y_test here for the ensemble evaluation\n",
        "X_train_idx, X_test_idx, y_train, y_test = train_test_split(\n",
        "    indices, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Splitting Complete (for test labels) ---\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "\n",
        "# Assuming cnn_test_predictions_proba (from CNN) and y_pred_rf (from Random Forest) are available in memory.\n",
        "# cnn_test_predictions_proba: shape (n_test_samples, num_classes) - probabilities\n",
        "# y_pred_rf: shape (n_test_samples,) - predicted class labels (integers)\n",
        "# y_test (True test labels, integers) should also be available from the splitting step.\n",
        "\n",
        "# Ensure y_pred_rf is one-hot encoded to match the shape of cnn_test_predictions_proba\n",
        "num_classes = len(np.unique(y_test))\n",
        "y_pred_rf_onehot = tf.keras.utils.to_categorical(y_pred_rf, num_classes=num_classes)\n",
        "print(f\"Random Forest test predictions (one-hot) shape: {y_pred_rf_onehot.shape}\")\n",
        "\n",
        "\n",
        "# --- Ensemble Strategy: Averaging Prediction Probabilities ---\n",
        "# For simplicity, we'll average the prediction probabilities from the CNN and the one-hot encoded RF predictions.\n",
        "# If the LSTM predictions were available (lstm_test_predictions_proba), they would be included here as well.\n",
        "\n",
        "# Combine available predictions (CNN and RF)\n",
        "# Note: This simple averaging assumes both models' outputs are directly comparable (probabilities or one-hot).\n",
        "# If models output probabilities and others output hard labels, you need to adjust.\n",
        "# Here, we treat the RF hard labels as a one-hot representation for averaging.\n",
        "combined_predictions_proba = (cnn_test_predictions_proba + y_pred_rf_onehot) / 2.0\n",
        "\n",
        "# Get the final predicted class by taking the argmax (class with highest probability)\n",
        "ensemble_predictions = np.argmax(combined_predictions_proba, axis=1)\n",
        "\n",
        "print(\"\\nEnsemble predictions generated.\")\n",
        "print(f\"Ensemble predictions shape: {ensemble_predictions.shape}\")\n",
        "\n",
        "# --- Evaluate the Ensemble Model ---\n",
        "print(\"\\n--- Ensemble Model Evaluation ---\")\n",
        "\n",
        "# Calculate and print accuracy\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
        "print(f\"Ensemble Model Test Accuracy: {ensemble_accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print classification report\n",
        "print(\"\\n--- Ensemble Model Classification Report ---\")\n",
        "print(classification_report(y_test, ensemble_predictions))\n",
        "\n",
        "# Calculate and print confusion matrix\n",
        "ensemble_cm = confusion_matrix(y_test, ensemble_predictions)\n",
        "print(\"\\n--- Ensemble Model Confusion Matrix ---\")\n",
        "print(\"Rows are True Labels (0, 1, 2); Columns are Predicted Labels (0, 1, 2)\")\n",
        "print(ensemble_cm)\n",
        "\n",
        "print(\"\\n✅ Ensemble model evaluation complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading saved NumPy labels from disk for splitting...\n",
            "Full Labels shape: (13410,)\n",
            "\n",
            "--- Data Splitting Complete (for test labels) ---\n",
            "y_test shape: (2682,)\n",
            "Random Forest test predictions (one-hot) shape: (2682, 3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cnn_test_predictions_proba' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2846375026.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# If models output probabilities and others output hard labels, you need to adjust.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Here, we treat the RF hard labels as a one-hot representation for averaging.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mcombined_predictions_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnn_test_predictions_proba\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_pred_rf_onehot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Get the final predicted class by taking the argmax (class with highest probability)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn_test_predictions_proba' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "386a91ee",
        "outputId": "4ab73efc-b04a-4ea5-ddc8-fa2af1e25eb6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# --- Define the necessary variables from the Random Forest training block ---\n",
        "# These variables should still be in memory:\n",
        "# X_test_rf (Test features)\n",
        "# y_test_rf (True test labels)\n",
        "# rf_model (The trained Random Forest object)\n",
        "# y_pred_rf (Predicted test labels from the Random Forest)\n",
        "\n",
        "# 1. Store the Random Forest predictions for the report\n",
        "rf_results_df = pd.DataFrame({\n",
        "    'True_Label': y_test_rf,\n",
        "    'Predicted_Label': y_pred_rf\n",
        "})\n",
        "\n",
        "rf_results_df.to_csv('/content/rf_final_test_predictions.csv', index=False)\n",
        "print(\"✅ Random Forest test predictions (True vs. Predicted) saved to: /content/rf_final_test_predictions.csv\")\n",
        "\n",
        "# 2. Calculate and print the confusion matrix (Excellent addition to your report)\n",
        "cm = confusion_matrix(y_test_rf, y_pred_rf)\n",
        "print(\"\\n--- Final Random Forest Confusion Matrix ---\")\n",
        "print(\"Rows are True Labels (0, 1, 2); Columns are Predicted Labels (0, 1, 2)\")\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Random Forest test predictions (True vs. Predicted) saved to: /content/rf_final_test_predictions.csv\n",
            "\n",
            "--- Final Random Forest Confusion Matrix ---\n",
            "Rows are True Labels (0, 1, 2); Columns are Predicted Labels (0, 1, 2)\n",
            "[[695 115  84]\n",
            " [205 383 306]\n",
            " [126 184 584]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59eafd99",
        "outputId": "1df8b97c-eda8-4254-ee55-826fc1eb0e99"
      },
      "source": [
        "# 1. Split the feature and label data\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n",
        "    X_features,\n",
        "    y_labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_labels\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set features shape: {X_train_rf.shape}\")\n",
        "\n",
        "# 2. Initialize and train the Random Forest Model\n",
        "print(\"Initializing and training Random Forest Classifier...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,      # Number of trees\n",
        "    max_depth=15,          # Maximum depth of trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1              # Use all available cores for speed\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "print(\"\\nRandom Forest Training Complete. Evaluating model...\")\n",
        "\n",
        "# 3. Evaluate the model\n",
        "y_pred_rf = rf_model.predict(X_test_rf)\n",
        "\n",
        "print(\"\\n--- Random Forest Classification Report ---\")\n",
        "print(classification_report(y_test_rf, y_pred_rf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set features shape: (10728, 427)\n",
            "Initializing and training Random Forest Classifier...\n",
            "\n",
            "Random Forest Training Complete. Evaluating model...\n",
            "\n",
            "--- Random Forest Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.78      0.72       894\n",
            "           1       0.56      0.43      0.49       894\n",
            "           2       0.60      0.65      0.63       894\n",
            "\n",
            "    accuracy                           0.62      2682\n",
            "   macro avg       0.61      0.62      0.61      2682\n",
            "weighted avg       0.61      0.62      0.61      2682\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39e3be9d",
        "outputId": "dd93901c-c6ad-4fd2-febc-226bb9f49709"
      },
      "source": [
        "all_X_features = []\n",
        "all_y_labels = []\n",
        "\n",
        "print(\"Starting memory-efficient feature extraction (participant by participant)...\")\n",
        "\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "\n",
        "    if os.path.exists(X_path):\n",
        "        # Load one participant's data (less memory burden)\n",
        "        X_eeg_participant = np.load(X_path)\n",
        "        y_labels_participant = np.load(y_path)\n",
        "\n",
        "        # Extract features\n",
        "        X_features_participant = extract_statistical_features(X_eeg_participant)\n",
        "\n",
        "        # Store features and labels\n",
        "        all_X_features.append(X_features_participant)\n",
        "        all_y_labels.append(y_labels_participant)\n",
        "\n",
        "        # Crucial step: Delete the large raw EEG array from memory\n",
        "        del X_eeg_participant\n",
        "\n",
        "        print(f\"Processed {p_id}. Features shape: {X_features_participant.shape}\")\n",
        "\n",
        "# Concatenate all features into final memory-friendly arrays\n",
        "X_features = np.concatenate(all_X_features, axis=0)\n",
        "y_labels = np.concatenate(all_y_labels, axis=0)\n",
        "\n",
        "print(\"\\nFeature Extraction Complete.\")\n",
        "print(f\"Final Feature Matrix shape (X): {X_features.shape}\")\n",
        "print(f\"Final Label Vector shape (y): {y_labels.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting memory-efficient feature extraction (participant by participant)...\n",
            "Processed P01. Features shape: (894, 427)\n",
            "Processed P02. Features shape: (894, 427)\n",
            "Processed P03. Features shape: (894, 427)\n",
            "Processed P04. Features shape: (894, 427)\n",
            "Processed P05. Features shape: (894, 427)\n",
            "Processed P06. Features shape: (894, 427)\n",
            "Processed P07. Features shape: (894, 427)\n",
            "Processed P08. Features shape: (894, 427)\n",
            "Processed P09. Features shape: (894, 427)\n",
            "Processed P10. Features shape: (894, 427)\n",
            "Processed P11. Features shape: (894, 427)\n",
            "Processed P12. Features shape: (894, 427)\n",
            "Processed P13. Features shape: (894, 427)\n",
            "Processed P14. Features shape: (894, 427)\n",
            "Processed P15. Features shape: (894, 427)\n",
            "\n",
            "Feature Extraction Complete.\n",
            "Final Feature Matrix shape (X): (13410, 427)\n",
            "Final Label Vector shape (y): (13410,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25a0cbcd",
        "outputId": "51670570-54e8-47b2-8e42-99241e08e0c8"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd # Import pandas for potential future use, though not strictly needed for this feature extraction\n",
        "from scipy.stats import iqr, skew\n",
        "# Assuming mne is already imported from previous steps if needed for other feature types\n",
        "# from tqdm import tqdm # Import tqdm for progress bar\n",
        "\n",
        "# --- Define Setup Variables ---\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np') # Directory where preprocessed data is saved\n",
        "FEATURES_SAVE_DIR = os.path.join(DATA_ROOT, 'rf_features_np') # New directory to save extracted features\n",
        "os.makedirs(FEATURES_SAVE_DIR, exist_ok=True) # Create the directory\n",
        "\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n",
        "\n",
        "# --- 2. Feature Extraction Function ---\n",
        "# This function takes a 3D numpy array (epochs, channels, samples) and returns 2D features\n",
        "def extract_statistical_features(X_data):\n",
        "    \"\"\"\n",
        "    Extracts statistical features per channel: Mean, Median, Std Dev, Min, Max, IQR, Skewness.\n",
        "    Input X_data shape: (n_epochs, n_channels, n_samples)\n",
        "    Output features shape: (n_epochs, n_channels * n_features)\n",
        "    \"\"\"\n",
        "    n_epochs, n_channels, n_samples = X_data.shape\n",
        "\n",
        "    # Calculate features across the sample dimension (axis=2)\n",
        "    # Ensure features are calculated correctly across the time dimension for each channel\n",
        "    features = {\n",
        "        'mean': np.mean(X_data, axis=2),\n",
        "        'median': np.median(X_data, axis=2),\n",
        "        'std': np.std(X_data, axis=2),\n",
        "        'min': np.min(X_data, axis=2),\n",
        "        'max': np.max(X_data, axis=2),\n",
        "        'iqr': iqr(X_data, axis=2),\n",
        "        'skew': skew(X_data, axis=2)\n",
        "    }\n",
        "\n",
        "    # Concatenate all features (resulting in shape (n_epochs, n_channels * 7))\n",
        "    # Stack along axis 1 (channels) to keep epochs separate\n",
        "    feature_list = [v for k, v in features.items()]\n",
        "    X_features = np.concatenate(feature_list, axis=1)\n",
        "\n",
        "    return X_features\n",
        "\n",
        "print(\"Setup complete. Feature extraction function defined.\")\n",
        "print(f\"Features will be saved to: {FEATURES_SAVE_DIR}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Feature extraction function defined.\n",
            "Features will be saved to: /content/EEG_BCI_Hackathon/rf_features_np\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63690c21",
        "outputId": "0c60dcd5-47fe-4d78-a3cf-1396a14471d1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history_cnn' is the variable holding the training history from the CNN model fit\n",
        "\n",
        "if 'history_cnn' in locals():\n",
        "    # Get accuracy and loss from the history object\n",
        "    acc = history_cnn.history['accuracy']\n",
        "    val_acc = history_cnn.history['val_accuracy']\n",
        "    loss = history_cnn.history['loss']\n",
        "    val_loss = history_cnn.history['val_loss']\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    # Plot Training and Validation Accuracy\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Training and Validation Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"CNN training history ('history_cnn') not found. Please run the CNN training cell first.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN training history ('history_cnn') not found. Please run the CNN training cell first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b2badbb"
      },
      "source": [
        "## Build and train CNN model on EEG segments\n",
        "\n",
        "Now, let's build and train a Convolutional Neural Network (CNN) model using the preprocessed EEG data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8dff8d2",
        "outputId": "8113e093-b1cc-4bcf-a77c-e2649cf4255d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
        "import numpy as np\n",
        "import os # Import os for path joining\n",
        "from tensorflow.keras.utils import Sequence # Import Sequence for the data generator\n",
        "\n",
        "# Re-define the variables used for paths and participant lists to ensure they are available\n",
        "DATA_ROOT = '/content/EEG_BCI_Hackathon'\n",
        "SAVE_DIR = os.path.join(DATA_ROOT, 'preprocessed_data_np')\n",
        "participant_ids = [f'P{i:02d}' for i in range(1, 16)]\n",
        "num_classes = 3 # Assuming 3 classes (Easy, Med, Diff)\n",
        "\n",
        "\n",
        "# --- Memory-Efficient Data Loading and Splitting (Load labels for splitting) ---\n",
        "# Load labels for splitting first, as this is typically small enough to fit in memory.\n",
        "all_y = []\n",
        "for p_id in participant_ids:\n",
        "    y_path = os.path.join(SAVE_DIR, f'{p_id}_y.npy')\n",
        "    if os.path.exists(y_path):\n",
        "        all_y.append(np.load(y_path))\n",
        "\n",
        "y_full = np.concatenate(all_y, axis=0)\n",
        "print(f\"Full Labels shape: {y_full.shape}\")\n",
        "\n",
        "# Split the INDEXES based on the full labels\n",
        "indices = np.arange(y_full.shape[0])\n",
        "X_train_idx, X_test_idx, y_train, y_test = train_test_split(\n",
        "    indices, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
        ")\n",
        "print(f\"Train indices shape: {X_train_idx.shape}, Test indices shape: {X_test_idx.shape}\")\n",
        "\n",
        "# --- Load the full X_eeg data into memory (necessary for the current Generator implementation) ---\n",
        "# Although we use indices, the current generator expects X_full to be in memory.\n",
        "# If X_eeg is still too large after this, we would need a more advanced generator\n",
        "# that loads batches directly from individual participant files using the map.\n",
        "all_X = []\n",
        "print(\"Loading full X_eeg data into memory...\")\n",
        "for p_id in participant_ids:\n",
        "    X_path = os.path.join(SAVE_DIR, f'{p_id}_X.npy')\n",
        "    if os.path.exists(X_path):\n",
        "        all_X.append(np.load(X_path))\n",
        "    # Warning for missing files is helpful but not critical if previous steps ran fully\n",
        "\n",
        "X_eeg = np.concatenate(all_X, axis=0)\n",
        "print(f\"Full X_eeg data loaded. Shape: {X_eeg.shape}\")\n",
        "\n",
        "\n",
        "# --- Memory-Safe Scaler Fitting ---\n",
        "# Fit the Scaler on a small sample (e.g., P01's data)\n",
        "X_sample_path = os.path.join(SAVE_DIR, 'P01_X.npy')\n",
        "if os.path.exists(X_sample_path):\n",
        "    X_sample = np.load(X_sample_path)\n",
        "    X_sample_reshaped = X_sample.reshape(X_sample.shape[0], -1)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_sample_reshaped)\n",
        "    print(\"Scaler fitted successfully on P01 sample data.\")\n",
        "    del X_sample, X_sample_reshaped # Free up sample memory\n",
        "else:\n",
        "     print(\"Warning: P01 sample data not found for scaler fitting. Scaler will not be used.\")\n",
        "     scaler = None # Set scaler to None if sample data is missing\n",
        "\n",
        "\n",
        "# --- Data Generator for CNN (Memory-Efficient Batch Loading) ---\n",
        "class EegCnnSequence(Sequence):\n",
        "    # Added X_full parameter to the constructor\n",
        "    def __init__(self, X_full, data_indices, labels, saved_data_dir, scaler, batch_size=32, shuffle=True):\n",
        "        self.X_full = X_full # Store the full data array\n",
        "        self.data_indices = data_indices\n",
        "        self.labels = labels\n",
        "        self.saved_data_dir = saved_data_dir\n",
        "        self.scaler = scaler\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        # --- Efficiently map global indices to participant files ---\n",
        "        # This part is not strictly needed if we load from the full X_full array passed in,\n",
        "        # but can be useful if we wanted to load directly from individual participant files.\n",
        "        # For now, we will rely on X_full being passed in.\n",
        "        # Kept the mapping logic commented out in case it's needed later for larger datasets\n",
        "        # where even X_full might be too large.\n",
        "        # self.global_to_participant_map = []\n",
        "        # current_global_idx = 0\n",
        "        # for p_id in participant_ids:\n",
        "        #     X_path = os.path.join(self.saved_data_dir, f'{p_id}_X.npy')\n",
        "        #     if os.path.exists(X_path):\n",
        "        #         # Load just the shape to avoid loading the whole array\n",
        "        #         temp_X = np.load(X_path, mmap_mode='r')\n",
        "        #         num_samples_p = temp_X.shape[0]\n",
        "        #         for i in range(num_samples_p):\n",
        "        #             self.global_to_participant_map.append((p_id, i))\n",
        "        #         current_global_idx += num_samples_p\n",
        "        #         del temp_X # Release the mmap_mode reference\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.data_indices) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get the global indices for this batch\n",
        "        batch_global_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Load data for this batch from the full array using the indices\n",
        "        X_batch_raw = self.X_full[batch_global_indices]\n",
        "        y_batch = self.labels[batch_global_indices] # Use global indices for labels too\n",
        "\n",
        "        # Preprocess and transform\n",
        "        X_batch = self._preprocess(X_batch_raw)\n",
        "\n",
        "        return X_batch, tf.keras.utils.to_categorical(y_batch, num_classes=num_classes)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indices after each epoch.\"\"\"\n",
        "        self.indices = np.arange(len(self.data_indices))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def _preprocess(self, X_raw):\n",
        "        # Scale (must reshape to 2D for scaler)\n",
        "        N, C, S = X_raw.shape\n",
        "        X_reshaped = X_raw.reshape(N, C * S)\n",
        "\n",
        "        if self.scaler:\n",
        "             X_scaled = self.scaler.transform(X_reshaped)\n",
        "        else:\n",
        "             X_scaled = X_reshaped # If no scaler fitted, just use raw\n",
        "\n",
        "        # Reshape back to 3D and then transpose for CNN (N, Samples, Channels)\n",
        "        X_final = X_scaled.reshape(N, C, S)\n",
        "        X_cnn = np.transpose(X_final, (0, 2, 1)) # (N, Samples, Channels)\n",
        "        return X_cnn\n",
        "\n",
        "\n",
        "# --- Create Data Generators for Training and Validation ---\n",
        "# Pass the full X_eeg data to the generator constructors\n",
        "train_generator_cnn = EegCnnSequence(X_eeg, X_train_idx, y_full, SAVE_DIR, scaler, shuffle=True)\n",
        "validation_generator_cnn = EegCnnSequence(X_eeg, X_test_idx, y_full, SAVE_DIR, scaler, shuffle=False)\n",
        "\n",
        "\n",
        "# --- Define the CNN Model ---\n",
        "# Input shape is (n_samples, n_channels)\n",
        "# Based on our preprocessed data shape (N, 61, 500) after transpose (N, 500, 61)\n",
        "input_shape = (X_eeg.shape[2], X_eeg.shape[1]) # (500, 61) # Correct input shape for CNN\n",
        "\n",
        "print(f\"CNN Model Input Shape: {input_shape}\")\n",
        "print(f\"Number of Output Classes: {num_classes}\")\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Input(shape=input_shape),\n",
        "    Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(filters=64, kernel_size=5, activation='relu', padding='same'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nCNN Model Summary:\")\n",
        "cnn_model.summary()\n",
        "\n",
        "\n",
        "# --- Train the model using the Data Generators ---\n",
        "print(\"\\n🚀 Starting CNN Training using Memory-Safe Generator...\")\n",
        "\n",
        "history_cnn = cnn_model.fit(\n",
        "    train_generator_cnn,\n",
        "    validation_data=validation_generator_cnn,\n",
        "    epochs=20, # Example: Train for 20 epochs\n",
        "    verbose=1,\n",
        "    # Removed batch_size as it's handled by the generator\n",
        ")\n",
        "\n",
        "print(\"\\nCNN model training completed.\")\n",
        "\n",
        "# Evaluate the model on the test generator\n",
        "print(\"\\nEvaluating CNN model on test set using generator...\")\n",
        "loss_cnn, accuracy_cnn = cnn_model.evaluate(validation_generator_cnn, verbose=0)\n",
        "print(f\"CNN Model Test Accuracy: {accuracy_cnn:.4f}\")\n",
        "print(f\"CNN Model Test Loss: {loss_cnn:.4f}\")\n",
        "\n",
        "# Store the trained CNN model for later ensemble\n",
        "trained_cnn_model = cnn_model\n",
        "\n",
        "# To get test predictions from the generator for ensemble, we need to predict batch by batch\n",
        "cnn_test_predictions_proba_list = []\n",
        "for i in range(len(validation_generator_cnn)):\n",
        "    X_batch, y_batch = validation_generator_cnn[i]\n",
        "    preds = cnn_model.predict(X_batch)\n",
        "    cnn_test_predictions_proba_list.append(preds)\n",
        "\n",
        "cnn_test_predictions_proba = np.concatenate(cnn_test_predictions_proba_list, axis=0)\n",
        "\n",
        "print(\"\\nCNN model and test predictions stored.\")\n",
        "print(f\"Shape of CNN test predictions (proba): {cnn_test_predictions_proba.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Labels shape: (13410,)\n",
            "Train indices shape: (10728,), Test indices shape: (2682,)\n",
            "Loading full X_eeg data into memory...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "tH5xYEazRMCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "720d1cf5"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial attempt to load EEG and ECG data from the specified NASA datasets (HC2S, SHARP-1, SHARP-2) failed because the required files were not found among the available data.\n",
        "*   Placeholder functions were defined for preprocessing EEG and ECG data, outlining steps such as filtering, segmentation, artifact handling, and normalization.\n",
        "*   Placeholder functions were defined for extracting hand-crafted features from preprocessed EEG and ECG data, including potential features like PSD, Hjorth parameters for EEG, and HRV metrics, morphological features for ECG.\n",
        "*   Placeholder data simulating preprocessed EEG segments, ECG sequences, hand-crafted features, and target labels were created with example shapes.\n",
        "*   The standard procedure for splitting data into training, validation, and testing sets was outlined, along with descriptions of the expected input shapes for the CNN, LSTM, and Random Forest models.\n",
        "*   A 1D CNN model for EEG, an LSTM model for ECG, and a Random Forest model for hand-crafted features were successfully built and trained using the placeholder data.\n",
        "*   Predictions were generated from each of the trained models on the placeholder validation data.\n",
        "*   An averaging voting strategy was implemented to combine the prediction probabilities from the CNN, LSTM, and Random Forest models.\n",
        "*   The combined model's performance was evaluated on the placeholder validation set, showing an accuracy of 20.00%.\n",
        "*   The classification report and confusion matrix revealed poor performance, with low precision, recall, and f1-scores across most classes, indicating significant misclassification.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The primary next step is to obtain the actual EEG and ECG data from the specified NASA datasets (HC2S, SHARP-1, SHARP-2) to replace the placeholder data and perform the analysis on real physiological signals.\n",
        "*   Once real data is loaded, re-run the preprocessing, feature extraction, model training, combination, and evaluation steps. Based on the evaluation results with real data, consider refining the preprocessing steps, exploring different hand-crafted features, tuning model architectures and hyperparameters, or experimenting with alternative prediction combination strategies (e.g., stacking).\n"
      ]
    }
  ]
}